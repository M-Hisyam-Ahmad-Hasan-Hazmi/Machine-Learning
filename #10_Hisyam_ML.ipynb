{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/M-Hisyam-Ahmad-Hasan-Hazmi/Machine-Learning/blob/main/%2310_Hisyam_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "v2Bw_wXXQKaf"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install pyglet==1.5.1\n",
        "!apt install python-opengl\n",
        "!apt install ffmpeg\n",
        "!apt install xvfb\n",
        "!pip3 install pyvirtualdisplay\n",
        "\n",
        "# Virtual display\n",
        "from pyvirtualdisplay import Display\n",
        "\n",
        "virtual_display = Display(visible=0, size=(1400, 900))\n",
        "virtual_display.start()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install gym==0.24\n",
        "!pip install pygame\n",
        "!pip install numpy\n",
        "\n",
        "!pip install imageio imageio_ffmpeg"
      ],
      "metadata": {
        "id": "oYbPDSFYQhwd"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import gym\n",
        "import random\n",
        "import time"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twtBNh1WQ3EF",
        "outputId": "0d61adbf-7bc5-4423-c2bf-f99f57186d24"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning: Gym version v0.24.0 has a number of critical issues with `gym.make` such that the `reset` and `step` functions are called before returning the environment. It is recommend to downgrading to v0.23.1 or upgrading to v0.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_map = [\n",
        "    \"SFFFH\",\n",
        "    \"HFHFF\",\n",
        "    \"FFFHF\",\n",
        "    \"FHFFF\",\n",
        "    \"HFFFG\"\n",
        "]\n",
        "\n",
        "env = gym.make('FrozenLake-v1', desc=my_map, is_slippery=False)\n",
        "env.render()\n",
        "env.reset()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-hUKLnhQ_pf",
        "outputId": "41d3179c-6ca9-4ec6-9023-50663f38cd36"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "action_space_size = env.action_space.n\n",
        "state_space_size = env.observation_space.n\n",
        "q_table = np.zeros((state_space_size, action_space_size))\n",
        "print(f'action_space_size = {action_space_size}')\n",
        "print(f'state_space_size = {state_space_size}')\n",
        "print(f'q_table = \\n{q_table}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JoAGkxOCUCej",
        "outputId": "d7155256-acea-4b31-e62d-6b80c7ee7904"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "action_space_size = 4\n",
            "state_space_size = 25\n",
            "q_table = \n",
            "[[0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training parameters\n",
        "num_episodes = 1000\n",
        "max_steps_per_episode = 100\n",
        "learning_rate = 0.1\n",
        "discount_rate = 0.99\n",
        "\n",
        "exploration_rate =1\n",
        "max_exploration_rate = 1\n",
        "min_exploration_rate = 0.01\n",
        "exploration_decay_rate = 0.05"
      ],
      "metadata": {
        "id": "ravyEYVNVXsq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rewards_all_episodes = []\n",
        "\n",
        "for episode in range(num_episodes):\n",
        "  state = env.reset()\n",
        "  state = 0\n",
        "  done = False\n",
        "  reward_current_episode = 0\n",
        "\n",
        "  for step in range(max_steps_per_episode):\n",
        "    exploration_rate_threshold = random.uniform(0, 1)\n",
        "    if exploration_rate_threshold > exploration_rate:\n",
        "      action = np.argmax(q_table[state, :])\n",
        "    else:\n",
        "      action = env.action_space.sample()\n",
        "\n",
        "    new_state, reward, done, info = env.step(action)\n",
        "    delta_q = ( 1 - learning_rate)+  learning_rate*(reward + discount_rate*np.max(q_table[new_state, :]))\n",
        "\n",
        "    print(f\"We are on {episode} episode and {step} step\")\n",
        "    print(f\"Delta Q = {delta_q}\")\n",
        "    print(f\"Q_table[{state},{action}]_old = {q_table[state, action]}\")\n",
        "\n",
        "    q_table[state, action] = q_table[state, action]*(1 - learning_rate)+\\\n",
        "                            learning_rate*(reward+discount_rate*np.max(q_table[new_state, :]))\n",
        "    print(f\"Q_table[{state, action}]_new = {q_table[state, action]}\")\n",
        "    print(f\"We are on {state} state\")\n",
        "    state = new_state\n",
        "    print(f\"And now we are on {state} state\")\n",
        "    reward_current_episode+= reward\n",
        "    print(f\"We get {reward} reward \")\n",
        "    print(f\"exploration_rate = {exploration_rate}\\n\")\n",
        "\n",
        "    if done == True:\n",
        "        break\n",
        "\n",
        "exploration_rate = min_exploration_rate +\\\n",
        "                 (max_exploration_rate - min_exploration_rate)*np.exp(-exploration_decay_rate*episode)\n",
        "rewards_all_episodes.append(reward_current_episode)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nr48_17XqBk",
        "outputId": "50995fc3-0645-41c1-8ee7-c30bd8a3ff83"
      },
      "execution_count": 7,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 864 episode and 1 step\n",
            "Delta Q = 0.9000001795115138\n",
            "Q_table[1,1]_old = 8.173832709840982e-07\n",
            "Q_table[(1, 1)]_new = 9.15156457644463e-07\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 864 episode and 2 step\n",
            "Delta Q = 0.9\n",
            "Q_table[6,0]_old = 0.0\n",
            "Q_table[(6, 0)]_new = 0.0\n",
            "We are on 6 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 865 episode and 0 step\n",
            "Delta Q = 0.9000012199813457\n",
            "Q_table[0,2]_old = 1.0467378120570689e-05\n",
            "Q_table[(0, 2)]_new = 1.0640621654262052e-05\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 865 episode and 1 step\n",
            "Delta Q = 0.9000001795115138\n",
            "Q_table[1,1]_old = 9.15156457644463e-07\n",
            "Q_table[(1, 1)]_new = 1.0031523256387913e-06\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 865 episode and 2 step\n",
            "Delta Q = 0.9\n",
            "Q_table[6,2]_old = 0.0\n",
            "Q_table[(6, 2)]_new = 0.0\n",
            "We are on 6 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 866 episode and 0 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 867 episode and 0 step\n",
            "Delta Q = 0.9000010534215438\n",
            "Q_table[0,3]_old = 6.226160554347554e-06\n",
            "Q_table[(0, 3)]_new = 6.6569660426847425e-06\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 867 episode and 1 step\n",
            "Delta Q = 0.9000010534215438\n",
            "Q_table[0,0]_old = 4.473737972364261e-06\n",
            "Q_table[(0, 0)]_new = 5.079785718899778e-06\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 867 episode and 2 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 868 episode and 0 step\n",
            "Delta Q = 0.9000010534215438\n",
            "Q_table[0,3]_old = 6.6569660426847425e-06\n",
            "Q_table[(0, 3)]_new = 7.044690982188212e-06\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 868 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 869 episode and 0 step\n",
            "Delta Q = 0.9000010534215438\n",
            "Q_table[0,0]_old = 5.079785718899778e-06\n",
            "Q_table[(0, 0)]_new = 5.625228690781743e-06\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 869 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 870 episode and 0 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 871 episode and 0 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 872 episode and 0 step\n",
            "Delta Q = 0.9000010534215438\n",
            "Q_table[0,0]_old = 5.625228690781743e-06\n",
            "Q_table[(0, 0)]_new = 6.116127365475512e-06\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 872 episode and 1 step\n",
            "Delta Q = 0.9000010534215438\n",
            "Q_table[0,3]_old = 7.044690982188212e-06\n",
            "Q_table[(0, 3)]_new = 7.393643427741334e-06\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 872 episode and 2 step\n",
            "Delta Q = 0.9000010534215438\n",
            "Q_table[0,0]_old = 6.116127365475512e-06\n",
            "Q_table[(0, 0)]_new = 6.557936172699905e-06\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 872 episode and 3 step\n",
            "Delta Q = 0.9000012199813457\n",
            "Q_table[0,2]_old = 1.0640621654262052e-05\n",
            "Q_table[(0, 2)]_new = 1.0796540834584279e-05\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 872 episode and 4 step\n",
            "Delta Q = 0.9000012199813457\n",
            "Q_table[1,3]_old = 7.305395743049803e-06\n",
            "Q_table[(1, 3)]_new = 7.794837514493255e-06\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 872 episode and 5 step\n",
            "Delta Q = 0.9000012199813457\n",
            "Q_table[1,3]_old = 7.794837514493255e-06\n",
            "Q_table[(1, 3)]_new = 8.23533510879236e-06\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 872 episode and 6 step\n",
            "Delta Q = 0.9000010688575426\n",
            "Q_table[1,0]_old = 6.054015145194223e-06\n",
            "Q_table[(1, 0)]_new = 6.5174711732986445e-06\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 872 episode and 7 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 873 episode and 0 step\n",
            "Delta Q = 0.9000010688575426\n",
            "Q_table[0,0]_old = 6.557936172699905e-06\n",
            "Q_table[(0, 0)]_new = 6.971000098053758e-06\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 873 episode and 1 step\n",
            "Delta Q = 0.9000010688575426\n",
            "Q_table[0,3]_old = 7.393643427741334e-06\n",
            "Q_table[(0, 3)]_new = 7.723136627591043e-06\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 873 episode and 2 step\n",
            "Delta Q = 0.9000010688575426\n",
            "Q_table[0,0]_old = 6.971000098053758e-06\n",
            "Q_table[(0, 0)]_new = 7.3427576308722255e-06\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 873 episode and 3 step\n",
            "Delta Q = 0.9000012199813457\n",
            "Q_table[0,2]_old = 1.0796540834584279e-05\n",
            "Q_table[(0, 2)]_new = 1.0936868096874283e-05\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 873 episode and 4 step\n",
            "Delta Q = 0.9000001795115138\n",
            "Q_table[1,1]_old = 1.0031523256387913e-06\n",
            "Q_table[(1, 1)]_new = 1.0823486068336868e-06\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 873 episode and 5 step\n",
            "Delta Q = 0.9\n",
            "Q_table[6,2]_old = 0.0\n",
            "Q_table[(6, 2)]_new = 0.0\n",
            "We are on 6 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 874 episode and 0 step\n",
            "Delta Q = 0.9000010827499416\n",
            "Q_table[0,0]_old = 7.3427576308722255e-06\n",
            "Q_table[(0, 0)]_new = 7.691231809375556e-06\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 874 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 875 episode and 0 step\n",
            "Delta Q = 0.9000010827499416\n",
            "Q_table[0,3]_old = 7.723136627591043e-06\n",
            "Q_table[(0, 3)]_new = 8.033572906422493e-06\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 875 episode and 1 step\n",
            "Delta Q = 0.9000010827499416\n",
            "Q_table[0,3]_old = 8.033572906422493e-06\n",
            "Q_table[(0, 3)]_new = 8.312965557370799e-06\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 875 episode and 2 step\n",
            "Delta Q = 0.9000010827499416\n",
            "Q_table[0,0]_old = 7.691231809375556e-06\n",
            "Q_table[(0, 0)]_new = 8.004858570028556e-06\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 875 episode and 3 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 876 episode and 0 step\n",
            "Delta Q = 0.9000010827499416\n",
            "Q_table[0,0]_old = 8.004858570028556e-06\n",
            "Q_table[(0, 0)]_new = 8.287122654616255e-06\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 876 episode and 1 step\n",
            "Delta Q = 0.9000010827499416\n",
            "Q_table[0,0]_old = 8.287122654616255e-06\n",
            "Q_table[(0, 0)]_new = 8.541160330745183e-06\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 876 episode and 2 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 877 episode and 0 step\n",
            "Delta Q = 0.9000010827499416\n",
            "Q_table[0,3]_old = 8.312965557370799e-06\n",
            "Q_table[(0, 3)]_new = 8.564418943224273e-06\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 877 episode and 1 step\n",
            "Delta Q = 0.9000010827499416\n",
            "Q_table[0,0]_old = 8.541160330745183e-06\n",
            "Q_table[(0, 0)]_new = 8.769794239261218e-06\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 877 episode and 2 step\n",
            "Delta Q = 0.9000010827499416\n",
            "Q_table[0,3]_old = 8.564418943224273e-06\n",
            "Q_table[(0, 3)]_new = 8.7907269904924e-06\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 877 episode and 3 step\n",
            "Delta Q = 0.9000012199813457\n",
            "Q_table[0,2]_old = 1.0936868096874283e-05\n",
            "Q_table[(0, 2)]_new = 1.1063162632935287e-05\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 877 episode and 4 step\n",
            "Delta Q = 0.9000010952531007\n",
            "Q_table[1,0]_old = 6.5174711732986445e-06\n",
            "Q_table[(1, 0)]_new = 6.960977156629374e-06\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 877 episode and 5 step\n",
            "Delta Q = 0.9000010952531007\n",
            "Q_table[0,3]_old = 8.7907269904924e-06\n",
            "Q_table[(0, 3)]_new = 9.006907392103753e-06\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 877 episode and 6 step\n",
            "Delta Q = 0.9000010952531007\n",
            "Q_table[0,3]_old = 9.006907392103753e-06\n",
            "Q_table[(0, 3)]_new = 9.201469753553971e-06\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 877 episode and 7 step\n",
            "Delta Q = 0.9000010952531007\n",
            "Q_table[0,0]_old = 8.769794239261218e-06\n",
            "Q_table[(0, 0)]_new = 8.988067915995689e-06\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 877 episode and 8 step\n",
            "Delta Q = 0.9000010952531007\n",
            "Q_table[0,3]_old = 9.201469753553971e-06\n",
            "Q_table[(0, 3)]_new = 9.376575878859168e-06\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 877 episode and 9 step\n",
            "Delta Q = 0.9000010952531007\n",
            "Q_table[0,3]_old = 9.376575878859168e-06\n",
            "Q_table[(0, 3)]_new = 9.534171391633845e-06\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 877 episode and 10 step\n",
            "Delta Q = 0.9000010952531007\n",
            "Q_table[0,3]_old = 9.534171391633845e-06\n",
            "Q_table[(0, 3)]_new = 9.676007353131054e-06\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 877 episode and 11 step\n",
            "Delta Q = 0.9000010952531007\n",
            "Q_table[0,0]_old = 8.988067915995689e-06\n",
            "Q_table[(0, 0)]_new = 9.184514225056713e-06\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 877 episode and 12 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 878 episode and 0 step\n",
            "Delta Q = 0.9000012199813457\n",
            "Q_table[0,2]_old = 1.1063162632935287e-05\n",
            "Q_table[(0, 2)]_new = 1.117682771539019e-05\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 878 episode and 1 step\n",
            "Delta Q = 0.9000001795115138\n",
            "Q_table[1,1]_old = 1.0823486068336868e-06\n",
            "Q_table[(1, 1)]_new = 1.1536252599090926e-06\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 878 episode and 2 step\n",
            "Delta Q = 0.9\n",
            "Q_table[6,0]_old = 0.0\n",
            "Q_table[(6, 0)]_new = 0.0\n",
            "We are on 6 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 879 episode and 0 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 880 episode and 0 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 881 episode and 0 step\n",
            "Delta Q = 0.9000011065059439\n",
            "Q_table[0,3]_old = 9.676007353131054e-06\n",
            "Q_table[(0, 3)]_new = 9.814912561641577e-06\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 881 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 882 episode and 0 step\n",
            "Delta Q = 0.9000012199813457\n",
            "Q_table[0,2]_old = 1.117682771539019e-05\n",
            "Q_table[(0, 2)]_new = 1.1279126289599604e-05\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 882 episode and 1 step\n",
            "Delta Q = 0.9000001795115138\n",
            "Q_table[1,1]_old = 1.1536252599090926e-06\n",
            "Q_table[(1, 1)]_new = 1.217774247676958e-06\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 882 episode and 2 step\n",
            "Delta Q = 0.9\n",
            "Q_table[6,0]_old = 0.0\n",
            "Q_table[(6, 0)]_new = 0.0\n",
            "We are on 6 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 883 episode and 0 step\n",
            "Delta Q = 0.9000011166335027\n",
            "Q_table[0,0]_old = 9.184514225056713e-06\n",
            "Q_table[(0, 0)]_new = 9.382696305221404e-06\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 883 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 884 episode and 0 step\n",
            "Delta Q = 0.9000011166335027\n",
            "Q_table[0,0]_old = 9.382696305221404e-06\n",
            "Q_table[(0, 0)]_new = 9.561060177369624e-06\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 884 episode and 1 step\n",
            "Delta Q = 0.9000011166335027\n",
            "Q_table[0,0]_old = 9.561060177369624e-06\n",
            "Q_table[(0, 0)]_new = 9.721587662303023e-06\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 884 episode and 2 step\n",
            "Delta Q = 0.9000011166335027\n",
            "Q_table[0,0]_old = 9.721587662303023e-06\n",
            "Q_table[(0, 0)]_new = 9.86606239874308e-06\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 884 episode and 3 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 885 episode and 0 step\n",
            "Delta Q = 0.9000012199813457\n",
            "Q_table[0,2]_old = 1.1279126289599604e-05\n",
            "Q_table[(0, 2)]_new = 1.1371195006388075e-05\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 885 episode and 1 step\n",
            "Delta Q = 0.9000019998684834\n",
            "Q_table[1,2]_old = 1.2323043896448805e-05\n",
            "Q_table[(1, 2)]_new = 1.3090607990180176e-05\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 885 episode and 2 step\n",
            "Delta Q = 0.9000019998684834\n",
            "Q_table[2,3]_old = 1.1145796189605718e-05\n",
            "Q_table[(2, 3)]_new = 1.2031085054021398e-05\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 885 episode and 3 step\n",
            "Delta Q = 0.9000042033760206\n",
            "Q_table[2,2]_old = 2.020069175127527e-05\n",
            "Q_table[(2, 2)]_new = 2.2383998596705742e-05\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 885 episode and 4 step\n",
            "Delta Q = 0.9\n",
            "Q_table[3,2]_old = 0.0\n",
            "Q_table[(3, 2)]_new = 0.0\n",
            "We are on 3 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 886 episode and 0 step\n",
            "Delta Q = 0.9000011257483057\n",
            "Q_table[0,0]_old = 9.86606239874308e-06\n",
            "Q_table[(0, 0)]_new = 1.0005204464501192e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 886 episode and 1 step\n",
            "Delta Q = 0.9000011257483057\n",
            "Q_table[0,0]_old = 1.0005204464501192e-05\n",
            "Q_table[(0, 0)]_new = 1.0130432323683493e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 886 episode and 2 step\n",
            "Delta Q = 0.9000011257483057\n",
            "Q_table[0,3]_old = 9.814912561641577e-06\n",
            "Q_table[(0, 3)]_new = 9.95916961110984e-06\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 886 episode and 3 step\n",
            "Delta Q = 0.9000011257483057\n",
            "Q_table[0,3]_old = 9.95916961110984e-06\n",
            "Q_table[(0, 3)]_new = 1.0089000955631275e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 886 episode and 4 step\n",
            "Delta Q = 0.9000012959701911\n",
            "Q_table[0,2]_old = 1.1371195006388075e-05\n",
            "Q_table[(0, 2)]_new = 1.1530045696777106e-05\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 886 episode and 5 step\n",
            "Delta Q = 0.9000012959701911\n",
            "Q_table[1,3]_old = 8.23533510879236e-06\n",
            "Q_table[(1, 3)]_new = 8.707771788940962e-06\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 886 episode and 6 step\n",
            "Delta Q = 0.9000022160158611\n",
            "Q_table[1,2]_old = 1.3090607990180176e-05\n",
            "Q_table[(1, 2)]_new = 1.3997563052236027e-05\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 886 episode and 7 step\n",
            "Delta Q = 0.9000013857587422\n",
            "Q_table[2,0]_old = 2.8086488439852225e-06\n",
            "Q_table[(2, 0)]_new = 3.913542701758067e-06\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 886 episode and 8 step\n",
            "Delta Q = 0.900001141474524\n",
            "Q_table[1,0]_old = 6.960977156629374e-06\n",
            "Q_table[(1, 0)]_new = 7.40635396494737e-06\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 886 episode and 9 step\n",
            "Delta Q = 0.9000013857587422\n",
            "Q_table[0,2]_old = 1.1530045696777106e-05\n",
            "Q_table[(0, 2)]_new = 1.1762799869270763e-05\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 886 episode and 10 step\n",
            "Delta Q = 0.9000013857587422\n",
            "Q_table[1,3]_old = 8.707771788940962e-06\n",
            "Q_table[(1, 3)]_new = 9.222753352218231e-06\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 886 episode and 11 step\n",
            "Delta Q = 0.900001164517187\n",
            "Q_table[1,0]_old = 7.40635396494737e-06\n",
            "Q_table[(1, 0)]_new = 7.830235755510438e-06\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 886 episode and 12 step\n",
            "Delta Q = 0.9000013857587422\n",
            "Q_table[0,2]_old = 1.1762799869270763e-05\n",
            "Q_table[(0, 2)]_new = 1.1972278624515055e-05\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 886 episode and 13 step\n",
            "Delta Q = 0.9000001795115138\n",
            "Q_table[1,1]_old = 1.217774247676958e-06\n",
            "Q_table[(1, 1)]_new = 1.2755083366680367e-06\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 886 episode and 14 step\n",
            "Delta Q = 0.9\n",
            "Q_table[6,2]_old = 0.0\n",
            "Q_table[(6, 2)]_new = 0.0\n",
            "We are on 6 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 887 episode and 0 step\n",
            "Delta Q = 0.9000013857587422\n",
            "Q_table[0,2]_old = 1.1972278624515055e-05\n",
            "Q_table[(0, 2)]_new = 1.2160809504234917e-05\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 887 episode and 1 step\n",
            "Delta Q = 0.9000013857587422\n",
            "Q_table[1,3]_old = 9.222753352218231e-06\n",
            "Q_table[(1, 3)]_new = 9.686236759167774e-06\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 887 episode and 2 step\n",
            "Delta Q = 0.9000013857587422\n",
            "Q_table[1,3]_old = 9.686236759167774e-06\n",
            "Q_table[(1, 3)]_new = 1.0103371825422365e-05\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 887 episode and 3 step\n",
            "Delta Q = 0.9000012039201409\n",
            "Q_table[1,0]_old = 7.830235755510438e-06\n",
            "Q_table[(1, 0)]_new = 8.251132320878651e-06\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 887 episode and 4 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 888 episode and 0 step\n",
            "Delta Q = 0.9000012039201409\n",
            "Q_table[0,0]_old = 1.0130432323683493e-05\n",
            "Q_table[(0, 0)]_new = 1.0321309232234401e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 888 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 889 episode and 0 step\n",
            "Delta Q = 0.9000013857587422\n",
            "Q_table[0,2]_old = 1.2160809504234917e-05\n",
            "Q_table[(0, 2)]_new = 1.2330487295982793e-05\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 889 episode and 1 step\n",
            "Delta Q = 0.9000012207182423\n",
            "Q_table[1,0]_old = 8.251132320878651e-06\n",
            "Q_table[(1, 0)]_new = 8.646737331093083e-06\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 889 episode and 2 step\n",
            "Delta Q = 0.9000012207182423\n",
            "Q_table[0,3]_old = 1.0089000955631275e-05\n",
            "Q_table[(0, 3)]_new = 1.0300819102370444e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 889 episode and 3 step\n",
            "Delta Q = 0.9000013857587422\n",
            "Q_table[0,2]_old = 1.2330487295982793e-05\n",
            "Q_table[(0, 2)]_new = 1.2483197308555879e-05\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 889 episode and 4 step\n",
            "Delta Q = 0.9000013857587422\n",
            "Q_table[1,3]_old = 1.0103371825422365e-05\n",
            "Q_table[(1, 3)]_new = 1.0478793385051494e-05\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 889 episode and 5 step\n",
            "Delta Q = 0.9000022160158611\n",
            "Q_table[1,2]_old = 1.3997563052236027e-05\n",
            "Q_table[(1, 2)]_new = 1.4813822608086293e-05\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 889 episode and 6 step\n",
            "Delta Q = 0.9\n",
            "Q_table[2,1]_old = 0.0\n",
            "Q_table[(2, 1)]_new = 0.0\n",
            "We are on 2 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 890 episode and 0 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 891 episode and 0 step\n",
            "Delta Q = 0.9000012358365336\n",
            "Q_table[0,0]_old = 1.0321309232234401e-05\n",
            "Q_table[(0, 0)]_new = 1.0525014842557994e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 891 episode and 1 step\n",
            "Delta Q = 0.9000012358365336\n",
            "Q_table[0,0]_old = 1.0525014842557994e-05\n",
            "Q_table[(0, 0)]_new = 1.0708349891849228e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 891 episode and 2 step\n",
            "Delta Q = 0.9000012358365336\n",
            "Q_table[0,3]_old = 1.0300819102370444e-05\n",
            "Q_table[(0, 3)]_new = 1.0506573725680432e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 891 episode and 3 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 892 episode and 0 step\n",
            "Delta Q = 0.9000014665684383\n",
            "Q_table[0,2]_old = 1.2483197308555879e-05\n",
            "Q_table[(0, 2)]_new = 1.2701446015900835e-05\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 892 episode and 1 step\n",
            "Delta Q = 0.9000022160158611\n",
            "Q_table[1,2]_old = 1.4813822608086293e-05\n",
            "Q_table[(1, 2)]_new = 1.5548456208351533e-05\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 892 episode and 2 step\n",
            "Delta Q = 0.9\n",
            "Q_table[2,1]_old = 0.0\n",
            "Q_table[(2, 1)]_new = 0.0\n",
            "We are on 2 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 893 episode and 0 step\n",
            "Delta Q = 0.9000012574431556\n",
            "Q_table[0,0]_old = 1.0708349891849228e-05\n",
            "Q_table[(0, 0)]_new = 1.0894958058238487e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 893 episode and 1 step\n",
            "Delta Q = 0.9000012574431556\n",
            "Q_table[0,0]_old = 1.0894958058238487e-05\n",
            "Q_table[(0, 0)]_new = 1.106290540798882e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 893 episode and 2 step\n",
            "Delta Q = 0.9000012574431556\n",
            "Q_table[0,0]_old = 1.106290540798882e-05\n",
            "Q_table[(0, 0)]_new = 1.121405802276412e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 893 episode and 3 step\n",
            "Delta Q = 0.9000015392971646\n",
            "Q_table[0,2]_old = 1.2701446015900835e-05\n",
            "Q_table[(0, 2)]_new = 1.2970598578937553e-05\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 893 episode and 4 step\n",
            "Delta Q = 0.9000015392971646\n",
            "Q_table[1,3]_old = 1.0478793385051494e-05\n",
            "Q_table[(1, 3)]_new = 1.0970211211173148e-05\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 893 episode and 5 step\n",
            "Delta Q = 0.9000001795115138\n",
            "Q_table[1,1]_old = 1.2755083366680367e-06\n",
            "Q_table[(1, 1)]_new = 1.3274690167600076e-06\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 893 episode and 6 step\n",
            "Delta Q = 0.9000000013607753\n",
            "Q_table[6,1]_old = 3.687701040917923e-09\n",
            "Q_table[(6, 1)]_new = 4.679706228677763e-09\n",
            "We are on 6 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 893 episode and 7 step\n",
            "Delta Q = 0.9\n",
            "Q_table[11,2]_old = 0.0\n",
            "Q_table[(11, 2)]_new = 0.0\n",
            "We are on 11 state\n",
            "And now we are on 12 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 893 episode and 8 step\n",
            "Delta Q = 0.9\n",
            "Q_table[12,1]_old = 0.0\n",
            "Q_table[(12, 1)]_new = 0.0\n",
            "We are on 12 state\n",
            "And now we are on 17 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 893 episode and 9 step\n",
            "Delta Q = 0.9\n",
            "Q_table[17,3]_old = 0.0\n",
            "Q_table[(17, 3)]_new = 0.0\n",
            "We are on 17 state\n",
            "And now we are on 12 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 893 episode and 10 step\n",
            "Delta Q = 0.9000000013607753\n",
            "Q_table[12,0]_old = 0.0\n",
            "Q_table[(12, 0)]_new = 1.360775291851632e-09\n",
            "We are on 12 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 893 episode and 11 step\n",
            "Delta Q = 0.9\n",
            "Q_table[11,1]_old = 0.0\n",
            "Q_table[(11, 1)]_new = 0.0\n",
            "We are on 11 state\n",
            "And now we are on 16 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 894 episode and 0 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 895 episode and 0 step\n",
            "Delta Q = 0.9000012840892594\n",
            "Q_table[0,3]_old = 1.0506573725680432e-05\n",
            "Q_table[(0, 3)]_new = 1.0740005612427209e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 895 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 896 episode and 0 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 897 episode and 0 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 898 episode and 0 step\n",
            "Delta Q = 0.9000012840892594\n",
            "Q_table[0,0]_old = 1.121405802276412e-05\n",
            "Q_table[(0, 0)]_new = 1.1376741479802526e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 898 episode and 1 step\n",
            "Delta Q = 0.9000012840892594\n",
            "Q_table[0,0]_old = 1.1376741479802526e-05\n",
            "Q_table[(0, 0)]_new = 1.1523156591137092e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 898 episode and 2 step\n",
            "Delta Q = 0.9000012840892594\n",
            "Q_table[0,3]_old = 1.0740005612427209e-05\n",
            "Q_table[(0, 3)]_new = 1.0950094310499306e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 898 episode and 3 step\n",
            "Delta Q = 0.9000012840892594\n",
            "Q_table[0,0]_old = 1.1523156591137092e-05\n",
            "Q_table[(0, 0)]_new = 1.1654930191338202e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 898 episode and 4 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 899 episode and 0 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 900 episode and 0 step\n",
            "Delta Q = 0.9000012840892594\n",
            "Q_table[0,0]_old = 1.1654930191338202e-05\n",
            "Q_table[(0, 0)]_new = 1.17735264315192e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 900 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 901 episode and 0 step\n",
            "Delta Q = 0.9000015392971646\n",
            "Q_table[0,2]_old = 1.2970598578937553e-05\n",
            "Q_table[(0, 2)]_new = 1.32128358856706e-05\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 901 episode and 1 step\n",
            "Delta Q = 0.9000013080707527\n",
            "Q_table[1,0]_old = 8.646737331093083e-06\n",
            "Q_table[(1, 0)]_new = 9.090134350665165e-06\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 901 episode and 2 step\n",
            "Delta Q = 0.9000013080707527\n",
            "Q_table[0,3]_old = 1.0950094310499306e-05\n",
            "Q_table[(0, 3)]_new = 1.1163155632130765e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 901 episode and 3 step\n",
            "Delta Q = 0.9000013080707527\n",
            "Q_table[0,0]_old = 1.17735264315192e-05\n",
            "Q_table[(0, 0)]_new = 1.190424454104867e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 901 episode and 4 step\n",
            "Delta Q = 0.9000013080707527\n",
            "Q_table[0,0]_old = 1.190424454104867e-05\n",
            "Q_table[(0, 0)]_new = 1.2021890839625194e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 901 episode and 5 step\n",
            "Delta Q = 0.9000015392971646\n",
            "Q_table[0,2]_old = 1.32128358856706e-05\n",
            "Q_table[(0, 2)]_new = 1.3430849461730342e-05\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 901 episode and 6 step\n",
            "Delta Q = 0.9000001795115138\n",
            "Q_table[1,1]_old = 1.3274690167600076e-06\n",
            "Q_table[(1, 1)]_new = 1.3742336288427814e-06\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 901 episode and 7 step\n",
            "Delta Q = 0.9000015392971646\n",
            "Q_table[6,3]_old = 1.813247613724995e-06\n",
            "Q_table[(6, 3)]_new = 3.171220016979297e-06\n",
            "We are on 6 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 901 episode and 8 step\n",
            "Delta Q = 0.9000013296540967\n",
            "Q_table[1,0]_old = 9.090134350665165e-06\n",
            "Q_table[(1, 0)]_new = 9.510775012309952e-06\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 901 episode and 9 step\n",
            "Delta Q = 0.9000013296540967\n",
            "Q_table[0,3]_old = 1.1163155632130765e-05\n",
            "Q_table[(0, 3)]_new = 1.1376494165628992e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 901 episode and 10 step\n",
            "Delta Q = 0.9000013296540967\n",
            "Q_table[0,3]_old = 1.1376494165628992e-05\n",
            "Q_table[(0, 3)]_new = 1.1568498845777398e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 901 episode and 11 step\n",
            "Delta Q = 0.9000013296540967\n",
            "Q_table[0,3]_old = 1.1568498845777398e-05\n",
            "Q_table[(0, 3)]_new = 1.1741303057910962e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 901 episode and 12 step\n",
            "Delta Q = 0.9000013296540967\n",
            "Q_table[0,0]_old = 1.2021890839625194e-05\n",
            "Q_table[(0, 0)]_new = 1.2149355852373979e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 901 episode and 13 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 902 episode and 0 step\n",
            "Delta Q = 0.9000013296540967\n",
            "Q_table[0,0]_old = 1.2149355852373979e-05\n",
            "Q_table[(0, 0)]_new = 1.2264074363847885e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 902 episode and 1 step\n",
            "Delta Q = 0.9000015392971646\n",
            "Q_table[0,2]_old = 1.3430849461730342e-05\n",
            "Q_table[(0, 2)]_new = 1.362706168018411e-05\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 902 episode and 2 step\n",
            "Delta Q = 0.9000015392971646\n",
            "Q_table[1,3]_old = 1.0970211211173148e-05\n",
            "Q_table[(1, 3)]_new = 1.1412487254682635e-05\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 902 episode and 3 step\n",
            "Delta Q = 0.9000013490791063\n",
            "Q_table[1,0]_old = 9.510775012309952e-06\n",
            "Q_table[(1, 0)]_new = 9.908776617417184e-06\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 902 episode and 4 step\n",
            "Delta Q = 0.9000015392971646\n",
            "Q_table[0,2]_old = 1.362706168018411e-05\n",
            "Q_table[(0, 2)]_new = 1.3803652676792501e-05\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 902 episode and 5 step\n",
            "Delta Q = 0.9000003139507817\n",
            "Q_table[1,1]_old = 1.3742336288427814e-06\n",
            "Q_table[(1, 1)]_new = 1.5507610476394538e-06\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 902 episode and 6 step\n",
            "Delta Q = 0.9000015392971646\n",
            "Q_table[6,3]_old = 3.171220016979297e-06\n",
            "Q_table[(6, 3)]_new = 4.393395179908169e-06\n",
            "We are on 6 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 902 episode and 7 step\n",
            "Delta Q = 0.9000015392971646\n",
            "Q_table[1,3]_old = 1.1412487254682635e-05\n",
            "Q_table[(1, 3)]_new = 1.1810535693841174e-05\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 902 episode and 8 step\n",
            "Delta Q = 0.9000015392971646\n",
            "Q_table[1,3]_old = 1.1810535693841174e-05\n",
            "Q_table[(1, 3)]_new = 1.216877928908386e-05\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 902 episode and 9 step\n",
            "Delta Q = 0.900001366561615\n",
            "Q_table[1,0]_old = 9.908776617417184e-06\n",
            "Q_table[(1, 0)]_new = 1.0284460570677923e-05\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 902 episode and 10 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 903 episode and 0 step\n",
            "Delta Q = 0.900001366561615\n",
            "Q_table[0,0]_old = 1.2264074363847885e-05\n",
            "Q_table[(0, 0)]_new = 1.2404228542465555e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 903 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 904 episode and 0 step\n",
            "Delta Q = 0.9000015392971646\n",
            "Q_table[0,2]_old = 1.3803652676792501e-05\n",
            "Q_table[(0, 2)]_new = 1.3962584573740054e-05\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 904 episode and 1 step\n",
            "Delta Q = 0.9000004349461228\n",
            "Q_table[1,1]_old = 1.5507610476394538e-06\n",
            "Q_table[(1, 1)]_new = 1.8306310656864173e-06\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 904 episode and 2 step\n",
            "Delta Q = 0.9000000013607753\n",
            "Q_table[6,1]_old = 4.679706228677763e-09\n",
            "Q_table[(6, 1)]_new = 5.572510897661619e-09\n",
            "We are on 6 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 904 episode and 3 step\n",
            "Delta Q = 0.9\n",
            "Q_table[11,0]_old = 0.0\n",
            "Q_table[(11, 0)]_new = 0.0\n",
            "We are on 11 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 904 episode and 4 step\n",
            "Delta Q = 0.9\n",
            "Q_table[10,0]_old = 0.0\n",
            "Q_table[(10, 0)]_new = 0.0\n",
            "We are on 10 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 904 episode and 5 step\n",
            "Delta Q = 0.9000000013607753\n",
            "Q_table[10,2]_old = 0.0\n",
            "Q_table[(10, 2)]_new = 1.360775291851632e-09\n",
            "We are on 10 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 904 episode and 6 step\n",
            "Delta Q = 0.9000000001347168\n",
            "Q_table[11,2]_old = 0.0\n",
            "Q_table[(11, 2)]_new = 1.3471675389331156e-10\n",
            "We are on 11 state\n",
            "And now we are on 12 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 904 episode and 7 step\n",
            "Delta Q = 0.9\n",
            "Q_table[12,2]_old = 0.0\n",
            "Q_table[(12, 2)]_new = 0.0\n",
            "We are on 12 state\n",
            "And now we are on 13 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 905 episode and 0 step\n",
            "Delta Q = 0.9000013822958728\n",
            "Q_table[0,3]_old = 1.1741303057910962e-05\n",
            "Q_table[(0, 3)]_new = 1.1949468624920131e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 905 episode and 1 step\n",
            "Delta Q = 0.9000013822958728\n",
            "Q_table[0,0]_old = 1.2404228542465555e-05\n",
            "Q_table[(0, 0)]_new = 1.2546101561019265e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 905 episode and 2 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 906 episode and 0 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 907 episode and 0 step\n",
            "Delta Q = 0.9000015392971646\n",
            "Q_table[0,2]_old = 1.3962584573740054e-05\n",
            "Q_table[(0, 2)]_new = 1.410562328099285e-05\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 907 episode and 1 step\n",
            "Delta Q = 0.9000004349461228\n",
            "Q_table[1,1]_old = 1.8306310656864173e-06\n",
            "Q_table[(1, 1)]_new = 2.082514081928684e-06\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 907 episode and 2 step\n",
            "Delta Q = 0.9000015392971646\n",
            "Q_table[6,3]_old = 4.393395179908169e-06\n",
            "Q_table[(6, 3)]_new = 5.493352826544154e-06\n",
            "We are on 6 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 907 episode and 3 step\n",
            "Delta Q = 0.9000015392971646\n",
            "Q_table[1,3]_old = 1.216877928908386e-05\n",
            "Q_table[(1, 3)]_new = 1.2491198524802276e-05\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 907 episode and 4 step\n",
            "Delta Q = 0.9000005438419298\n",
            "Q_table[1,1]_old = 2.082514081928684e-06\n",
            "Q_table[(1, 1)]_new = 2.418104603563687e-06\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 907 episode and 5 step\n",
            "Delta Q = 0.9000015392971646\n",
            "Q_table[6,3]_old = 5.493352826544154e-06\n",
            "Q_table[(6, 3)]_new = 6.483314708516541e-06\n",
            "We are on 6 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 907 episode and 6 step\n",
            "Delta Q = 0.9000006418481562\n",
            "Q_table[1,1]_old = 2.418104603563687e-06\n",
            "Q_table[(1, 1)]_new = 2.818142299350456e-06\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 907 episode and 7 step\n",
            "Delta Q = 0.9\n",
            "Q_table[6,0]_old = 0.0\n",
            "Q_table[(6, 0)]_new = 0.0\n",
            "We are on 6 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 908 episode and 0 step\n",
            "Delta Q = 0.9000013964567048\n",
            "Q_table[0,3]_old = 1.1949468624920131e-05\n",
            "Q_table[(0, 3)]_new = 1.215097846724641e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 908 episode and 1 step\n",
            "Delta Q = 0.9000013964567048\n",
            "Q_table[0,3]_old = 1.215097846724641e-05\n",
            "Q_table[(0, 3)]_new = 1.2332337325340063e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 908 episode and 2 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 909 episode and 0 step\n",
            "Delta Q = 0.9000013964567048\n",
            "Q_table[0,0]_old = 1.2546101561019265e-05\n",
            "Q_table[(0, 0)]_new = 1.2687948109735631e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 909 episode and 1 step\n",
            "Delta Q = 0.9000013964567048\n",
            "Q_table[0,3]_old = 1.2332337325340063e-05\n",
            "Q_table[(0, 3)]_new = 1.249556029762435e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 909 episode and 2 step\n",
            "Delta Q = 0.9000013964567048\n",
            "Q_table[0,0]_old = 1.2687948109735631e-05\n",
            "Q_table[(0, 0)]_new = 1.2815610003580361e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 909 episode and 3 step\n",
            "Delta Q = 0.9000013964567048\n",
            "Q_table[0,0]_old = 1.2815610003580361e-05\n",
            "Q_table[(0, 0)]_new = 1.2930505708040619e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 909 episode and 4 step\n",
            "Delta Q = 0.9000013964567048\n",
            "Q_table[0,3]_old = 1.249556029762435e-05\n",
            "Q_table[(0, 3)]_new = 1.2642460972680209e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 909 episode and 5 step\n",
            "Delta Q = 0.9000013964567048\n",
            "Q_table[0,3]_old = 1.2642460972680209e-05\n",
            "Q_table[(0, 3)]_new = 1.2774671580230482e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 909 episode and 6 step\n",
            "Delta Q = 0.9000013964567048\n",
            "Q_table[0,0]_old = 1.2930505708040619e-05\n",
            "Q_table[(0, 0)]_new = 1.303391184205485e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 909 episode and 7 step\n",
            "Delta Q = 0.9000015392971646\n",
            "Q_table[0,2]_old = 1.410562328099285e-05\n",
            "Q_table[(0, 2)]_new = 1.4234358117520367e-05\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 909 episode and 8 step\n",
            "Delta Q = 0.9000006418481562\n",
            "Q_table[1,1]_old = 2.818142299350456e-06\n",
            "Q_table[(1, 1)]_new = 3.1781762255585483e-06\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 909 episode and 9 step\n",
            "Delta Q = 0.9000000013607753\n",
            "Q_table[6,1]_old = 5.572510897661619e-09\n",
            "Q_table[(6, 1)]_new = 6.3760350997470895e-09\n",
            "We are on 6 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 909 episode and 10 step\n",
            "Delta Q = 0.9000000001347168\n",
            "Q_table[11,2]_old = 1.3471675389331156e-10\n",
            "Q_table[(11, 2)]_new = 2.5596183239729194e-10\n",
            "We are on 11 state\n",
            "And now we are on 12 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 909 episode and 11 step\n",
            "Delta Q = 0.9\n",
            "Q_table[12,3]_old = 0.0\n",
            "Q_table[(12, 3)]_new = 0.0\n",
            "We are on 12 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 910 episode and 0 step\n",
            "Delta Q = 0.9000015392971646\n",
            "Q_table[0,2]_old = 1.4234358117520367e-05\n",
            "Q_table[(0, 2)]_new = 1.4350219470395133e-05\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 910 episode and 1 step\n",
            "Delta Q = 0.9000015392971646\n",
            "Q_table[1,3]_old = 1.2491198524802276e-05\n",
            "Q_table[(1, 3)]_new = 1.278137583694885e-05\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 910 episode and 2 step\n",
            "Delta Q = 0.9000006418481562\n",
            "Q_table[1,1]_old = 3.1781762255585483e-06\n",
            "Q_table[(1, 1)]_new = 3.5022067591458313e-06\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 910 episode and 3 step\n",
            "Delta Q = 0.9\n",
            "Q_table[6,0]_old = 0.0\n",
            "Q_table[(6, 0)]_new = 0.0\n",
            "We are on 6 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 911 episode and 0 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 912 episode and 0 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 913 episode and 0 step\n",
            "Delta Q = 0.9000014206717276\n",
            "Q_table[0,3]_old = 1.2774671580230482e-05\n",
            "Q_table[(0, 3)]_new = 1.2917876149776552e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 913 episode and 1 step\n",
            "Delta Q = 0.9000014206717276\n",
            "Q_table[0,3]_old = 1.2917876149776552e-05\n",
            "Q_table[(0, 3)]_new = 1.3046760262368016e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 913 episode and 2 step\n",
            "Delta Q = 0.9000014206717276\n",
            "Q_table[0,3]_old = 1.3046760262368016e-05\n",
            "Q_table[(0, 3)]_new = 1.3162755963700332e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 913 episode and 3 step\n",
            "Delta Q = 0.9000014206717276\n",
            "Q_table[0,0]_old = 1.303391184205485e-05\n",
            "Q_table[(0, 0)]_new = 1.3151192385418484e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 913 episode and 4 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 914 episode and 0 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 915 episode and 0 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 916 episode and 0 step\n",
            "Delta Q = 0.9000015392971646\n",
            "Q_table[0,2]_old = 1.4350219470395133e-05\n",
            "Q_table[(0, 2)]_new = 1.4454494687982422e-05\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 916 episode and 1 step\n",
            "Delta Q = 0.9000015392971646\n",
            "Q_table[1,3]_old = 1.278137583694885e-05\n",
            "Q_table[(1, 3)]_new = 1.3042535417880767e-05\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 916 episode and 2 step\n",
            "Delta Q = 0.9000022160158611\n",
            "Q_table[1,2]_old = 1.5548456208351533e-05\n",
            "Q_table[(1, 2)]_new = 1.6209626448590247e-05\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 916 episode and 3 step\n",
            "Delta Q = 0.9000022160158611\n",
            "Q_table[2,3]_old = 1.2031085054021398e-05\n",
            "Q_table[(2, 3)]_new = 1.3043992409693127e-05\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 916 episode and 4 step\n",
            "Delta Q = 0.9000016047530184\n",
            "Q_table[2,0]_old = 3.913542701758067e-06\n",
            "Q_table[(2, 0)]_new = 5.126941449992695e-06\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 916 episode and 5 step\n",
            "Delta Q = 0.9000016047530184\n",
            "Q_table[1,3]_old = 1.3042535417880767e-05\n",
            "Q_table[(1, 3)]_new = 1.3343034894503124e-05\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 916 episode and 6 step\n",
            "Delta Q = 0.9000022160158611\n",
            "Q_table[1,2]_old = 1.6209626448590247e-05\n",
            "Q_table[(1, 2)]_new = 1.6804679664805092e-05\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 916 episode and 7 step\n",
            "Delta Q = 0.9000042033760206\n",
            "Q_table[2,2]_old = 2.2383998596705742e-05\n",
            "Q_table[(2, 2)]_new = 2.434897475759317e-05\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 916 episode and 8 step\n",
            "Delta Q = 0.9\n",
            "Q_table[3,2]_old = 0.0\n",
            "Q_table[(3, 2)]_new = 0.0\n",
            "We are on 3 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 917 episode and 0 step\n",
            "Delta Q = 0.9000014309949741\n",
            "Q_table[0,3]_old = 1.3162755963700332e-05\n",
            "Q_table[(0, 3)]_new = 1.327747534144056e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 917 episode and 1 step\n",
            "Delta Q = 0.9000014309949741\n",
            "Q_table[0,0]_old = 1.3151192385418484e-05\n",
            "Q_table[(0, 0)]_new = 1.3267068120986896e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 917 episode and 2 step\n",
            "Delta Q = 0.9000016636632868\n",
            "Q_table[0,2]_old = 1.4454494687982422e-05\n",
            "Q_table[(0, 2)]_new = 1.4672708505999884e-05\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 917 episode and 3 step\n",
            "Delta Q = 0.9000016636632868\n",
            "Q_table[1,3]_old = 1.3343034894503124e-05\n",
            "Q_table[(1, 3)]_new = 1.3672394691868515e-05\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 917 episode and 4 step\n",
            "Delta Q = 0.9000014525981421\n",
            "Q_table[1,0]_old = 1.0284460570677923e-05\n",
            "Q_table[(1, 0)]_new = 1.0708612655704119e-05\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 917 episode and 5 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 918 episode and 0 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 919 episode and 0 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 920 episode and 0 step\n",
            "Delta Q = 0.9000014525981421\n",
            "Q_table[0,0]_old = 1.3267068120986896e-05\n",
            "Q_table[(0, 0)]_new = 1.3392959450982194e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 920 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 921 episode and 0 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 922 episode and 0 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 923 episode and 0 step\n",
            "Delta Q = 0.9000014525981421\n",
            "Q_table[0,0]_old = 1.3392959450982194e-05\n",
            "Q_table[(0, 0)]_new = 1.3506261647977963e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 923 episode and 1 step\n",
            "Delta Q = 0.9000016636632868\n",
            "Q_table[0,2]_old = 1.4672708505999884e-05\n",
            "Q_table[(0, 2)]_new = 1.4869100942215601e-05\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 923 episode and 2 step\n",
            "Delta Q = 0.9000016636632868\n",
            "Q_table[1,3]_old = 1.3672394691868515e-05\n",
            "Q_table[(1, 3)]_new = 1.3968818509497369e-05\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 923 episode and 3 step\n",
            "Delta Q = 0.9000016636632868\n",
            "Q_table[1,3]_old = 1.3968818509497369e-05\n",
            "Q_table[(1, 3)]_new = 1.4235599945363337e-05\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 923 episode and 4 step\n",
            "Delta Q = 0.9000016636632868\n",
            "Q_table[1,3]_old = 1.4235599945363337e-05\n",
            "Q_table[(1, 3)]_new = 1.4475703237642707e-05\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 923 episode and 5 step\n",
            "Delta Q = 0.9000006418481562\n",
            "Q_table[1,1]_old = 3.5022067591458313e-06\n",
            "Q_table[(1, 1)]_new = 3.793834239374386e-06\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 923 episode and 6 step\n",
            "Delta Q = 0.9\n",
            "Q_table[6,0]_old = 0.0\n",
            "Q_table[(6, 0)]_new = 0.0\n",
            "We are on 6 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 924 episode and 0 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 925 episode and 0 step\n",
            "Delta Q = 0.9000016636632868\n",
            "Q_table[0,2]_old = 1.4869100942215601e-05\n",
            "Q_table[(0, 2)]_new = 1.5045854134809746e-05\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 925 episode and 1 step\n",
            "Delta Q = 0.9000014895395594\n",
            "Q_table[1,0]_old = 1.0708612655704119e-05\n",
            "Q_table[(1, 0)]_new = 1.1127290949479873e-05\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 925 episode and 2 step\n",
            "Delta Q = 0.9000014895395594\n",
            "Q_table[0,3]_old = 1.327747534144056e-05\n",
            "Q_table[(0, 3)]_new = 1.3439267366642668e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 925 episode and 3 step\n",
            "Delta Q = 0.9000014895395594\n",
            "Q_table[0,3]_old = 1.3439267366642668e-05\n",
            "Q_table[(0, 3)]_new = 1.3584880189324567e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 925 episode and 4 step\n",
            "Delta Q = 0.9000014895395594\n",
            "Q_table[0,3]_old = 1.3584880189324567e-05\n",
            "Q_table[(0, 3)]_new = 1.3715931729738276e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 925 episode and 5 step\n",
            "Delta Q = 0.9000014895395594\n",
            "Q_table[0,3]_old = 1.3715931729738276e-05\n",
            "Q_table[(0, 3)]_new = 1.3833878116110614e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 925 episode and 6 step\n",
            "Delta Q = 0.9000014895395594\n",
            "Q_table[0,0]_old = 1.3506261647977963e-05\n",
            "Q_table[(0, 0)]_new = 1.3645175042526332e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 925 episode and 7 step\n",
            "Delta Q = 0.9000014895395594\n",
            "Q_table[0,3]_old = 1.3833878116110614e-05\n",
            "Q_table[(0, 3)]_new = 1.3940029863845717e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 925 episode and 8 step\n",
            "Delta Q = 0.9000016636632868\n",
            "Q_table[0,2]_old = 1.5045854134809746e-05\n",
            "Q_table[(0, 2)]_new = 1.5204932008144476e-05\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 925 episode and 9 step\n",
            "Delta Q = 0.9000006418481562\n",
            "Q_table[1,1]_old = 3.793834239374386e-06\n",
            "Q_table[(1, 1)]_new = 4.056298971580085e-06\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 925 episode and 10 step\n",
            "Delta Q = 0.9000016636632868\n",
            "Q_table[6,3]_old = 6.483314708516541e-06\n",
            "Q_table[(6, 3)]_new = 7.4986465244805915e-06\n",
            "We are on 6 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 925 episode and 11 step\n",
            "Delta Q = 0.900002410548501\n",
            "Q_table[1,2]_old = 1.6804679664805092e-05\n",
            "Q_table[(1, 2)]_new = 1.7534760199326308e-05\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 925 episode and 12 step\n",
            "Delta Q = 0.9000017359412598\n",
            "Q_table[2,0]_old = 5.126941449992695e-06\n",
            "Q_table[(2, 0)]_new = 6.35018856472673e-06\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 925 episode and 13 step\n",
            "Delta Q = 0.9000007423660059\n",
            "Q_table[1,1]_old = 4.056298971580085e-06\n",
            "Q_table[(1, 1)]_new = 4.393035080345655e-06\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 925 episode and 14 step\n",
            "Delta Q = 0.9000017359412598\n",
            "Q_table[6,3]_old = 7.4986465244805915e-06\n",
            "Q_table[(6, 3)]_new = 8.484723131765838e-06\n",
            "We are on 6 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 925 episode and 15 step\n",
            "Delta Q = 0.9000015052882688\n",
            "Q_table[1,0]_old = 1.1127290949479873e-05\n",
            "Q_table[(1, 0)]_new = 1.151985012333819e-05\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 925 episode and 16 step\n",
            "Delta Q = 0.9000017359412598\n",
            "Q_table[0,2]_old = 1.5204932008144476e-05\n",
            "Q_table[(0, 2)]_new = 1.5420380067063333e-05\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 925 episode and 17 step\n",
            "Delta Q = 0.9000008399875901\n",
            "Q_table[1,1]_old = 4.393035080345655e-06\n",
            "Q_table[(1, 1)]_new = 4.793719162355907e-06\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 925 episode and 18 step\n",
            "Delta Q = 0.9\n",
            "Q_table[6,0]_old = 0.0\n",
            "Q_table[(6, 0)]_new = 0.0\n",
            "We are on 6 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 926 episode and 0 step\n",
            "Delta Q = 0.9000015266176267\n",
            "Q_table[0,0]_old = 1.3645175042526332e-05\n",
            "Q_table[(0, 0)]_new = 1.3807275164912969e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 926 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 927 episode and 0 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 928 episode and 0 step\n",
            "Delta Q = 0.9000015266176267\n",
            "Q_table[0,0]_old = 1.3807275164912969e-05\n",
            "Q_table[(0, 0)]_new = 1.3953165275060942e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 928 episode and 1 step\n",
            "Delta Q = 0.9000017359412598\n",
            "Q_table[0,2]_old = 1.5420380067063333e-05\n",
            "Q_table[(0, 2)]_new = 1.5614283320090306e-05\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 928 episode and 2 step\n",
            "Delta Q = 0.9000008399875901\n",
            "Q_table[1,1]_old = 4.793719162355907e-06\n",
            "Q_table[(1, 1)]_new = 5.154334836165135e-06\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 928 episode and 3 step\n",
            "Delta Q = 0.9\n",
            "Q_table[6,2]_old = 0.0\n",
            "Q_table[(6, 2)]_new = 0.0\n",
            "We are on 6 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 929 episode and 0 step\n",
            "Delta Q = 0.9000015458140487\n",
            "Q_table[0,3]_old = 1.3940029863845717e-05\n",
            "Q_table[(0, 3)]_new = 1.4091840926150087e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 929 episode and 1 step\n",
            "Delta Q = 0.9000015458140487\n",
            "Q_table[0,3]_old = 1.4091840926150087e-05\n",
            "Q_table[(0, 3)]_new = 1.422847088222402e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 929 episode and 2 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 930 episode and 0 step\n",
            "Delta Q = 0.9000015458140487\n",
            "Q_table[0,0]_old = 1.3953165275060942e-05\n",
            "Q_table[(0, 0)]_new = 1.4103662796243789e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 930 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 931 episode and 0 step\n",
            "Delta Q = 0.9000017359412598\n",
            "Q_table[0,2]_old = 1.5614283320090306e-05\n",
            "Q_table[(0, 2)]_new = 1.578879624781458e-05\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 931 episode and 1 step\n",
            "Delta Q = 0.9000017359412598\n",
            "Q_table[1,3]_old = 1.4475703237642707e-05\n",
            "Q_table[(1, 3)]_new = 1.476407417361174e-05\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 931 episode and 2 step\n",
            "Delta Q = 0.9000017359412598\n",
            "Q_table[1,3]_old = 1.476407417361174e-05\n",
            "Q_table[(1, 3)]_new = 1.502360801598387e-05\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 931 episode and 3 step\n",
            "Delta Q = 0.9000015630908286\n",
            "Q_table[1,0]_old = 1.151985012333819e-05\n",
            "Q_table[(1, 0)]_new = 1.1930955939538015e-05\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 931 episode and 4 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 932 episode and 0 step\n",
            "Delta Q = 0.9000015630908286\n",
            "Q_table[0,3]_old = 1.422847088222402e-05\n",
            "Q_table[(0, 3)]_new = 1.4368714622535262e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 932 episode and 1 step\n",
            "Delta Q = 0.9000017359412598\n",
            "Q_table[0,2]_old = 1.578879624781458e-05\n",
            "Q_table[(0, 2)]_new = 1.5945857882766426e-05\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 932 episode and 2 step\n",
            "Delta Q = 0.900002410548501\n",
            "Q_table[1,2]_old = 1.7534760199326308e-05\n",
            "Q_table[(1, 2)]_new = 1.8191832680395402e-05\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 932 episode and 3 step\n",
            "Delta Q = 0.9000018009914353\n",
            "Q_table[2,0]_old = 6.35018856472673e-06\n",
            "Q_table[(2, 0)]_new = 7.516161143613202e-06\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 932 episode and 4 step\n",
            "Delta Q = 0.9000015786399305\n",
            "Q_table[1,0]_old = 1.1930955939538015e-05\n",
            "Q_table[(1, 0)]_new = 1.2316500275978091e-05\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 932 episode and 5 step\n",
            "Delta Q = 0.9000018009914353\n",
            "Q_table[0,2]_old = 1.5945857882766426e-05\n",
            "Q_table[(0, 2)]_new = 1.6152263529848927e-05\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 932 episode and 6 step\n",
            "Delta Q = 0.9000018009914353\n",
            "Q_table[1,3]_old = 1.502360801598387e-05\n",
            "Q_table[(1, 3)]_new = 1.532223864974463e-05\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 932 episode and 7 step\n",
            "Delta Q = 0.9000018009914353\n",
            "Q_table[1,3]_old = 1.532223864974463e-05\n",
            "Q_table[(1, 3)]_new = 1.559100622012931e-05\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 932 episode and 8 step\n",
            "Delta Q = 0.9000008399875901\n",
            "Q_table[1,1]_old = 5.154334836165135e-06\n",
            "Q_table[(1, 1)]_new = 5.478888942593439e-06\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 932 episode and 9 step\n",
            "Delta Q = 0.9\n",
            "Q_table[6,0]_old = 0.0\n",
            "Q_table[(6, 0)]_new = 0.0\n",
            "We are on 6 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 933 episode and 0 step\n",
            "Delta Q = 0.9000015990740895\n",
            "Q_table[0,3]_old = 1.4368714622535262e-05\n",
            "Q_table[(0, 3)]_new = 1.4530917249736782e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 933 episode and 1 step\n",
            "Delta Q = 0.9000015990740895\n",
            "Q_table[0,3]_old = 1.4530917249736782e-05\n",
            "Q_table[(0, 3)]_new = 1.4676899614218148e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 933 episode and 2 step\n",
            "Delta Q = 0.9000018009914353\n",
            "Q_table[0,2]_old = 1.6152263529848927e-05\n",
            "Q_table[(0, 2)]_new = 1.6338028612223178e-05\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 933 episode and 3 step\n",
            "Delta Q = 0.900002410548501\n",
            "Q_table[1,2]_old = 1.8191832680395402e-05\n",
            "Q_table[(1, 2)]_new = 1.8783197913357587e-05\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 933 episode and 4 step\n",
            "Delta Q = 0.9000042033760206\n",
            "Q_table[2,2]_old = 2.434897475759317e-05\n",
            "Q_table[(2, 2)]_new = 2.6117453302391853e-05\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 933 episode and 5 step\n",
            "Delta Q = 0.9\n",
            "Q_table[3,2]_old = 0.0\n",
            "Q_table[(3, 2)]_new = 0.0\n",
            "We are on 3 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 934 episode and 0 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 935 episode and 0 step\n",
            "Delta Q = 0.9000016174648326\n",
            "Q_table[0,0]_old = 1.4103662796243789e-05\n",
            "Q_table[(0, 0)]_new = 1.4310761349229506e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 935 episode and 1 step\n",
            "Delta Q = 0.9000016174648326\n",
            "Q_table[0,3]_old = 1.4676899614218148e-05\n",
            "Q_table[(0, 3)]_new = 1.4826674485406429e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 935 episode and 2 step\n",
            "Delta Q = 0.9000016174648326\n",
            "Q_table[0,3]_old = 1.4826674485406429e-05\n",
            "Q_table[(0, 3)]_new = 1.4961471869475881e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 935 episode and 3 step\n",
            "Delta Q = 0.9000016174648326\n",
            "Q_table[0,0]_old = 1.4310761349229506e-05\n",
            "Q_table[(0, 0)]_new = 1.449715004691665e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 935 episode and 4 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 936 episode and 0 step\n",
            "Delta Q = 0.9000018595365934\n",
            "Q_table[0,2]_old = 1.6338028612223178e-05\n",
            "Q_table[(0, 2)]_new = 1.6563762344423263e-05\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 936 episode and 1 step\n",
            "Delta Q = 0.9000016398124722\n",
            "Q_table[1,0]_old = 1.2316500275978091e-05\n",
            "Q_table[(1, 0)]_new = 1.2724662720478185e-05\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 936 episode and 2 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 937 episode and 0 step\n",
            "Delta Q = 0.9000018595365934\n",
            "Q_table[0,2]_old = 1.6563762344423263e-05\n",
            "Q_table[(0, 2)]_new = 1.676692270340334e-05\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 937 episode and 1 step\n",
            "Delta Q = 0.9000016599253476\n",
            "Q_table[1,0]_old = 1.2724662720478185e-05\n",
            "Q_table[(1, 0)]_new = 1.3112121796067297e-05\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 937 episode and 2 step\n",
            "Delta Q = 0.9000016599253476\n",
            "Q_table[0,3]_old = 1.4961471869475881e-05\n",
            "Q_table[(0, 3)]_new = 1.5125250030165224e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 937 episode and 3 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 938 episode and 0 step\n",
            "Delta Q = 0.9000016599253476\n",
            "Q_table[0,3]_old = 1.5125250030165224e-05\n",
            "Q_table[(0, 3)]_new = 1.527265037478563e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 938 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 939 episode and 0 step\n",
            "Delta Q = 0.9000016599253476\n",
            "Q_table[0,0]_old = 1.449715004691665e-05\n",
            "Q_table[(0, 0)]_new = 1.4707360389861916e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 939 episode and 1 step\n",
            "Delta Q = 0.9000016599253476\n",
            "Q_table[0,0]_old = 1.4707360389861916e-05\n",
            "Q_table[(0, 0)]_new = 1.4896549698512655e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 939 episode and 2 step\n",
            "Delta Q = 0.9000016599253476\n",
            "Q_table[0,0]_old = 1.4896549698512655e-05\n",
            "Q_table[(0, 0)]_new = 1.506682007629832e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 939 episode and 3 step\n",
            "Delta Q = 0.9000018595365934\n",
            "Q_table[0,2]_old = 1.676692270340334e-05\n",
            "Q_table[(0, 2)]_new = 1.6949767026485407e-05\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 939 episode and 4 step\n",
            "Delta Q = 0.9000018595365934\n",
            "Q_table[1,3]_old = 1.559100622012931e-05\n",
            "Q_table[(1, 3)]_new = 1.589144219153878e-05\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 939 episode and 5 step\n",
            "Delta Q = 0.9000025856278769\n",
            "Q_table[1,2]_old = 1.8783197913357587e-05\n",
            "Q_table[(1, 2)]_new = 1.9490505998958623e-05\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 939 episode and 6 step\n",
            "Delta Q = 0.9000025856278769\n",
            "Q_table[2,3]_old = 1.3043992409693127e-05\n",
            "Q_table[(2, 3)]_new = 1.4325221045660607e-05\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 939 episode and 7 step\n",
            "Delta Q = 0.900001929560094\n",
            "Q_table[2,0]_old = 7.516161143613202e-06\n",
            "Q_table[(2, 0)]_new = 8.694105123148786e-06\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 939 episode and 8 step\n",
            "Delta Q = 0.900001929560094\n",
            "Q_table[1,3]_old = 1.589144219153878e-05\n",
            "Q_table[(1, 3)]_new = 1.6231858066281807e-05\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 939 episode and 9 step\n",
            "Delta Q = 0.9000025856278769\n",
            "Q_table[1,2]_old = 1.9490505998958623e-05\n",
            "Q_table[(1, 2)]_new = 2.0127083275999553e-05\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 939 episode and 10 step\n",
            "Delta Q = 0.9\n",
            "Q_table[2,1]_old = 0.0\n",
            "Q_table[(2, 1)]_new = 0.0\n",
            "We are on 2 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 940 episode and 0 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 941 episode and 0 step\n",
            "Delta Q = 0.9000016780269356\n",
            "Q_table[0,3]_old = 1.527265037478563e-05\n",
            "Q_table[(0, 3)]_new = 1.5423412272929125e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 941 episode and 1 step\n",
            "Delta Q = 0.9000016780269356\n",
            "Q_table[0,0]_old = 1.506682007629832e-05\n",
            "Q_table[(0, 0)]_new = 1.5238165004290544e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 941 episode and 2 step\n",
            "Delta Q = 0.9000016780269356\n",
            "Q_table[0,0]_old = 1.5238165004290544e-05\n",
            "Q_table[(0, 0)]_new = 1.5392375439483546e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 941 episode and 3 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 942 episode and 0 step\n",
            "Delta Q = 0.9000016780269356\n",
            "Q_table[0,0]_old = 1.5392375439483546e-05\n",
            "Q_table[(0, 0)]_new = 1.5531164831157245e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 942 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 943 episode and 0 step\n",
            "Delta Q = 0.9000016780269356\n",
            "Q_table[0,0]_old = 1.5531164831157245e-05\n",
            "Q_table[(0, 0)]_new = 1.5656075283663578e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 943 episode and 1 step\n",
            "Delta Q = 0.9000016780269356\n",
            "Q_table[0,0]_old = 1.5656075283663578e-05\n",
            "Q_table[(0, 0)]_new = 1.5768494690919276e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 943 episode and 2 step\n",
            "Delta Q = 0.9000016780269356\n",
            "Q_table[0,3]_old = 1.5423412272929125e-05\n",
            "Q_table[(0, 3)]_new = 1.5559097981258267e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 943 episode and 3 step\n",
            "Delta Q = 0.9000016780269356\n",
            "Q_table[0,0]_old = 1.5768494690919276e-05\n",
            "Q_table[(0, 0)]_new = 1.5869672157449403e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 943 episode and 4 step\n",
            "Delta Q = 0.9000016780269356\n",
            "Q_table[0,0]_old = 1.5869672157449403e-05\n",
            "Q_table[(0, 0)]_new = 1.5960731877326517e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 943 episode and 5 step\n",
            "Delta Q = 0.9000019925812444\n",
            "Q_table[0,2]_old = 1.6949767026485407e-05\n",
            "Q_table[(0, 2)]_new = 1.724737156816082e-05\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 943 episode and 6 step\n",
            "Delta Q = 0.9000008399875901\n",
            "Q_table[1,1]_old = 5.478888942593439e-06\n",
            "Q_table[(1, 1)]_new = 5.770987638378913e-06\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 943 episode and 7 step\n",
            "Delta Q = 0.9000000013607753\n",
            "Q_table[6,1]_old = 6.3760350997470895e-09\n",
            "Q_table[(6, 1)]_new = 7.099206881624013e-09\n",
            "We are on 6 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 943 episode and 8 step\n",
            "Delta Q = 0.9000008399875901\n",
            "Q_table[11,3]_old = 1.3745204968198303e-08\n",
            "Q_table[(11, 3)]_new = 8.523582745161963e-07\n",
            "We are on 11 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 943 episode and 9 step\n",
            "Delta Q = 0.9\n",
            "Q_table[6,2]_old = 0.0\n",
            "Q_table[(6, 2)]_new = 0.0\n",
            "We are on 6 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 944 episode and 0 step\n",
            "Delta Q = 0.9000019925812444\n",
            "Q_table[0,2]_old = 1.724737156816082e-05\n",
            "Q_table[(0, 2)]_new = 1.7515215655668698e-05\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 944 episode and 1 step\n",
            "Delta Q = 0.90000173400635\n",
            "Q_table[1,0]_old = 1.3112121796067297e-05\n",
            "Q_table[(1, 0)]_new = 1.3534915966371769e-05\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 944 episode and 2 step\n",
            "Delta Q = 0.90000173400635\n",
            "Q_table[0,3]_old = 1.5559097981258267e-05\n",
            "Q_table[(0, 3)]_new = 1.573719453304364e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 944 episode and 3 step\n",
            "Delta Q = 0.90000173400635\n",
            "Q_table[0,3]_old = 1.573719453304364e-05\n",
            "Q_table[(0, 3)]_new = 1.5897481429650476e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 944 episode and 4 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 945 episode and 0 step\n",
            "Delta Q = 0.9000019925812444\n",
            "Q_table[0,2]_old = 1.7515215655668698e-05\n",
            "Q_table[(0, 2)]_new = 1.7756275334425785e-05\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 945 episode and 1 step\n",
            "Delta Q = 0.9000017578712581\n",
            "Q_table[1,0]_old = 1.3534915966371769e-05\n",
            "Q_table[(1, 0)]_new = 1.3939295627842745e-05\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 945 episode and 2 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 946 episode and 0 step\n",
            "Delta Q = 0.9000017578712581\n",
            "Q_table[0,3]_old = 1.5897481429650476e-05\n",
            "Q_table[(0, 3)]_new = 1.6065604544793582e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 946 episode and 1 step\n",
            "Delta Q = 0.9000017578712581\n",
            "Q_table[0,3]_old = 1.6065604544793582e-05\n",
            "Q_table[(0, 3)]_new = 1.6216915348422376e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 946 episode and 2 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 947 episode and 0 step\n",
            "Delta Q = 0.9000017578712581\n",
            "Q_table[0,3]_old = 1.6216915348422376e-05\n",
            "Q_table[(0, 3)]_new = 1.6353095071688292e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 947 episode and 1 step\n",
            "Delta Q = 0.9000017578712581\n",
            "Q_table[0,3]_old = 1.6353095071688292e-05\n",
            "Q_table[(0, 3)]_new = 1.6475656822627616e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 947 episode and 2 step\n",
            "Delta Q = 0.9000017578712581\n",
            "Q_table[0,0]_old = 1.5960731877326517e-05\n",
            "Q_table[(0, 0)]_new = 1.612252994770202e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 947 episode and 3 step\n",
            "Delta Q = 0.9000017578712581\n",
            "Q_table[0,0]_old = 1.612252994770202e-05\n",
            "Q_table[(0, 0)]_new = 1.6268148211039972e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 947 episode and 4 step\n",
            "Delta Q = 0.9000017578712581\n",
            "Q_table[0,0]_old = 1.6268148211039972e-05\n",
            "Q_table[(0, 0)]_new = 1.6399204648044127e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 947 episode and 5 step\n",
            "Delta Q = 0.9000017578712581\n",
            "Q_table[0,0]_old = 1.6399204648044127e-05\n",
            "Q_table[(0, 0)]_new = 1.6517155441347868e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 947 episode and 6 step\n",
            "Delta Q = 0.9000017578712581\n",
            "Q_table[0,0]_old = 1.6517155441347868e-05\n",
            "Q_table[(0, 0)]_new = 1.6623311155321235e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 947 episode and 7 step\n",
            "Delta Q = 0.9000017578712581\n",
            "Q_table[0,0]_old = 1.6623311155321235e-05\n",
            "Q_table[(0, 0)]_new = 1.6718851297897265e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 947 episode and 8 step\n",
            "Delta Q = 0.9000019925812444\n",
            "Q_table[0,2]_old = 1.7756275334425785e-05\n",
            "Q_table[(0, 2)]_new = 1.7973229045307164e-05\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 947 episode and 9 step\n",
            "Delta Q = 0.9000025856278769\n",
            "Q_table[1,2]_old = 2.0127083275999553e-05\n",
            "Q_table[(1, 2)]_new = 2.0700002825336392e-05\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 947 episode and 10 step\n",
            "Delta Q = 0.9000042033760206\n",
            "Q_table[2,2]_old = 2.6117453302391853e-05\n",
            "Q_table[(2, 2)]_new = 2.770908399271067e-05\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 947 episode and 11 step\n",
            "Delta Q = 0.9000027431993153\n",
            "Q_table[3,0]_old = 3.5569666856040558e-06\n",
            "Q_table[(3, 0)]_new = 5.944469332322007e-06\n",
            "We are on 3 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 947 episode and 12 step\n",
            "Delta Q = 0.9000027431993153\n",
            "Q_table[2,3]_old = 1.4325221045660607e-05\n",
            "Q_table[(2, 3)]_new = 1.5635898256372904e-05\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 947 episode and 13 step\n",
            "Delta Q = 0.9000020493002797\n",
            "Q_table[2,0]_old = 8.694105123148786e-06\n",
            "Q_table[(2, 0)]_new = 9.87399489054221e-06\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 947 episode and 14 step\n",
            "Delta Q = 0.9000020493002797\n",
            "Q_table[1,3]_old = 1.6231858066281807e-05\n",
            "Q_table[(1, 3)]_new = 1.665797253936193e-05\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 947 episode and 15 step\n",
            "Delta Q = 0.9000027431993153\n",
            "Q_table[1,2]_old = 2.0700002825336392e-05\n",
            "Q_table[(1, 2)]_new = 2.137320185808111e-05\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 947 episode and 16 step\n",
            "Delta Q = 0.9000027431993153\n",
            "Q_table[2,3]_old = 1.5635898256372904e-05\n",
            "Q_table[(2, 3)]_new = 1.681550774601397e-05\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 947 episode and 17 step\n",
            "Delta Q = 0.9000042033760206\n",
            "Q_table[2,2]_old = 2.770908399271067e-05\n",
            "Q_table[(2, 2)]_new = 2.9141551613997604e-05\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 947 episode and 18 step\n",
            "Delta Q = 0.9\n",
            "Q_table[3,2]_old = 0.0\n",
            "Q_table[(3, 2)]_new = 0.0\n",
            "We are on 3 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 948 episode and 0 step\n",
            "Delta Q = 0.9000017793496755\n",
            "Q_table[0,0]_old = 1.6718851297897265e-05\n",
            "Q_table[(0, 0)]_new = 1.682631584359295e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 948 episode and 1 step\n",
            "Delta Q = 0.900002115946984\n",
            "Q_table[0,2]_old = 1.7973229045307164e-05\n",
            "Q_table[(0, 2)]_new = 1.8291853124726477e-05\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 948 episode and 2 step\n",
            "Delta Q = 0.9000028850136098\n",
            "Q_table[1,2]_old = 2.137320185808111e-05\n",
            "Q_table[(1, 2)]_new = 2.2120895282058763e-05\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 948 episode and 3 step\n",
            "Delta Q = 0.9\n",
            "Q_table[2,1]_old = 0.0\n",
            "Q_table[(2, 1)]_new = 0.0\n",
            "We are on 2 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 949 episode and 0 step\n",
            "Delta Q = 0.9000018108934593\n",
            "Q_table[0,0]_old = 1.682631584359295e-05\n",
            "Q_table[(0, 0)]_new = 1.6954577718581575e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 949 episode and 1 step\n",
            "Delta Q = 0.9000018108934593\n",
            "Q_table[0,3]_old = 1.6475656822627616e-05\n",
            "Q_table[(0, 3)]_new = 1.6638984599712775e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 949 episode and 2 step\n",
            "Delta Q = 0.9000018108934593\n",
            "Q_table[0,3]_old = 1.6638984599712775e-05\n",
            "Q_table[(0, 3)]_new = 1.678597959908942e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 949 episode and 3 step\n",
            "Delta Q = 0.9000018108934593\n",
            "Q_table[0,3]_old = 1.678597959908942e-05\n",
            "Q_table[(0, 3)]_new = 1.69182750985284e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 949 episode and 4 step\n",
            "Delta Q = 0.9000021899686329\n",
            "Q_table[0,2]_old = 1.8291853124726477e-05\n",
            "Q_table[(0, 2)]_new = 1.8652636445177647e-05\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 949 episode and 5 step\n",
            "Delta Q = 0.9000028850136098\n",
            "Q_table[1,2]_old = 2.2120895282058763e-05\n",
            "Q_table[(1, 2)]_new = 2.279381936363865e-05\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 949 episode and 6 step\n",
            "Delta Q = 0.9000028850136098\n",
            "Q_table[2,3]_old = 1.681550774601397e-05\n",
            "Q_table[(2, 3)]_new = 1.8018970581198334e-05\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 949 episode and 7 step\n",
            "Delta Q = 0.9000042033760206\n",
            "Q_table[2,2]_old = 2.9141551613997604e-05\n",
            "Q_table[(2, 2)]_new = 3.0430772473155844e-05\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 949 episode and 8 step\n",
            "Delta Q = 0.9\n",
            "Q_table[3,2]_old = 0.0\n",
            "Q_table[(3, 2)]_new = 0.0\n",
            "We are on 3 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 950 episode and 0 step\n",
            "Delta Q = 0.9000018466110081\n",
            "Q_table[0,3]_old = 1.69182750985284e-05\n",
            "Q_table[(0, 3)]_new = 1.7073058596748148e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 950 episode and 1 step\n",
            "Delta Q = 0.9000018466110081\n",
            "Q_table[0,0]_old = 1.6954577718581575e-05\n",
            "Q_table[(0, 0)]_new = 1.7105730954796006e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 950 episode and 2 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 951 episode and 0 step\n",
            "Delta Q = 0.9000018466110081\n",
            "Q_table[0,0]_old = 1.7105730954796006e-05\n",
            "Q_table[(0, 0)]_new = 1.7241768867388993e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 951 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 952 episode and 0 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 953 episode and 0 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 954 episode and 0 step\n",
            "Delta Q = 0.9000018466110081\n",
            "Q_table[0,3]_old = 1.7073058596748148e-05\n",
            "Q_table[(0, 3)]_new = 1.721236374514592e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 954 episode and 1 step\n",
            "Delta Q = 0.9000018466110081\n",
            "Q_table[0,3]_old = 1.721236374514592e-05\n",
            "Q_table[(0, 3)]_new = 1.7337738378703913e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 954 episode and 2 step\n",
            "Delta Q = 0.9000018466110081\n",
            "Q_table[0,3]_old = 1.7337738378703913e-05\n",
            "Q_table[(0, 3)]_new = 1.745057554890611e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 954 episode and 3 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 955 episode and 0 step\n",
            "Delta Q = 0.9000022565881171\n",
            "Q_table[0,2]_old = 1.8652636445177647e-05\n",
            "Q_table[(0, 2)]_new = 1.904396091766011e-05\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 955 episode and 1 step\n",
            "Delta Q = 0.9000008399875901\n",
            "Q_table[1,1]_old = 5.770987638378913e-06\n",
            "Q_table[(1, 1)]_new = 6.0338764645858394e-06\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 955 episode and 2 step\n",
            "Delta Q = 0.9000000843834692\n",
            "Q_table[6,1]_old = 7.099206881624013e-09\n",
            "Q_table[(6, 1)]_new = 9.077275537056504e-08\n",
            "We are on 6 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 955 episode and 3 step\n",
            "Delta Q = 0.9000000001347168\n",
            "Q_table[11,0]_old = 0.0\n",
            "Q_table[(11, 0)]_new = 1.3471675389331156e-10\n",
            "We are on 11 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 955 episode and 4 step\n",
            "Delta Q = 0.9\n",
            "Q_table[10,1]_old = 0.0\n",
            "Q_table[(10, 1)]_new = 0.0\n",
            "We are on 10 state\n",
            "And now we are on 15 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 955 episode and 5 step\n",
            "Delta Q = 0.9\n",
            "Q_table[15,0]_old = 0.0\n",
            "Q_table[(15, 0)]_new = 0.0\n",
            "We are on 15 state\n",
            "And now we are on 15 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 955 episode and 6 step\n",
            "Delta Q = 0.9\n",
            "Q_table[15,1]_old = 0.0\n",
            "Q_table[(15, 1)]_new = 0.0\n",
            "We are on 15 state\n",
            "And now we are on 20 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 956 episode and 0 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 957 episode and 0 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 958 episode and 0 step\n",
            "Delta Q = 0.9000022565881171\n",
            "Q_table[0,2]_old = 1.904396091766011e-05\n",
            "Q_table[(0, 2)]_new = 1.9396152942894323e-05\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 958 episode and 1 step\n",
            "Delta Q = 0.9000008399875901\n",
            "Q_table[1,1]_old = 6.0338764645858394e-06\n",
            "Q_table[(1, 1)]_new = 6.270476408172073e-06\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 958 episode and 2 step\n",
            "Delta Q = 0.9000022565881171\n",
            "Q_table[6,3]_old = 8.484723131765838e-06\n",
            "Q_table[(6, 3)]_new = 9.892838935589481e-06\n",
            "We are on 6 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 958 episode and 3 step\n",
            "Delta Q = 0.9000022565881171\n",
            "Q_table[1,3]_old = 1.665797253936193e-05\n",
            "Q_table[(1, 3)]_new = 1.7248763402425965e-05\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 958 episode and 4 step\n",
            "Delta Q = 0.9000009793910546\n",
            "Q_table[1,1]_old = 6.270476408172073e-06\n",
            "Q_table[(1, 1)]_new = 6.622819821978225e-06\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 958 episode and 5 step\n",
            "Delta Q = 0.9\n",
            "Q_table[6,0]_old = 0.0\n",
            "Q_table[(6, 0)]_new = 0.0\n",
            "We are on 6 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 959 episode and 0 step\n",
            "Delta Q = 0.9000019202191414\n",
            "Q_table[0,3]_old = 1.745057554890611e-05\n",
            "Q_table[(0, 3)]_new = 1.7625737135362036e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 959 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 960 episode and 0 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 961 episode and 0 step\n",
            "Delta Q = 0.9000019202191414\n",
            "Q_table[0,0]_old = 1.7241768867388993e-05\n",
            "Q_table[(0, 0)]_new = 1.7437811121996632e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 961 episode and 1 step\n",
            "Delta Q = 0.9000022565881171\n",
            "Q_table[0,2]_old = 1.9396152942894323e-05\n",
            "Q_table[(0, 2)]_new = 1.9713125765605116e-05\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 961 episode and 2 step\n",
            "Delta Q = 0.9000009793910546\n",
            "Q_table[1,1]_old = 6.622819821978225e-06\n",
            "Q_table[(1, 1)]_new = 6.939928894403761e-06\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 961 episode and 3 step\n",
            "Delta Q = 0.9000022565881171\n",
            "Q_table[6,3]_old = 9.892838935589481e-06\n",
            "Q_table[(6, 3)]_new = 1.116014315903076e-05\n",
            "We are on 6 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 961 episode and 4 step\n",
            "Delta Q = 0.9000011048541727\n",
            "Q_table[1,1]_old = 6.939928894403761e-06\n",
            "Q_table[(1, 1)]_new = 7.35079017770743e-06\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 961 episode and 5 step\n",
            "Delta Q = 0.9\n",
            "Q_table[6,0]_old = 0.0\n",
            "Q_table[(6, 0)]_new = 0.0\n",
            "We are on 6 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 962 episode and 0 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 963 episode and 0 step\n",
            "Delta Q = 0.9000019515994508\n",
            "Q_table[0,3]_old = 1.7625737135362036e-05\n",
            "Q_table[(0, 3)]_new = 1.781476287262074e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 963 episode and 1 step\n",
            "Delta Q = 0.9000019515994508\n",
            "Q_table[0,3]_old = 1.781476287262074e-05\n",
            "Q_table[(0, 3)]_new = 1.798488603615357e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 963 episode and 2 step\n",
            "Delta Q = 0.9000019515994508\n",
            "Q_table[0,0]_old = 1.7437811121996632e-05\n",
            "Q_table[(0, 0)]_new = 1.7645629460591877e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 963 episode and 3 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 964 episode and 0 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 965 episode and 0 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 966 episode and 0 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 967 episode and 0 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 968 episode and 0 step\n",
            "Delta Q = 0.9000022565881171\n",
            "Q_table[0,2]_old = 1.9713125765605116e-05\n",
            "Q_table[(0, 2)]_new = 1.9998401306044833e-05\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 968 episode and 1 step\n",
            "Delta Q = 0.9000011048541727\n",
            "Q_table[1,1]_old = 7.35079017770743e-06\n",
            "Q_table[(1, 1)]_new = 7.720565332680733e-06\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 968 episode and 2 step\n",
            "Delta Q = 0.9\n",
            "Q_table[6,0]_old = 0.0\n",
            "Q_table[(6, 0)]_new = 0.0\n",
            "We are on 6 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 969 episode and 0 step\n",
            "Delta Q = 0.9000019798417294\n",
            "Q_table[0,0]_old = 1.7645629460591877e-05\n",
            "Q_table[(0, 0)]_new = 1.7860908243831128e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 969 episode and 1 step\n",
            "Delta Q = 0.9000019798417294\n",
            "Q_table[0,3]_old = 1.798488603615357e-05\n",
            "Q_table[(0, 3)]_new = 1.816623916183665e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 969 episode and 2 step\n",
            "Delta Q = 0.9000019798417294\n",
            "Q_table[0,0]_old = 1.7860908243831128e-05\n",
            "Q_table[(0, 0)]_new = 1.8054659148746453e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 969 episode and 3 step\n",
            "Delta Q = 0.9000019798417294\n",
            "Q_table[0,3]_old = 1.816623916183665e-05\n",
            "Q_table[(0, 3)]_new = 1.8329456974951423e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 969 episode and 4 step\n",
            "Delta Q = 0.9000022565881171\n",
            "Q_table[0,2]_old = 1.9998401306044833e-05\n",
            "Q_table[(0, 2)]_new = 2.0255149292440577e-05\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 969 episode and 5 step\n",
            "Delta Q = 0.90000200525978\n",
            "Q_table[1,0]_old = 1.3939295627842745e-05\n",
            "Q_table[(1, 0)]_new = 1.455062584501009e-05\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 969 episode and 6 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 970 episode and 0 step\n",
            "Delta Q = 0.90000200525978\n",
            "Q_table[0,0]_old = 1.8054659148746453e-05\n",
            "Q_table[(0, 0)]_new = 1.8254453013823426e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 970 episode and 1 step\n",
            "Delta Q = 0.9000022565881171\n",
            "Q_table[0,2]_old = 2.0255149292440577e-05\n",
            "Q_table[(0, 2)]_new = 2.0486222480196744e-05\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 970 episode and 2 step\n",
            "Delta Q = 0.9000022565881171\n",
            "Q_table[1,3]_old = 1.7248763402425965e-05\n",
            "Q_table[(1, 3)]_new = 1.7780475179183595e-05\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 970 episode and 3 step\n",
            "Delta Q = 0.9000020281360256\n",
            "Q_table[1,0]_old = 1.455062584501009e-05\n",
            "Q_table[(1, 0)]_new = 1.5123699286048559e-05\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 970 episode and 4 step\n",
            "Delta Q = 0.9000020281360256\n",
            "Q_table[0,0]_old = 1.8254453013823426e-05\n",
            "Q_table[(0, 0)]_new = 1.845714373798056e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 970 episode and 5 step\n",
            "Delta Q = 0.9000020281360256\n",
            "Q_table[0,0]_old = 1.845714373798056e-05\n",
            "Q_table[(0, 0)]_new = 1.863956538972198e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 970 episode and 6 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 971 episode and 0 step\n",
            "Delta Q = 0.9000020281360256\n",
            "Q_table[0,0]_old = 1.863956538972198e-05\n",
            "Q_table[(0, 0)]_new = 1.880374487628926e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 971 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 972 episode and 0 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 0 step\n",
            "Delta Q = 0.9000022565881171\n",
            "Q_table[0,2]_old = 2.0486222480196744e-05\n",
            "Q_table[(0, 2)]_new = 2.0694188349177298e-05\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 1 step\n",
            "Delta Q = 0.9000020487246466\n",
            "Q_table[1,0]_old = 1.5123699286048559e-05\n",
            "Q_table[(1, 0)]_new = 1.5660054004012256e-05\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 2 step\n",
            "Delta Q = 0.9000020487246466\n",
            "Q_table[0,3]_old = 1.8329456974951423e-05\n",
            "Q_table[(0, 3)]_new = 1.8545235924024833e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 3 step\n",
            "Delta Q = 0.9000022565881171\n",
            "Q_table[0,2]_old = 2.0694188349177298e-05\n",
            "Q_table[(0, 2)]_new = 2.0881357631259793e-05\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 4 step\n",
            "Delta Q = 0.9000022565881171\n",
            "Q_table[1,3]_old = 1.7780475179183595e-05\n",
            "Q_table[(1, 3)]_new = 1.8259015778265463e-05\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 5 step\n",
            "Delta Q = 0.9000030126464749\n",
            "Q_table[1,2]_old = 2.279381936363865e-05\n",
            "Q_table[(1, 2)]_new = 2.3527083902117215e-05\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 6 step\n",
            "Delta Q = 0.9000042033760206\n",
            "Q_table[2,2]_old = 3.0430772473155844e-05\n",
            "Q_table[(2, 2)]_new = 3.159107124639826e-05\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 7 step\n",
            "Delta Q = 0.900026032151871\n",
            "Q_table[3,1]_old = 4.245834364200001e-05\n",
            "Q_table[(3, 1)]_new = 6.42446611488e-05\n",
            "We are on 3 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 8 step\n",
            "Delta Q = 0.9\n",
            "Q_table[8,1]_old = 0.0\n",
            "Q_table[(8, 1)]_new = 0.0\n",
            "We are on 8 state\n",
            "And now we are on 13 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 974 episode and 0 step\n",
            "Delta Q = 0.9000020672544056\n",
            "Q_table[0,0]_old = 1.880374487628926e-05\n",
            "Q_table[(0, 0)]_new = 1.8990624794155055e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 974 episode and 1 step\n",
            "Delta Q = 0.9000023291813063\n",
            "Q_table[0,2]_old = 2.0881357631259793e-05\n",
            "Q_table[(0, 2)]_new = 2.1122403174443418e-05\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 974 episode and 2 step\n",
            "Delta Q = 0.9000020911179143\n",
            "Q_table[1,0]_old = 1.5660054004012256e-05\n",
            "Q_table[(1, 0)]_new = 1.6185166517880927e-05\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 974 episode and 3 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 975 episode and 0 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 976 episode and 0 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 977 episode and 0 step\n",
            "Delta Q = 0.9000023291813063\n",
            "Q_table[0,2]_old = 2.1122403174443418e-05\n",
            "Q_table[(0, 2)]_new = 2.133934416330868e-05\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 977 episode and 1 step\n",
            "Delta Q = 0.9000031275160534\n",
            "Q_table[1,2]_old = 2.3527083902117215e-05\n",
            "Q_table[(1, 2)]_new = 2.430189156529892e-05\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 977 episode and 2 step\n",
            "Delta Q = 0.900002405887265\n",
            "Q_table[2,0]_old = 9.87399489054221e-06\n",
            "Q_table[(2, 0)]_new = 1.1292482666452582e-05\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 977 episode and 3 step\n",
            "Delta Q = 0.900002405887265\n",
            "Q_table[1,3]_old = 1.8259015778265463e-05\n",
            "Q_table[(1, 3)]_new = 1.883900146540351e-05\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 977 episode and 4 step\n",
            "Delta Q = 0.9000021125950722\n",
            "Q_table[1,0]_old = 1.6185166517880927e-05\n",
            "Q_table[(1, 0)]_new = 1.6679244938260393e-05\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 977 episode and 5 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 978 episode and 0 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 979 episode and 0 step\n",
            "Delta Q = 0.9000021125950722\n",
            "Q_table[0,3]_old = 1.8545235924024833e-05\n",
            "Q_table[(0, 3)]_new = 1.880330740378991e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 979 episode and 1 step\n",
            "Delta Q = 0.9000021125950722\n",
            "Q_table[0,0]_old = 1.8990624794155055e-05\n",
            "Q_table[(0, 0)]_new = 1.920415738690711e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 979 episode and 2 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 980 episode and 0 step\n",
            "Delta Q = 0.9000021125950722\n",
            "Q_table[0,3]_old = 1.880330740378991e-05\n",
            "Q_table[(0, 3)]_new = 1.9035571735578477e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 980 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 981 episode and 0 step\n",
            "Delta Q = 0.900002405887265\n",
            "Q_table[0,2]_old = 2.133934416330868e-05\n",
            "Q_table[(0, 2)]_new = 2.1611297011942405e-05\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 981 episode and 1 step\n",
            "Delta Q = 0.9000021395184042\n",
            "Q_table[1,0]_old = 1.6679244938260393e-05\n",
            "Q_table[(1, 0)]_new = 1.715083884861665e-05\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 981 episode and 2 step\n",
            "Delta Q = 0.9000021395184042\n",
            "Q_table[0,3]_old = 1.9035571735578477e-05\n",
            "Q_table[(0, 3)]_new = 1.927153296620293e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 981 episode and 3 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 982 episode and 0 step\n",
            "Delta Q = 0.9000021395184042\n",
            "Q_table[0,0]_old = 1.920415738690711e-05\n",
            "Q_table[(0, 0)]_new = 1.9423260052398696e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 982 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 983 episode and 0 step\n",
            "Delta Q = 0.9000021395184042\n",
            "Q_table[0,3]_old = 1.927153296620293e-05\n",
            "Q_table[(0, 3)]_new = 1.9483898073764934e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 983 episode and 1 step\n",
            "Delta Q = 0.900002405887265\n",
            "Q_table[0,2]_old = 2.1611297011942405e-05\n",
            "Q_table[(0, 2)]_new = 2.1856054575712756e-05\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 983 episode and 2 step\n",
            "Delta Q = 0.900002163749403\n",
            "Q_table[1,0]_old = 1.715083884861665e-05\n",
            "Q_table[(1, 0)]_new = 1.759950436675055e-05\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 983 episode and 3 step\n",
            "Delta Q = 0.900002163749403\n",
            "Q_table[0,3]_old = 1.9483898073764934e-05\n",
            "Q_table[(0, 3)]_new = 1.9699257669384004e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 983 episode and 4 step\n",
            "Delta Q = 0.900002163749403\n",
            "Q_table[0,3]_old = 1.9699257669384004e-05\n",
            "Q_table[(0, 3)]_new = 1.9893081305441167e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 983 episode and 5 step\n",
            "Delta Q = 0.900002163749403\n",
            "Q_table[0,0]_old = 1.9423260052398696e-05\n",
            "Q_table[(0, 0)]_new = 1.964468345015439e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 983 episode and 6 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 984 episode and 0 step\n",
            "Delta Q = 0.900002163749403\n",
            "Q_table[0,0]_old = 1.964468345015439e-05\n",
            "Q_table[(0, 0)]_new = 1.9843964508134516e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 984 episode and 1 step\n",
            "Delta Q = 0.900002163749403\n",
            "Q_table[0,3]_old = 1.9893081305441167e-05\n",
            "Q_table[(0, 3)]_new = 2.0067522577892617e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 984 episode and 2 step\n",
            "Delta Q = 0.900002405887265\n",
            "Q_table[0,2]_old = 2.1856054575712756e-05\n",
            "Q_table[(0, 2)]_new = 2.2076336383106072e-05\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 984 episode and 3 step\n",
            "Delta Q = 0.9000021855573019\n",
            "Q_table[1,0]_old = 1.759950436675055e-05\n",
            "Q_table[(1, 0)]_new = 1.8025111232002993e-05\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 984 episode and 4 step\n",
            "Delta Q = 0.9000021855573019\n",
            "Q_table[0,0]_old = 1.9843964508134516e-05\n",
            "Q_table[(0, 0)]_new = 2.0045125359248564e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 984 episode and 5 step\n",
            "Delta Q = 0.9000021855573019\n",
            "Q_table[0,0]_old = 2.0045125359248564e-05\n",
            "Q_table[(0, 0)]_new = 2.022617012525121e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 984 episode and 6 step\n",
            "Delta Q = 0.9000021855573019\n",
            "Q_table[0,0]_old = 2.022617012525121e-05\n",
            "Q_table[(0, 0)]_new = 2.038911041465359e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 984 episode and 7 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 985 episode and 0 step\n",
            "Delta Q = 0.9000021855573019\n",
            "Q_table[0,0]_old = 2.038911041465359e-05\n",
            "Q_table[(0, 0)]_new = 2.0535756675115732e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 985 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 0 step\n",
            "Delta Q = 0.9000021855573019\n",
            "Q_table[0,3]_old = 2.0067522577892617e-05\n",
            "Q_table[(0, 3)]_new = 2.0246327622030856e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 1 step\n",
            "Delta Q = 0.900002405887265\n",
            "Q_table[0,2]_old = 2.2076336383106072e-05\n",
            "Q_table[(0, 2)]_new = 2.2274590009760057e-05\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 2 step\n",
            "Delta Q = 0.900002405887265\n",
            "Q_table[1,3]_old = 1.883900146540351e-05\n",
            "Q_table[(1, 3)]_new = 1.9360988583827752e-05\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 3 step\n",
            "Delta Q = 0.9000031275160534\n",
            "Q_table[1,2]_old = 2.430189156529892e-05\n",
            "Q_table[(1, 2)]_new = 2.4999218462162456e-05\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 4 step\n",
            "Delta Q = 0.9000024749226277\n",
            "Q_table[2,0]_old = 1.1292482666452582e-05\n",
            "Q_table[(2, 0)]_new = 1.2638157027561408e-05\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 5 step\n",
            "Delta Q = 0.9000031275160534\n",
            "Q_table[1,2]_old = 2.4999218462162456e-05\n",
            "Q_table[(1, 2)]_new = 2.5626812669339637e-05\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 6 step\n",
            "Delta Q = 0.9000063602214537\n",
            "Q_table[2,2]_old = 3.159107124639826e-05\n",
            "Q_table[(2, 2)]_new = 3.479218557548964e-05\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 7 step\n",
            "Delta Q = 0.900026032151871\n",
            "Q_table[3,1]_old = 6.42446611488e-05\n",
            "Q_table[(3, 1)]_new = 8.385234690492e-05\n",
            "We are on 3 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 8 step\n",
            "Delta Q = 0.9\n",
            "Q_table[8,0]_old = 0.0\n",
            "Q_table[(8, 0)]_new = 0.0\n",
            "We are on 8 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 987 episode and 0 step\n",
            "Delta Q = 0.9000025370544543\n",
            "Q_table[0,2]_old = 2.2274590009760057e-05\n",
            "Q_table[(0, 2)]_new = 2.2584185463048676e-05\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 987 episode and 1 step\n",
            "Delta Q = 0.9000022358343609\n",
            "Q_table[1,0]_old = 1.8025111232002993e-05\n",
            "Q_table[(1, 0)]_new = 1.845843446964451e-05\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 987 episode and 2 step\n",
            "Delta Q = 0.9000022358343609\n",
            "Q_table[0,3]_old = 2.0246327622030856e-05\n",
            "Q_table[(0, 3)]_new = 2.045752922066959e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 987 episode and 3 step\n",
            "Delta Q = 0.9000022358343609\n",
            "Q_table[0,0]_old = 2.0535756675115732e-05\n",
            "Q_table[(0, 0)]_new = 2.0718015368445978e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 987 episode and 4 step\n",
            "Delta Q = 0.9000022358343609\n",
            "Q_table[0,3]_old = 2.045752922066959e-05\n",
            "Q_table[(0, 3)]_new = 2.064761065944445e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 987 episode and 5 step\n",
            "Delta Q = 0.9000022358343609\n",
            "Q_table[0,3]_old = 2.064761065944445e-05\n",
            "Q_table[(0, 3)]_new = 2.0818683954341825e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 987 episode and 6 step\n",
            "Delta Q = 0.9000022358343609\n",
            "Q_table[0,0]_old = 2.0718015368445978e-05\n",
            "Q_table[(0, 0)]_new = 2.0882048192443198e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 987 episode and 7 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 988 episode and 0 step\n",
            "Delta Q = 0.9000022358343609\n",
            "Q_table[0,0]_old = 2.0882048192443198e-05\n",
            "Q_table[(0, 0)]_new = 2.1029677734040697e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 988 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 989 episode and 0 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 990 episode and 0 step\n",
            "Delta Q = 0.9000022358343609\n",
            "Q_table[0,0]_old = 2.1029677734040697e-05\n",
            "Q_table[(0, 0)]_new = 2.1162544321478446e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 990 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 0 step\n",
            "Delta Q = 0.9000022358343609\n",
            "Q_table[0,3]_old = 2.0818683954341825e-05\n",
            "Q_table[(0, 3)]_new = 2.0972649919749462e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 1 step\n",
            "Delta Q = 0.9000022358343609\n",
            "Q_table[0,0]_old = 2.1162544321478446e-05\n",
            "Q_table[(0, 0)]_new = 2.128212425017242e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 2 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 992 episode and 0 step\n",
            "Delta Q = 0.9000025370544543\n",
            "Q_table[0,2]_old = 2.2584185463048676e-05\n",
            "Q_table[(0, 2)]_new = 2.2862821371008432e-05\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 992 episode and 1 step\n",
            "Delta Q = 0.9000022634193158\n",
            "Q_table[1,0]_old = 1.845843446964451e-05\n",
            "Q_table[(1, 0)]_new = 1.8876010338409897e-05\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 992 episode and 2 step\n",
            "Delta Q = 0.9000022634193158\n",
            "Q_table[0,0]_old = 2.128212425017242e-05\n",
            "Q_table[(0, 0)]_new = 2.1417331140885015e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 992 episode and 3 step\n",
            "Delta Q = 0.9000022634193158\n",
            "Q_table[0,0]_old = 2.1417331140885015e-05\n",
            "Q_table[(0, 0)]_new = 2.153901734252635e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 992 episode and 4 step\n",
            "Delta Q = 0.9000025370544543\n",
            "Q_table[0,2]_old = 2.2862821371008432e-05\n",
            "Q_table[(0, 2)]_new = 2.3113593688172212e-05\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 992 episode and 5 step\n",
            "Delta Q = 0.9000022882457751\n",
            "Q_table[1,0]_old = 1.8876010338409897e-05\n",
            "Q_table[(1, 0)]_new = 1.9276655079697955e-05\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 992 episode and 6 step\n",
            "Delta Q = 0.9000022882457751\n",
            "Q_table[0,3]_old = 2.0972649919749462e-05\n",
            "Q_table[(0, 3)]_new = 2.1163630702903566e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 992 episode and 7 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 993 episode and 0 step\n",
            "Delta Q = 0.9000025370544543\n",
            "Q_table[0,2]_old = 2.3113593688172212e-05\n",
            "Q_table[(0, 2)]_new = 2.3339288773619615e-05\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 993 episode and 1 step\n",
            "Delta Q = 0.9000023105895886\n",
            "Q_table[1,0]_old = 1.9276655079697955e-05\n",
            "Q_table[(1, 0)]_new = 1.9659579160316503e-05\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 993 episode and 2 step\n",
            "Delta Q = 0.9000025370544543\n",
            "Q_table[0,2]_old = 2.3339288773619615e-05\n",
            "Q_table[(0, 2)]_new = 2.354241435052228e-05\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 993 episode and 3 step\n",
            "Delta Q = 0.9000025370544543\n",
            "Q_table[1,3]_old = 1.9360988583827752e-05\n",
            "Q_table[(1, 3)]_new = 1.9961944179709603e-05\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 993 episode and 4 step\n",
            "Delta Q = 0.900003444426372\n",
            "Q_table[1,2]_old = 2.5626812669339637e-05\n",
            "Q_table[(1, 2)]_new = 2.650855777437915e-05\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 993 episode and 5 step\n",
            "Delta Q = 0.900003444426372\n",
            "Q_table[2,3]_old = 1.8018970581198334e-05\n",
            "Q_table[(2, 3)]_new = 1.9661499895051975e-05\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 993 episode and 6 step\n",
            "Delta Q = 0.9\n",
            "Q_table[2,1]_old = 0.0\n",
            "Q_table[(2, 1)]_new = 0.0\n",
            "We are on 2 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 994 episode and 0 step\n",
            "Delta Q = 0.9000026243472197\n",
            "Q_table[0,2]_old = 2.354241435052228e-05\n",
            "Q_table[(0, 2)]_new = 2.3812520135133587e-05\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 994 episode and 1 step\n",
            "Delta Q = 0.9000026243472197\n",
            "Q_table[1,3]_old = 1.9961944179709603e-05\n",
            "Q_table[(1, 3)]_new = 2.0590096981402182e-05\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 994 episode and 2 step\n",
            "Delta Q = 0.9000026243472197\n",
            "Q_table[1,3]_old = 2.0590096981402182e-05\n",
            "Q_table[(1, 3)]_new = 2.1155434502925498e-05\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 994 episode and 3 step\n",
            "Delta Q = 0.900003444426372\n",
            "Q_table[1,2]_old = 2.650855777437915e-05\n",
            "Q_table[(1, 2)]_new = 2.730212836891471e-05\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 994 episode and 4 step\n",
            "Delta Q = 0.900003444426372\n",
            "Q_table[2,3]_old = 1.9661499895051975e-05\n",
            "Q_table[(2, 3)]_new = 2.1139776277520253e-05\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 994 episode and 5 step\n",
            "Delta Q = 0.9000027029107085\n",
            "Q_table[2,0]_old = 1.2638157027561408e-05\n",
            "Q_table[(2, 0)]_new = 1.4077252033327824e-05\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 994 episode and 6 step\n",
            "Delta Q = 0.900003444426372\n",
            "Q_table[1,2]_old = 2.730212836891471e-05\n",
            "Q_table[(1, 2)]_new = 2.8016341903996716e-05\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 994 episode and 7 step\n",
            "Delta Q = 0.900003444426372\n",
            "Q_table[2,3]_old = 2.1139776277520253e-05\n",
            "Q_table[(2, 3)]_new = 2.2470225021741705e-05\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 994 episode and 8 step\n",
            "Delta Q = 0.9000027736178485\n",
            "Q_table[2,0]_old = 1.4077252033327824e-05\n",
            "Q_table[(2, 0)]_new = 1.544314467849072e-05\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 994 episode and 9 step\n",
            "Delta Q = 0.9000023574394934\n",
            "Q_table[1,0]_old = 1.9659579160316503e-05\n",
            "Q_table[(1, 0)]_new = 2.005106073766308e-05\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 994 episode and 10 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 995 episode and 0 step\n",
            "Delta Q = 0.9000023574394934\n",
            "Q_table[0,3]_old = 2.1163630702903566e-05\n",
            "Q_table[(0, 3)]_new = 2.1404707125991436e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 995 episode and 1 step\n",
            "Delta Q = 0.9000023574394934\n",
            "Q_table[0,3]_old = 2.1404707125991436e-05\n",
            "Q_table[(0, 3)]_new = 2.1621675906770517e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 995 episode and 2 step\n",
            "Delta Q = 0.9000023574394934\n",
            "Q_table[0,0]_old = 2.153901734252635e-05\n",
            "Q_table[(0, 0)]_new = 2.174255510165194e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 995 episode and 3 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 996 episode and 0 step\n",
            "Delta Q = 0.9000027736178485\n",
            "Q_table[0,2]_old = 2.3812520135133587e-05\n",
            "Q_table[(0, 2)]_new = 2.4204885970115903e-05\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 996 episode and 1 step\n",
            "Delta Q = 0.9000027736178485\n",
            "Q_table[1,3]_old = 2.1155434502925498e-05\n",
            "Q_table[(1, 3)]_new = 2.1813508901128624e-05\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 996 episode and 2 step\n",
            "Delta Q = 0.900003444426372\n",
            "Q_table[1,2]_old = 2.8016341903996716e-05\n",
            "Q_table[(1, 2)]_new = 2.865913408557052e-05\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 996 episode and 3 step\n",
            "Delta Q = 0.9000028372542745\n",
            "Q_table[2,0]_old = 1.544314467849072e-05\n",
            "Q_table[(2, 0)]_new = 1.673608448511313e-05\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 996 episode and 4 step\n",
            "Delta Q = 0.900002396283711\n",
            "Q_table[1,0]_old = 2.005106073766308e-05\n",
            "Q_table[(1, 0)]_new = 2.0442238374938246e-05\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 996 episode and 5 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 997 episode and 0 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 998 episode and 0 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 999 episode and 0 step\n",
            "Delta Q = 0.900002396283711\n",
            "Q_table[0,0]_old = 2.174255510165194e-05\n",
            "Q_table[(0, 0)]_new = 2.1964583302528222e-05\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 999 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[0,1]_old = 0.0\n",
            "Q_table[(0, 1)]_new = 0.0\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imageio imageio_ffmpeg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j45ghrMbmYMW",
        "outputId": "090dd1fa-6224-4f69-b7b4-7759cfa6e27f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (2.31.6)\n",
            "Requirement already satisfied: imageio_ffmpeg in /usr/local/lib/python3.10/dist-packages (0.4.9)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from imageio) (1.25.2)\n",
            "Requirement already satisfied: pillow<10.1.0,>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio) (9.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio_ffmpeg) (67.7.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import imageio"
      ],
      "metadata": {
        "id": "NKpgHiejml6h"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def record_video(env, q_table, out_directory, fps=1):\n",
        "  images = []\n",
        "  done = False\n",
        "  state = env.reset(seed=random.randint(0,500))\n",
        "  img = env.render(mode='rgb_array')\n",
        "  images.append(img)\n",
        "  while not done:\n",
        "    # Take the action (index) that have the maximum expected future reward given that state\n",
        "    action = np.argmax(q_table[state][:])\n",
        "    state, reward, done, info = env.step(action) # We directly put next_state = state for recording logic\n",
        "    img = env.render(mode='rgb_array')\n",
        "    images.append(img)\n",
        "  imageio.mimsave(out_directory, [np.array(img) for i, img in enumerate(images)], fps=fps)"
      ],
      "metadata": {
        "id": "Vi8Mq4tEl4Yb"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_path=\"/content/replay.gif\"\n",
        "video_fps=1\n",
        "record_video(env, q_table, video_path, video_fps)\n",
        "\n",
        "from IPython.display import Image\n",
        "Image('./replay.gif')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "turRjFNxmFal",
        "outputId": "c1292929-2559-4460-ae9a-90f757ae8148"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/imageio/plugins/pillow.py:390: DeprecationWarning: The keyword `fps` is no longer supported. Use `duration`(in ms) instead, e.g. `fps=50` == `duration=20` (1000 * 1/50).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/gif": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    }
  ]
}