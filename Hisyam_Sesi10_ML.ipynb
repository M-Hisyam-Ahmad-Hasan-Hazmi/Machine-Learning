{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/M-Hisyam-Ahmad-Hasan-Hazmi/Machine-Learning/blob/main/Hisyam_Sesi10_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "v2Bw_wXXQKaf"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install pyglet==1.5.1\n",
        "!apt install python-opengl\n",
        "!apt install ffmpeg\n",
        "!apt install xvfb\n",
        "!pip3 install pyvirtualdisplay\n",
        "\n",
        "# Virtual display\n",
        "from pyvirtualdisplay import Display\n",
        "\n",
        "virtual_display = Display(visible=0, size=(1400, 900))\n",
        "virtual_display.start()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install gym==0.24\n",
        "!pip install pygame\n",
        "!pip install numpy\n",
        "\n",
        "!pip install imageio imageio_ffmpeg"
      ],
      "metadata": {
        "id": "oYbPDSFYQhwd"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import gym\n",
        "import random\n",
        "import time"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twtBNh1WQ3EF",
        "outputId": "985db2d4-7cf9-4b11-e190-170083f93977"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning: Gym version v0.24.0 has a number of critical issues with `gym.make` such that the `reset` and `step` functions are called before returning the environment. It is recommend to downgrading to v0.23.1 or upgrading to v0.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_map = [\n",
        "    \"SFFFF\",\n",
        "    \"FHFHH\",\n",
        "    \"FFFHH\",\n",
        "    \"HFFFG\"\n",
        "]\n",
        "\n",
        "env = gym.make('FrozenLake-v1', desc=my_map, is_slippery=False)\n",
        "env.render()\n",
        "env.reset()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-hUKLnhQ_pf",
        "outputId": "b8adba38-b4b2-4a75-ec17-378d160523f2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "action_space_size = env.action_space.n\n",
        "state_space_size = env.observation_space.n\n",
        "q_table = np.zeros((state_space_size, action_space_size))\n",
        "print(f'action_space_size = {action_space_size}')\n",
        "print(f'state_space_size = {state_space_size}')\n",
        "print(f'q_table = \\n{q_table}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JoAGkxOCUCej",
        "outputId": "f19084e4-6fa7-4c6d-9027-51c27eec1849"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "action_space_size = 4\n",
            "state_space_size = 20\n",
            "q_table = \n",
            "[[0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training parameters\n",
        "num_episodes = 1000\n",
        "max_steps_per_episode = 100\n",
        "learning_rate = 0.1\n",
        "discount_rate = 0.99\n",
        "\n",
        "exploration_rate =1\n",
        "max_exploration_rate = 1\n",
        "min_exploration_rate = 0.01\n",
        "exploration_decay_rate = 0.05"
      ],
      "metadata": {
        "id": "ravyEYVNVXsq"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rewards_all_episodes = []\n",
        "\n",
        "for episode in range(num_episodes):\n",
        "  state = env.reset()\n",
        "  state = 0\n",
        "  done = False\n",
        "  reward_current_episode = 0\n",
        "\n",
        "  for step in range(max_steps_per_episode):\n",
        "    exploration_rate_threshold = random.uniform(0, 1)\n",
        "    if exploration_rate_threshold > exploration_rate:\n",
        "      action = np.argmax(q_table[state, :])\n",
        "    else:\n",
        "      action = env.action_space.sample()\n",
        "\n",
        "    new_state, reward, done, info = env.step(action)\n",
        "    delta_q = ( 1 - learning_rate)+  learning_rate*(reward + discount_rate*np.max(q_table[new_state, :]))\n",
        "\n",
        "    print(f\"We are on {episode} episode and {step} step\")\n",
        "    print(f\"Delta Q = {delta_q}\")\n",
        "    print(f\"Q_table[{state},{action}]_old = {q_table[state, action]}\")\n",
        "\n",
        "    q_table[state, action] = q_table[state, action]*(1 - learning_rate)+\\\n",
        "                            learning_rate*(reward+discount_rate*np.max(q_table[new_state, :]))\n",
        "    print(f\"Q_table[{state, action}]_new = {q_table[state, action]}\")\n",
        "    print(f\"We are on {state} state\")\n",
        "    state = new_state\n",
        "    print(f\"And now we are on {state} state\")\n",
        "    reward_current_episode+= reward\n",
        "    print(f\"We get {reward} reward \")\n",
        "    print(f\"exploration_rate = {exploration_rate}\\n\")\n",
        "\n",
        "    if done == True:\n",
        "        break\n",
        "\n",
        "exploration_rate = min_exploration_rate +\\\n",
        "                 (max_exploration_rate - min_exploration_rate)*np.exp(-exploration_decay_rate*episode)\n",
        "rewards_all_episodes.append(reward_current_episode)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nr48_17XqBk",
        "outputId": "4993505c-3dce-423d-cadb-cec256041771",
        "collapsed": true
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 935 episode and 2 step\n",
            "Delta Q = 0.9037642797178409\n",
            "Q_table[0,2]_old = 0.03629647895753067\n",
            "Q_table[(0, 2)]_new = 0.03643111077961847\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 935 episode and 3 step\n",
            "Delta Q = 0.9\n",
            "Q_table[1,1]_old = 0.0\n",
            "Q_table[(1, 1)]_new = 0.0\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 936 episode and 0 step\n",
            "Delta Q = 0.9031369782736823\n",
            "Q_table[0,1]_old = 0.029944341019178713\n",
            "Q_table[(0, 1)]_new = 0.030086885190943102\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 936 episode and 1 step\n",
            "Delta Q = 0.9036066799671822\n",
            "Q_table[5,3]_old = 0.031686649229113725\n",
            "Q_table[(5, 3)]_new = 0.03212466427338458\n",
            "We are on 5 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 936 episode and 2 step\n",
            "Delta Q = 0.903180341763065\n",
            "Q_table[0,1]_old = 0.030086885190943102\n",
            "Q_table[(0, 1)]_new = 0.030258538434913867\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 936 episode and 3 step\n",
            "Delta Q = 0.9036066799671822\n",
            "Q_table[5,3]_old = 0.03212466427338458\n",
            "Q_table[(5, 3)]_new = 0.032518877813228354\n",
            "We are on 5 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 936 episode and 4 step\n",
            "Delta Q = 0.9036066799671822\n",
            "Q_table[0,0]_old = 0.0346390360772566\n",
            "Q_table[(0, 0)]_new = 0.034781812436713175\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 936 episode and 5 step\n",
            "Delta Q = 0.9037642797178409\n",
            "Q_table[0,2]_old = 0.03643111077961847\n",
            "Q_table[(0, 2)]_new = 0.03655227941949749\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 936 episode and 6 step\n",
            "Delta Q = 0.9037642797178409\n",
            "Q_table[1,3]_old = 0.03233298853161547\n",
            "Q_table[(1, 3)]_new = 0.03286396939629478\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 936 episode and 7 step\n",
            "Delta Q = 0.9036186756625303\n",
            "Q_table[1,0]_old = 0.029559565772281585\n",
            "Q_table[(1, 0)]_new = 0.03022228485758368\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 936 episode and 8 step\n",
            "Delta Q = 0.9036186756625303\n",
            "Q_table[0,0]_old = 0.034781812436713175\n",
            "Q_table[(0, 0)]_new = 0.03492230685557211\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 936 episode and 9 step\n",
            "Delta Q = 0.9037642797178409\n",
            "Q_table[0,2]_old = 0.03655227941949749\n",
            "Q_table[(0, 2)]_new = 0.036661331195388606\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 936 episode and 10 step\n",
            "Delta Q = 0.9036294717883435\n",
            "Q_table[1,0]_old = 0.03022228485758368\n",
            "Q_table[(1, 0)]_new = 0.030829528160168786\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 936 episode and 11 step\n",
            "Delta Q = 0.9037642797178409\n",
            "Q_table[0,2]_old = 0.036661331195388606\n",
            "Q_table[(0, 2)]_new = 0.03675947779369061\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 936 episode and 12 step\n",
            "Delta Q = 0.9041728359034157\n",
            "Q_table[1,2]_old = 0.038023027452938014\n",
            "Q_table[(1, 2)]_new = 0.03839356061105984\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 936 episode and 13 step\n",
            "Delta Q = 0.9049153436965169\n",
            "Q_table[2,1]_old = 0.04214985761025886\n",
            "Q_table[(2, 1)]_new = 0.042850215545749866\n",
            "We are on 2 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 936 episode and 14 step\n",
            "Delta Q = 0.9\n",
            "Q_table[7,0]_old = 0.0\n",
            "Q_table[(7, 0)]_new = 0.0\n",
            "We are on 7 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 937 episode and 0 step\n",
            "Delta Q = 0.9032193689035096\n",
            "Q_table[0,1]_old = 0.030258538434913867\n",
            "Q_table[(0, 1)]_new = 0.030452053494932088\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 937 episode and 1 step\n",
            "Delta Q = 0.9032049155030526\n",
            "Q_table[5,1]_old = 0.026103172766950244\n",
            "Q_table[(5, 1)]_new = 0.02669777099330784\n",
            "We are on 5 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 937 episode and 2 step\n",
            "Delta Q = 0.9\n",
            "Q_table[10,1]_old = 0.0\n",
            "Q_table[(10, 1)]_new = 0.0\n",
            "We are on 10 state\n",
            "And now we are on 15 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 938 episode and 0 step\n",
            "Delta Q = 0.9036391883015754\n",
            "Q_table[0,3]_old = 0.03470211884118618\n",
            "Q_table[(0, 3)]_new = 0.03487109525864293\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 938 episode and 1 step\n",
            "Delta Q = 0.9036391883015754\n",
            "Q_table[0,3]_old = 0.03487109525864293\n",
            "Q_table[(0, 3)]_new = 0.03502317403435401\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 938 episode and 2 step\n",
            "Delta Q = 0.9038009625004949\n",
            "Q_table[0,2]_old = 0.03675947779369061\n",
            "Q_table[(0, 2)]_new = 0.03688449251481647\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 938 episode and 3 step\n",
            "Delta Q = 0.9\n",
            "Q_table[1,1]_old = 0.0\n",
            "Q_table[(1, 1)]_new = 0.0\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 939 episode and 0 step\n",
            "Delta Q = 0.9036515647589669\n",
            "Q_table[0,0]_old = 0.03492230685557211\n",
            "Q_table[(0, 0)]_new = 0.035081640928981736\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 939 episode and 1 step\n",
            "Delta Q = 0.9032193689035096\n",
            "Q_table[0,1]_old = 0.030452053494932088\n",
            "Q_table[(0, 1)]_new = 0.03062621704894849\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 939 episode and 2 step\n",
            "Delta Q = 0.9\n",
            "Q_table[5,2]_old = 0.0\n",
            "Q_table[(5, 2)]_new = 0.0\n",
            "We are on 5 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 940 episode and 0 step\n",
            "Delta Q = 0.9036515647589669\n",
            "Q_table[0,3]_old = 0.03502317403435401\n",
            "Q_table[(0, 3)]_new = 0.03517242138988544\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 940 episode and 1 step\n",
            "Delta Q = 0.9032193689035096\n",
            "Q_table[0,1]_old = 0.03062621704894849\n",
            "Q_table[(0, 1)]_new = 0.030782964247563247\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 940 episode and 2 step\n",
            "Delta Q = 0.9036515647589669\n",
            "Q_table[5,3]_old = 0.032518877813228354\n",
            "Q_table[(5, 3)]_new = 0.03291855479087235\n",
            "We are on 5 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 940 episode and 3 step\n",
            "Delta Q = 0.9032589369242964\n",
            "Q_table[0,1]_old = 0.030782964247563247\n",
            "Q_table[(0, 1)]_new = 0.030963604747103284\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 940 episode and 4 step\n",
            "Delta Q = 0.9032589369242964\n",
            "Q_table[5,0]_old = 0.02590053053287054\n",
            "Q_table[(5, 0)]_new = 0.02656941440387985\n",
            "We are on 5 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 940 episode and 5 step\n",
            "Delta Q = 0.9036515647589669\n",
            "Q_table[5,3]_old = 0.03291855479087235\n",
            "Q_table[(5, 3)]_new = 0.03327826407075195\n",
            "We are on 5 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 940 episode and 6 step\n",
            "Delta Q = 0.9036515647589669\n",
            "Q_table[0,0]_old = 0.035081640928981736\n",
            "Q_table[(0, 0)]_new = 0.035225041595050396\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 940 episode and 7 step\n",
            "Delta Q = 0.9036515647589669\n",
            "Q_table[0,0]_old = 0.035225041595050396\n",
            "Q_table[(0, 0)]_new = 0.03535410219451219\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 940 episode and 8 step\n",
            "Delta Q = 0.9032945481430045\n",
            "Q_table[0,1]_old = 0.030963604747103284\n",
            "Q_table[(0, 1)]_new = 0.031161792415397398\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 940 episode and 9 step\n",
            "Delta Q = 0.9032945481430045\n",
            "Q_table[5,0]_old = 0.02656941440387985\n",
            "Q_table[(5, 0)]_new = 0.027207021106496306\n",
            "We are on 5 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 940 episode and 10 step\n",
            "Delta Q = 0.9\n",
            "Q_table[5,2]_old = 0.0\n",
            "Q_table[(5, 2)]_new = 0.0\n",
            "We are on 5 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 941 episode and 0 step\n",
            "Delta Q = 0.9032945481430045\n",
            "Q_table[0,1]_old = 0.031161792415397398\n",
            "Q_table[(0, 1)]_new = 0.0313401613168621\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 941 episode and 1 step\n",
            "Delta Q = 0.9036515647589669\n",
            "Q_table[5,3]_old = 0.03327826407075195\n",
            "Q_table[(5, 3)]_new = 0.033602002422643586\n",
            "We are on 5 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 941 episode and 2 step\n",
            "Delta Q = 0.9036515647589669\n",
            "Q_table[0,0]_old = 0.03535410219451219\n",
            "Q_table[(0, 0)]_new = 0.0354702567340278\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 941 episode and 3 step\n",
            "Delta Q = 0.9036515647589669\n",
            "Q_table[0,0]_old = 0.0354702567340278\n",
            "Q_table[(0, 0)]_new = 0.03557479581959185\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 941 episode and 4 step\n",
            "Delta Q = 0.9036515647589669\n",
            "Q_table[0,0]_old = 0.03557479581959185\n",
            "Q_table[(0, 0)]_new = 0.0356688809965995\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 941 episode and 5 step\n",
            "Delta Q = 0.9036515647589669\n",
            "Q_table[0,0]_old = 0.0356688809965995\n",
            "Q_table[(0, 0)]_new = 0.035753557655906376\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 941 episode and 6 step\n",
            "Delta Q = 0.9033265982398417\n",
            "Q_table[0,1]_old = 0.0313401613168621\n",
            "Q_table[(0, 1)]_new = 0.0315327434250176\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 941 episode and 7 step\n",
            "Delta Q = 0.9036515647589669\n",
            "Q_table[5,3]_old = 0.033602002422643586\n",
            "Q_table[(5, 3)]_new = 0.03389336693934606\n",
            "We are on 5 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 941 episode and 8 step\n",
            "Delta Q = 0.9036515647589669\n",
            "Q_table[0,0]_old = 0.035753557655906376\n",
            "Q_table[(0, 0)]_new = 0.03582976664928257\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 941 episode and 9 step\n",
            "Delta Q = 0.9033554433269952\n",
            "Q_table[0,1]_old = 0.0315327434250176\n",
            "Q_table[(0, 1)]_new = 0.031734912409511096\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 941 episode and 10 step\n",
            "Delta Q = 0.9032049155030526\n",
            "Q_table[5,1]_old = 0.02669777099330784\n",
            "Q_table[(5, 1)]_new = 0.02723290939702968\n",
            "We are on 5 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 941 episode and 11 step\n",
            "Delta Q = 0.9042701386104588\n",
            "Q_table[10,2]_old = 0.03237288386921841\n",
            "Q_table[(10, 2)]_new = 0.03340573409275538\n",
            "We are on 10 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 941 episode and 12 step\n",
            "Delta Q = 0.9075108772483897\n",
            "Q_table[11,2]_old = 0.04313271323695765\n",
            "Q_table[(11, 2)]_new = 0.046330319161651645\n",
            "We are on 11 state\n",
            "And now we are on 12 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 941 episode and 13 step\n",
            "Delta Q = 0.9\n",
            "Q_table[12,2]_old = 0.0\n",
            "Q_table[(12, 2)]_new = 0.0\n",
            "We are on 12 state\n",
            "And now we are on 13 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 942 episode and 0 step\n",
            "Delta Q = 0.9033554433269952\n",
            "Q_table[0,1]_old = 0.031734912409511096\n",
            "Q_table[(0, 1)]_new = 0.031916864495555246\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 942 episode and 1 step\n",
            "Delta Q = 0.9033071676751828\n",
            "Q_table[5,1]_old = 0.02723290939702968\n",
            "Q_table[(5, 1)]_new = 0.027816786132509493\n",
            "We are on 5 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 942 episode and 2 step\n",
            "Delta Q = 0.9\n",
            "Q_table[10,1]_old = 0.0\n",
            "Q_table[(10, 1)]_new = 0.0\n",
            "We are on 10 state\n",
            "And now we are on 15 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 943 episode and 0 step\n",
            "Delta Q = 0.9038009625004949\n",
            "Q_table[0,2]_old = 0.03688449251481647\n",
            "Q_table[(0, 2)]_new = 0.03699700576382975\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 943 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[1,1]_old = 0.0\n",
            "Q_table[(1, 1)]_new = 0.0\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 944 episode and 0 step\n",
            "Delta Q = 0.9033554433269952\n",
            "Q_table[0,1]_old = 0.031916864495555246\n",
            "Q_table[(0, 1)]_new = 0.03208062137299498\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 944 episode and 1 step\n",
            "Delta Q = 0.9033554433269952\n",
            "Q_table[5,0]_old = 0.027207021106496306\n",
            "Q_table[(5, 0)]_new = 0.027841762322841936\n",
            "We are on 5 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 944 episode and 2 step\n",
            "Delta Q = 0.9033554433269952\n",
            "Q_table[5,0]_old = 0.027841762322841936\n",
            "Q_table[(5, 0)]_new = 0.028413029417553002\n",
            "We are on 5 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 944 episode and 3 step\n",
            "Delta Q = 0.9\n",
            "Q_table[5,2]_old = 0.0\n",
            "Q_table[(5, 2)]_new = 0.0\n",
            "We are on 5 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 945 episode and 0 step\n",
            "Delta Q = 0.9038009625004949\n",
            "Q_table[0,2]_old = 0.03699700576382975\n",
            "Q_table[(0, 2)]_new = 0.037098267687941694\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 945 episode and 1 step\n",
            "Delta Q = 0.9042421713390293\n",
            "Q_table[1,2]_old = 0.03839356061105984\n",
            "Q_table[(1, 2)]_new = 0.038796375888983096\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 945 episode and 2 step\n",
            "Delta Q = 0.9042421713390293\n",
            "Q_table[2,3]_old = 0.03114829594868285\n",
            "Q_table[(2, 3)]_new = 0.0322756376928438\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 945 episode and 3 step\n",
            "Delta Q = 0.902115436934708\n",
            "Q_table[2,2]_old = 0.014725596605965152\n",
            "Q_table[(2, 2)]_new = 0.015368473880076547\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 945 episode and 4 step\n",
            "Delta Q = 0.9042421713390293\n",
            "Q_table[3,0]_old = 0.021368049845534448\n",
            "Q_table[(3, 0)]_new = 0.02347341620001024\n",
            "We are on 3 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 945 episode and 5 step\n",
            "Delta Q = 0.9042421713390293\n",
            "Q_table[2,3]_old = 0.0322756376928438\n",
            "Q_table[(2, 3)]_new = 0.033290245262588655\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 945 episode and 6 step\n",
            "Delta Q = 0.9023238682038011\n",
            "Q_table[2,2]_old = 0.015368473880076547\n",
            "Q_table[(2, 2)]_new = 0.016155494695869906\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 945 episode and 7 step\n",
            "Delta Q = 0.9023238682038011\n",
            "Q_table[3,3]_old = 0.010448796812163937\n",
            "Q_table[(3, 3)]_new = 0.011727785334748558\n",
            "We are on 3 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 945 episode and 8 step\n",
            "Delta Q = 0.9002784321003541\n",
            "Q_table[3,2]_old = 0.00147941709566254\n",
            "Q_table[(3, 2)]_new = 0.001609907486450327\n",
            "We are on 3 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 945 episode and 9 step\n",
            "Delta Q = 0.9002784321003541\n",
            "Q_table[4,3]_old = 0.0007281373894063826\n",
            "Q_table[(4, 3)]_new = 0.0009337557508197853\n",
            "We are on 4 state\n",
            "And now we are on 4 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 945 episode and 10 step\n",
            "Delta Q = 0.9\n",
            "Q_table[4,1]_old = 0.0\n",
            "Q_table[(4, 1)]_new = 0.0\n",
            "We are on 4 state\n",
            "And now we are on 9 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 946 episode and 0 step\n",
            "Delta Q = 0.9036727285011062\n",
            "Q_table[0,3]_old = 0.03517242138988544\n",
            "Q_table[(0, 3)]_new = 0.035327907752003125\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 946 episode and 1 step\n",
            "Delta Q = 0.9038408412130093\n",
            "Q_table[0,2]_old = 0.037098267687941694\n",
            "Q_table[(0, 2)]_new = 0.03722928213215686\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 946 episode and 2 step\n",
            "Delta Q = 0.9036856989310835\n",
            "Q_table[1,0]_old = 0.030829528160168786\n",
            "Q_table[(1, 0)]_new = 0.031432274275235435\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 946 episode and 3 step\n",
            "Delta Q = 0.9036856989310835\n",
            "Q_table[0,3]_old = 0.035327907752003125\n",
            "Q_table[(0, 3)]_new = 0.03548081590788634\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 946 episode and 4 step\n",
            "Delta Q = 0.9036856989310835\n",
            "Q_table[0,0]_old = 0.03582976664928257\n",
            "Q_table[(0, 0)]_new = 0.03593248891543785\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 946 episode and 5 step\n",
            "Delta Q = 0.9033554433269952\n",
            "Q_table[0,1]_old = 0.03208062137299498\n",
            "Q_table[(0, 1)]_new = 0.03222800256269074\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 946 episode and 6 step\n",
            "Delta Q = 0.9033071676751828\n",
            "Q_table[5,1]_old = 0.027816786132509493\n",
            "Q_table[(5, 1)]_new = 0.028342275194441324\n",
            "We are on 5 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 946 episode and 7 step\n",
            "Delta Q = 0.9\n",
            "Q_table[10,1]_old = 0.0\n",
            "Q_table[(10, 1)]_new = 0.0\n",
            "We are on 10 state\n",
            "And now we are on 15 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 947 episode and 0 step\n",
            "Delta Q = 0.9033554433269952\n",
            "Q_table[0,1]_old = 0.03222800256269074\n",
            "Q_table[(0, 1)]_new = 0.03236064563341692\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 947 episode and 1 step\n",
            "Delta Q = 0.9036856989310835\n",
            "Q_table[5,3]_old = 0.03389336693934606\n",
            "Q_table[(5, 3)]_new = 0.03418972917649499\n",
            "We are on 5 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 947 episode and 2 step\n",
            "Delta Q = 0.903384783188473\n",
            "Q_table[0,1]_old = 0.03236064563341692\n",
            "Q_table[(0, 1)]_new = 0.03250936425854824\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 947 episode and 3 step\n",
            "Delta Q = 0.903384783188473\n",
            "Q_table[5,0]_old = 0.028413029417553002\n",
            "Q_table[(5, 0)]_new = 0.028956509664270706\n",
            "We are on 5 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 947 episode and 4 step\n",
            "Delta Q = 0.9036856989310835\n",
            "Q_table[5,3]_old = 0.03418972917649499\n",
            "Q_table[(5, 3)]_new = 0.03445645518992902\n",
            "We are on 5 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 947 episode and 5 step\n",
            "Delta Q = 0.9036856989310835\n",
            "Q_table[0,0]_old = 0.03593248891543785\n",
            "Q_table[(0, 0)]_new = 0.036024938954977596\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 947 episode and 6 step\n",
            "Delta Q = 0.9036856989310835\n",
            "Q_table[0,0]_old = 0.036024938954977596\n",
            "Q_table[(0, 0)]_new = 0.03610814399056337\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 947 episode and 7 step\n",
            "Delta Q = 0.9038408412130093\n",
            "Q_table[0,2]_old = 0.03722928213215686\n",
            "Q_table[(0, 2)]_new = 0.037347195131950506\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 947 episode and 8 step\n",
            "Delta Q = 0.9042421713390293\n",
            "Q_table[1,2]_old = 0.038796375888983096\n",
            "Q_table[(1, 2)]_new = 0.039158909639114024\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 947 episode and 9 step\n",
            "Delta Q = 0.9042421713390293\n",
            "Q_table[2,3]_old = 0.033290245262588655\n",
            "Q_table[(2, 3)]_new = 0.034203392075359024\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 947 episode and 10 step\n",
            "Delta Q = 0.9049153436965169\n",
            "Q_table[2,1]_old = 0.042850215545749866\n",
            "Q_table[(2, 1)]_new = 0.04348053768769177\n",
            "We are on 2 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 947 episode and 11 step\n",
            "Delta Q = 0.9043045732310815\n",
            "Q_table[7,3]_old = 0.01740880063111186\n",
            "Q_table[(7, 3)]_new = 0.01997249379908216\n",
            "We are on 7 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 947 episode and 12 step\n",
            "Delta Q = 0.9038767320542723\n",
            "Q_table[2,0]_old = 0.026002939215387738\n",
            "Q_table[(2, 0)]_new = 0.027279377348121255\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 947 episode and 13 step\n",
            "Delta Q = 0.9038767320542723\n",
            "Q_table[1,3]_old = 0.03286396939629478\n",
            "Q_table[(1, 3)]_new = 0.03345430451093759\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 947 episode and 14 step\n",
            "Delta Q = 0.9038767320542723\n",
            "Q_table[1,3]_old = 0.03345430451093759\n",
            "Q_table[(1, 3)]_new = 0.033985606114116114\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 947 episode and 15 step\n",
            "Delta Q = 0.9036973723180631\n",
            "Q_table[1,0]_old = 0.031432274275235435\n",
            "Q_table[(1, 0)]_new = 0.03198641916577499\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 947 episode and 16 step\n",
            "Delta Q = 0.9036973723180631\n",
            "Q_table[0,0]_old = 0.03610814399056337\n",
            "Q_table[(0, 0)]_new = 0.03619470190957014\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 947 episode and 17 step\n",
            "Delta Q = 0.9036973723180631\n",
            "Q_table[0,3]_old = 0.03548081590788634\n",
            "Q_table[(0, 3)]_new = 0.03563010663516081\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 947 episode and 18 step\n",
            "Delta Q = 0.9036973723180631\n",
            "Q_table[0,0]_old = 0.03619470190957014\n",
            "Q_table[(0, 0)]_new = 0.036272604036676225\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 947 episode and 19 step\n",
            "Delta Q = 0.9038767320542723\n",
            "Q_table[0,2]_old = 0.037347195131950506\n",
            "Q_table[(0, 2)]_new = 0.03748920767302775\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 947 episode and 20 step\n",
            "Delta Q = 0.9\n",
            "Q_table[1,1]_old = 0.0\n",
            "Q_table[(1, 1)]_new = 0.0\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 948 episode and 0 step\n",
            "Delta Q = 0.9037114315596297\n",
            "Q_table[0,0]_old = 0.036272604036676225\n",
            "Q_table[(0, 0)]_new = 0.03635677519263835\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 948 episode and 1 step\n",
            "Delta Q = 0.9037114315596297\n",
            "Q_table[0,3]_old = 0.03563010663516081\n",
            "Q_table[(0, 3)]_new = 0.03577852753127447\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 948 episode and 2 step\n",
            "Delta Q = 0.9037114315596297\n",
            "Q_table[0,3]_old = 0.03577852753127447\n",
            "Q_table[(0, 3)]_new = 0.03591210633777677\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 948 episode and 3 step\n",
            "Delta Q = 0.9038767320542723\n",
            "Q_table[0,2]_old = 0.03748920767302775\n",
            "Q_table[(0, 2)]_new = 0.037617018959997264\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 948 episode and 4 step\n",
            "Delta Q = 0.9037240848770397\n",
            "Q_table[1,0]_old = 0.03198641916577499\n",
            "Q_table[(1, 0)]_new = 0.032511862126237225\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 948 episode and 5 step\n",
            "Delta Q = 0.9037240848770397\n",
            "Q_table[0,0]_old = 0.03635677519263835\n",
            "Q_table[(0, 0)]_new = 0.03644518255041424\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 948 episode and 6 step\n",
            "Delta Q = 0.903411189063803\n",
            "Q_table[0,1]_old = 0.03250936425854824\n",
            "Q_table[(0, 1)]_new = 0.03266961689649639\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 948 episode and 7 step\n",
            "Delta Q = 0.903411189063803\n",
            "Q_table[5,0]_old = 0.028956509664270706\n",
            "Q_table[(5, 0)]_new = 0.029472047761646608\n",
            "We are on 5 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 948 episode and 8 step\n",
            "Delta Q = 0.903411189063803\n",
            "Q_table[5,0]_old = 0.029472047761646608\n",
            "Q_table[(5, 0)]_new = 0.029936032049284925\n",
            "We are on 5 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 948 episode and 9 step\n",
            "Delta Q = 0.903411189063803\n",
            "Q_table[5,0]_old = 0.029936032049284925\n",
            "Q_table[(5, 0)]_new = 0.030353617908159408\n",
            "We are on 5 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 948 episode and 10 step\n",
            "Delta Q = 0.9033071676751828\n",
            "Q_table[5,1]_old = 0.028342275194441324\n",
            "Q_table[(5, 1)]_new = 0.028815215350179973\n",
            "We are on 5 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 948 episode and 11 step\n",
            "Delta Q = 0.9033071676751828\n",
            "Q_table[10,0]_old = 0.016480831375936644\n",
            "Q_table[(10, 0)]_new = 0.01813991591352576\n",
            "We are on 10 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 948 episode and 12 step\n",
            "Delta Q = 0.9045867015970035\n",
            "Q_table[10,2]_old = 0.03340573409275538\n",
            "Q_table[(10, 2)]_new = 0.03465186228048336\n",
            "We are on 10 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 948 episode and 13 step\n",
            "Delta Q = 0.9034305343657679\n",
            "Q_table[11,0]_old = 0.007851405359912179\n",
            "Q_table[(11, 0)]_new = 0.010496799189688814\n",
            "We are on 11 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 948 episode and 14 step\n",
            "Delta Q = 0.9034305343657679\n",
            "Q_table[10,0]_old = 0.01813991591352576\n",
            "Q_table[(10, 0)]_new = 0.01975645868794104\n",
            "We are on 10 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 948 episode and 15 step\n",
            "Delta Q = 0.9045867015970035\n",
            "Q_table[10,2]_old = 0.03465186228048336\n",
            "Q_table[(10, 2)]_new = 0.03577337764943853\n",
            "We are on 10 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 948 episode and 16 step\n",
            "Delta Q = 0.9035415643872944\n",
            "Q_table[11,0]_old = 0.010496799189688814\n",
            "Q_table[(11, 0)]_new = 0.012988683658014347\n",
            "We are on 11 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 948 episode and 17 step\n",
            "Delta Q = 0.9045867015970035\n",
            "Q_table[10,2]_old = 0.03577337764943853\n",
            "Q_table[(10, 2)]_new = 0.036782741481498196\n",
            "We are on 10 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 948 episode and 18 step\n",
            "Delta Q = 0.9036414914066684\n",
            "Q_table[11,0]_old = 0.012988683658014347\n",
            "Q_table[(11, 0)]_new = 0.015331306698881234\n",
            "We are on 11 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 948 episode and 19 step\n",
            "Delta Q = 0.9036414914066684\n",
            "Q_table[10,0]_old = 0.01975645868794104\n",
            "Q_table[(10, 0)]_new = 0.021422304225815255\n",
            "We are on 10 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 948 episode and 20 step\n",
            "Delta Q = 0.9\n",
            "Q_table[10,1]_old = 0.0\n",
            "Q_table[(10, 1)]_new = 0.0\n",
            "We are on 10 state\n",
            "And now we are on 15 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 949 episode and 0 step\n",
            "Delta Q = 0.903411189063803\n",
            "Q_table[0,1]_old = 0.03266961689649639\n",
            "Q_table[(0, 1)]_new = 0.03281384427064973\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 949 episode and 1 step\n",
            "Delta Q = 0.903411189063803\n",
            "Q_table[5,0]_old = 0.030353617908159408\n",
            "Q_table[(5, 0)]_new = 0.03072944518114644\n",
            "We are on 5 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 949 episode and 2 step\n",
            "Delta Q = 0.9036414914066684\n",
            "Q_table[5,1]_old = 0.028815215350179973\n",
            "Q_table[(5, 1)]_new = 0.029575185221830298\n",
            "We are on 5 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 949 episode and 3 step\n",
            "Delta Q = 0.9\n",
            "Q_table[10,1]_old = 0.0\n",
            "Q_table[(10, 1)]_new = 0.0\n",
            "We are on 10 state\n",
            "And now we are on 15 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 950 episode and 0 step\n",
            "Delta Q = 0.9037240848770397\n",
            "Q_table[0,0]_old = 0.03644518255041424\n",
            "Q_table[(0, 0)]_new = 0.036524749172412545\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 950 episode and 1 step\n",
            "Delta Q = 0.903411189063803\n",
            "Q_table[0,1]_old = 0.03281384427064973\n",
            "Q_table[(0, 1)]_new = 0.032943648907387726\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 950 episode and 2 step\n",
            "Delta Q = 0.9037240848770397\n",
            "Q_table[5,3]_old = 0.03445645518992902\n",
            "Q_table[(5, 3)]_new = 0.03473489454797585\n",
            "We are on 5 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 950 episode and 3 step\n",
            "Delta Q = 0.9038767320542723\n",
            "Q_table[0,2]_old = 0.037617018959997264\n",
            "Q_table[(0, 2)]_new = 0.03773204911826983\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 950 episode and 4 step\n",
            "Delta Q = 0.9\n",
            "Q_table[1,1]_old = 0.0\n",
            "Q_table[(1, 1)]_new = 0.0\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 951 episode and 0 step\n",
            "Delta Q = 0.9034387545602496\n",
            "Q_table[0,1]_old = 0.032943648907387726\n",
            "Q_table[(0, 1)]_new = 0.033088038576898564\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 951 episode and 1 step\n",
            "Delta Q = 0.9036414914066684\n",
            "Q_table[5,1]_old = 0.029575185221830298\n",
            "Q_table[(5, 1)]_new = 0.03025915810631559\n",
            "We are on 5 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 951 episode and 2 step\n",
            "Delta Q = 0.9\n",
            "Q_table[10,1]_old = 0.0\n",
            "Q_table[(10, 1)]_new = 0.0\n",
            "We are on 10 state\n",
            "And now we are on 15 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 952 episode and 0 step\n",
            "Delta Q = 0.9038767320542723\n",
            "Q_table[0,2]_old = 0.03773204911826983\n",
            "Q_table[(0, 2)]_new = 0.03783557626071513\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 952 episode and 1 step\n",
            "Delta Q = 0.9037457220498109\n",
            "Q_table[1,0]_old = 0.032511862126237225\n",
            "Q_table[(1, 0)]_new = 0.033006397963424305\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 952 episode and 2 step\n",
            "Delta Q = 0.9037457220498109\n",
            "Q_table[0,3]_old = 0.03591210633777677\n",
            "Q_table[(0, 3)]_new = 0.0360666177538099\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 952 episode and 3 step\n",
            "Delta Q = 0.9037457220498109\n",
            "Q_table[0,3]_old = 0.0360666177538099\n",
            "Q_table[(0, 3)]_new = 0.03620567802823971\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 952 episode and 4 step\n",
            "Delta Q = 0.9037457220498109\n",
            "Q_table[0,0]_old = 0.036524749172412545\n",
            "Q_table[(0, 0)]_new = 0.036617996304982095\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 952 episode and 5 step\n",
            "Delta Q = 0.9037457220498109\n",
            "Q_table[0,3]_old = 0.03620567802823971\n",
            "Q_table[(0, 3)]_new = 0.03633083227522653\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 952 episode and 6 step\n",
            "Delta Q = 0.9038767320542723\n",
            "Q_table[0,2]_old = 0.03783557626071513\n",
            "Q_table[(0, 2)]_new = 0.03792875068891591\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 952 episode and 7 step\n",
            "Delta Q = 0.9037549463182027\n",
            "Q_table[1,0]_old = 0.033006397963424305\n",
            "Q_table[(1, 0)]_new = 0.03346070448528455\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 952 episode and 8 step\n",
            "Delta Q = 0.9037549463182027\n",
            "Q_table[0,3]_old = 0.03633083227522653\n",
            "Q_table[(0, 3)]_new = 0.036452695365906555\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 952 episode and 9 step\n",
            "Delta Q = 0.9038767320542723\n",
            "Q_table[0,2]_old = 0.03792875068891591\n",
            "Q_table[(0, 2)]_new = 0.03801260767429661\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 952 episode and 10 step\n",
            "Delta Q = 0.9\n",
            "Q_table[1,1]_old = 0.0\n",
            "Q_table[(1, 1)]_new = 0.0\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 953 episode and 0 step\n",
            "Delta Q = 0.9037632481597554\n",
            "Q_table[0,0]_old = 0.036617996304982095\n",
            "Q_table[(0, 0)]_new = 0.03671944483423925\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 953 episode and 1 step\n",
            "Delta Q = 0.9037632481597554\n",
            "Q_table[0,0]_old = 0.03671944483423925\n",
            "Q_table[(0, 0)]_new = 0.036810748510570694\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 953 episode and 2 step\n",
            "Delta Q = 0.9037632481597554\n",
            "Q_table[0,0]_old = 0.036810748510570694\n",
            "Q_table[(0, 0)]_new = 0.03689292181926899\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 953 episode and 3 step\n",
            "Delta Q = 0.9038767320542723\n",
            "Q_table[0,2]_old = 0.03801260767429661\n",
            "Q_table[(0, 2)]_new = 0.038088078961139235\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 953 episode and 4 step\n",
            "Delta Q = 0.9037707198171528\n",
            "Q_table[1,0]_old = 0.03346070448528455\n",
            "Q_table[(1, 0)]_new = 0.03388535385390888\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 953 episode and 5 step\n",
            "Delta Q = 0.9037707198171528\n",
            "Q_table[0,3]_old = 0.036452695365906555\n",
            "Q_table[(0, 3)]_new = 0.036578145646468684\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 953 episode and 6 step\n",
            "Delta Q = 0.9034387545602496\n",
            "Q_table[0,1]_old = 0.033088038576898564\n",
            "Q_table[(0, 1)]_new = 0.033217989279458314\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 953 episode and 7 step\n",
            "Delta Q = 0.9\n",
            "Q_table[5,2]_old = 0.0\n",
            "Q_table[(5, 2)]_new = 0.0\n",
            "We are on 5 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 954 episode and 0 step\n",
            "Delta Q = 0.9037707198171528\n",
            "Q_table[0,3]_old = 0.036578145646468684\n",
            "Q_table[(0, 3)]_new = 0.0366910508989746\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 954 episode and 1 step\n",
            "Delta Q = 0.9037707198171528\n",
            "Q_table[0,3]_old = 0.0366910508989746\n",
            "Q_table[(0, 3)]_new = 0.036792665626229924\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 954 episode and 2 step\n",
            "Delta Q = 0.9037707198171528\n",
            "Q_table[0,3]_old = 0.036792665626229924\n",
            "Q_table[(0, 3)]_new = 0.036884118880759716\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 954 episode and 3 step\n",
            "Delta Q = 0.9034387545602496\n",
            "Q_table[0,1]_old = 0.033217989279458314\n",
            "Q_table[(0, 1)]_new = 0.03333494491176209\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 954 episode and 4 step\n",
            "Delta Q = 0.9\n",
            "Q_table[5,2]_old = 0.0\n",
            "Q_table[(5, 2)]_new = 0.0\n",
            "We are on 5 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 955 episode and 0 step\n",
            "Delta Q = 0.9034387545602496\n",
            "Q_table[0,1]_old = 0.03333494491176209\n",
            "Q_table[(0, 1)]_new = 0.03344020498083549\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 955 episode and 1 step\n",
            "Delta Q = 0.9037707198171528\n",
            "Q_table[5,3]_old = 0.03473489454797585\n",
            "Q_table[(5, 3)]_new = 0.035032124910331044\n",
            "We are on 5 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 955 episode and 2 step\n",
            "Delta Q = 0.9037707198171528\n",
            "Q_table[0,0]_old = 0.03689292181926899\n",
            "Q_table[(0, 0)]_new = 0.03697434945449487\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 955 episode and 3 step\n",
            "Delta Q = 0.9037707198171528\n",
            "Q_table[0,3]_old = 0.036884118880759716\n",
            "Q_table[(0, 3)]_new = 0.03696642680983653\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 955 episode and 4 step\n",
            "Delta Q = 0.9034681803661228\n",
            "Q_table[0,1]_old = 0.03344020498083549\n",
            "Q_table[(0, 1)]_new = 0.03356436484887471\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 955 episode and 5 step\n",
            "Delta Q = 0.9036414914066684\n",
            "Q_table[5,1]_old = 0.03025915810631559\n",
            "Q_table[(5, 1)]_new = 0.03087473370235235\n",
            "We are on 5 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 955 episode and 6 step\n",
            "Delta Q = 0.9\n",
            "Q_table[10,1]_old = 0.0\n",
            "Q_table[(10, 1)]_new = 0.0\n",
            "We are on 10 state\n",
            "And now we are on 15 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 956 episode and 0 step\n",
            "Delta Q = 0.9037707198171528\n",
            "Q_table[0,3]_old = 0.03696642680983653\n",
            "Q_table[(0, 3)]_new = 0.03704050394600566\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 956 episode and 1 step\n",
            "Delta Q = 0.9037707198171528\n",
            "Q_table[0,3]_old = 0.03704050394600566\n",
            "Q_table[(0, 3)]_new = 0.03710717336855787\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 956 episode and 2 step\n",
            "Delta Q = 0.9034681803661228\n",
            "Q_table[0,1]_old = 0.03356436484887471\n",
            "Q_table[(0, 1)]_new = 0.03367610873011002\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 956 episode and 3 step\n",
            "Delta Q = 0.9034681803661228\n",
            "Q_table[5,0]_old = 0.03072944518114644\n",
            "Q_table[(5, 0)]_new = 0.03112468102915457\n",
            "We are on 5 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 956 episode and 4 step\n",
            "Delta Q = 0.9037707198171528\n",
            "Q_table[5,3]_old = 0.035032124910331044\n",
            "Q_table[(5, 3)]_new = 0.035299632236450725\n",
            "We are on 5 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 956 episode and 5 step\n",
            "Delta Q = 0.9034946635914086\n",
            "Q_table[0,1]_old = 0.03367610873011002\n",
            "Q_table[(0, 1)]_new = 0.03380316144850764\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 956 episode and 6 step\n",
            "Delta Q = 0.9\n",
            "Q_table[5,2]_old = 0.0\n",
            "Q_table[(5, 2)]_new = 0.0\n",
            "We are on 5 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 957 episode and 0 step\n",
            "Delta Q = 0.9037707198171528\n",
            "Q_table[0,3]_old = 0.03710717336855787\n",
            "Q_table[(0, 3)]_new = 0.037167175848854865\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 957 episode and 1 step\n",
            "Delta Q = 0.9034946635914086\n",
            "Q_table[0,1]_old = 0.03380316144850764\n",
            "Q_table[(0, 1)]_new = 0.03391750889506549\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 957 episode and 2 step\n",
            "Delta Q = 0.9037707198171528\n",
            "Q_table[5,3]_old = 0.035299632236450725\n",
            "Q_table[(5, 3)]_new = 0.035540388829958434\n",
            "We are on 5 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 957 episode and 3 step\n",
            "Delta Q = 0.9038767320542723\n",
            "Q_table[0,2]_old = 0.038088078961139235\n",
            "Q_table[(0, 2)]_new = 0.0381560031192976\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 957 episode and 4 step\n",
            "Delta Q = 0.9037774443088105\n",
            "Q_table[1,0]_old = 0.03388535385390888\n",
            "Q_table[(1, 0)]_new = 0.03427426277732846\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 957 episode and 5 step\n",
            "Delta Q = 0.9037774443088105\n",
            "Q_table[0,3]_old = 0.037167175848854865\n",
            "Q_table[(0, 3)]_new = 0.03722790257277984\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 957 episode and 6 step\n",
            "Delta Q = 0.9037774443088105\n",
            "Q_table[0,0]_old = 0.03697434945449487\n",
            "Q_table[(0, 0)]_new = 0.03705435881785584\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 957 episode and 7 step\n",
            "Delta Q = 0.9038767320542723\n",
            "Q_table[0,2]_old = 0.0381560031192976\n",
            "Q_table[(0, 2)]_new = 0.03821713486164013\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 957 episode and 8 step\n",
            "Delta Q = 0.9037834963513024\n",
            "Q_table[1,0]_old = 0.03427426277732846\n",
            "Q_table[(1, 0)]_new = 0.034630332850897984\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 957 episode and 9 step\n",
            "Delta Q = 0.9037834963513024\n",
            "Q_table[0,3]_old = 0.03722790257277984\n",
            "Q_table[(0, 3)]_new = 0.03728860866680423\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 957 episode and 10 step\n",
            "Delta Q = 0.9038767320542723\n",
            "Q_table[0,2]_old = 0.03821713486164013\n",
            "Q_table[(0, 2)]_new = 0.03827215342974841\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 957 episode and 11 step\n",
            "Delta Q = 0.9037889431895452\n",
            "Q_table[1,0]_old = 0.034630332850897984\n",
            "Q_table[(1, 0)]_new = 0.03495624275535328\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 957 episode and 12 step\n",
            "Delta Q = 0.9038767320542723\n",
            "Q_table[0,2]_old = 0.03827215342974841\n",
            "Q_table[(0, 2)]_new = 0.03832167014104586\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 957 episode and 13 step\n",
            "Delta Q = 0.9043045732310815\n",
            "Q_table[1,2]_old = 0.039158909639114024\n",
            "Q_table[(1, 2)]_new = 0.03954759190628411\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 957 episode and 14 step\n",
            "Delta Q = 0.9039152115987221\n",
            "Q_table[2,0]_old = 0.027279377348121255\n",
            "Q_table[(2, 0)]_new = 0.028466651212031256\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 957 episode and 15 step\n",
            "Delta Q = 0.9037938453439636\n",
            "Q_table[1,0]_old = 0.03495624275535328\n",
            "Q_table[(1, 0)]_new = 0.035254463823781494\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 957 episode and 16 step\n",
            "Delta Q = 0.9039152115987221\n",
            "Q_table[0,2]_old = 0.03832167014104586\n",
            "Q_table[(0, 2)]_new = 0.038404714725663404\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 957 episode and 17 step\n",
            "Delta Q = 0.9043045732310815\n",
            "Q_table[1,2]_old = 0.03954759190628411\n",
            "Q_table[(1, 2)]_new = 0.039897405946737186\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 957 episode and 18 step\n",
            "Delta Q = 0.903949843188727\n",
            "Q_table[2,0]_old = 0.028466651212031256\n",
            "Q_table[(2, 0)]_new = 0.029569829279555114\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 957 episode and 19 step\n",
            "Delta Q = 0.903949843188727\n",
            "Q_table[1,3]_old = 0.033985606114116114\n",
            "Q_table[(1, 3)]_new = 0.03453688869143148\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 957 episode and 20 step\n",
            "Delta Q = 0.9\n",
            "Q_table[1,1]_old = 0.0\n",
            "Q_table[(1, 1)]_new = 0.0\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 958 episode and 0 step\n",
            "Delta Q = 0.9038020667578407\n",
            "Q_table[0,0]_old = 0.03705435881785584\n",
            "Q_table[(0, 0)]_new = 0.03715098969391094\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 958 episode and 1 step\n",
            "Delta Q = 0.9038020667578407\n",
            "Q_table[0,3]_old = 0.03728860866680423\n",
            "Q_table[(0, 3)]_new = 0.03736181455796449\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 958 episode and 2 step\n",
            "Delta Q = 0.9038020667578407\n",
            "Q_table[0,0]_old = 0.03715098969391094\n",
            "Q_table[(0, 0)]_new = 0.03723795748236052\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 958 episode and 3 step\n",
            "Delta Q = 0.9035184984941659\n",
            "Q_table[0,1]_old = 0.03391750889506549\n",
            "Q_table[(0, 1)]_new = 0.03404425649972483\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 958 episode and 4 step\n",
            "Delta Q = 0.9036414914066684\n",
            "Q_table[5,1]_old = 0.03087473370235235\n",
            "Q_table[(5, 1)]_new = 0.03142875173878544\n",
            "We are on 5 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 958 episode and 5 step\n",
            "Delta Q = 0.9036414914066684\n",
            "Q_table[10,0]_old = 0.021422304225815255\n",
            "Q_table[(10, 0)]_new = 0.022921565209902052\n",
            "We are on 10 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 958 episode and 6 step\n",
            "Delta Q = 0.9\n",
            "Q_table[10,1]_old = 0.0\n",
            "Q_table[(10, 1)]_new = 0.0\n",
            "We are on 10 state\n",
            "And now we are on 15 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 959 episode and 0 step\n",
            "Delta Q = 0.9035184984941659\n",
            "Q_table[0,1]_old = 0.03404425649972483\n",
            "Q_table[(0, 1)]_new = 0.034158329343918235\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 959 episode and 1 step\n",
            "Delta Q = 0.9038020667578407\n",
            "Q_table[5,3]_old = 0.035540388829958434\n",
            "Q_table[(5, 3)]_new = 0.03578841670480327\n",
            "We are on 5 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 959 episode and 2 step\n",
            "Delta Q = 0.903949843188727\n",
            "Q_table[0,2]_old = 0.038404714725663404\n",
            "Q_table[(0, 2)]_new = 0.038514086441824046\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 959 episode and 3 step\n",
            "Delta Q = 0.9043045732310815\n",
            "Q_table[1,2]_old = 0.039897405946737186\n",
            "Q_table[(1, 2)]_new = 0.04021223858314495\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 959 episode and 4 step\n",
            "Delta Q = 0.9023238682038011\n",
            "Q_table[2,2]_old = 0.016155494695869906\n",
            "Q_table[(2, 2)]_new = 0.016863813430083932\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 959 episode and 5 step\n",
            "Delta Q = 0.9043045732310815\n",
            "Q_table[3,0]_old = 0.02347341620001024\n",
            "Q_table[(3, 0)]_new = 0.025430647811090706\n",
            "We are on 3 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 959 episode and 6 step\n",
            "Delta Q = 0.902517634133298\n",
            "Q_table[2,2]_old = 0.016863813430083932\n",
            "Q_table[(2, 2)]_new = 0.01769506622037352\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 959 episode and 7 step\n",
            "Delta Q = 0.9043045732310815\n",
            "Q_table[3,0]_old = 0.025430647811090706\n",
            "Q_table[(3, 0)]_new = 0.02719215626106312\n",
            "We are on 3 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 959 episode and 8 step\n",
            "Delta Q = 0.9049153436965169\n",
            "Q_table[2,1]_old = 0.04348053768769177\n",
            "Q_table[(2, 1)]_new = 0.04404782761543948\n",
            "We are on 2 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 959 episode and 9 step\n",
            "Delta Q = 0.9\n",
            "Q_table[7,0]_old = 0.0\n",
            "Q_table[(7, 0)]_new = 0.0\n",
            "We are on 7 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 960 episode and 0 step\n",
            "Delta Q = 0.9038128945577406\n",
            "Q_table[0,3]_old = 0.03736181455796449\n",
            "Q_table[(0, 3)]_new = 0.03743852765990862\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 960 episode and 1 step\n",
            "Delta Q = 0.9038128945577406\n",
            "Q_table[0,3]_old = 0.03743852765990862\n",
            "Q_table[(0, 3)]_new = 0.03750756945165834\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 960 episode and 2 step\n",
            "Delta Q = 0.9035430532537756\n",
            "Q_table[0,1]_old = 0.034158329343918235\n",
            "Q_table[(0, 1)]_new = 0.03428554966330194\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 960 episode and 3 step\n",
            "Delta Q = 0.9035430532537756\n",
            "Q_table[5,0]_old = 0.03112468102915457\n",
            "Q_table[(5, 0)]_new = 0.031555266180014634\n",
            "We are on 5 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 960 episode and 4 step\n",
            "Delta Q = 0.9\n",
            "Q_table[5,2]_old = 0.0\n",
            "Q_table[(5, 2)]_new = 0.0\n",
            "We are on 5 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 961 episode and 0 step\n",
            "Delta Q = 0.9035430532537756\n",
            "Q_table[0,1]_old = 0.03428554966330194\n",
            "Q_table[(0, 1)]_new = 0.03440004795074727\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 961 episode and 1 step\n",
            "Delta Q = 0.9036414914066684\n",
            "Q_table[5,1]_old = 0.03142875173878544\n",
            "Q_table[(5, 1)]_new = 0.03192736797157522\n",
            "We are on 5 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 961 episode and 2 step\n",
            "Delta Q = 0.9036414914066684\n",
            "Q_table[10,0]_old = 0.022921565209902052\n",
            "Q_table[(10, 0)]_new = 0.024270900095580167\n",
            "We are on 10 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 961 episode and 3 step\n",
            "Delta Q = 0.9035430532537756\n",
            "Q_table[10,3]_old = 0.020051441777547977\n",
            "Q_table[(10, 3)]_new = 0.021589350853568702\n",
            "We are on 10 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 961 episode and 4 step\n",
            "Delta Q = 0.9\n",
            "Q_table[5,2]_old = 0.0\n",
            "Q_table[(5, 2)]_new = 0.0\n",
            "We are on 5 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 962 episode and 0 step\n",
            "Delta Q = 0.9035430532537756\n",
            "Q_table[0,1]_old = 0.03440004795074727\n",
            "Q_table[(0, 1)]_new = 0.03450309640944807\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 962 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[5,2]_old = 0.0\n",
            "Q_table[(5, 2)]_new = 0.0\n",
            "We are on 5 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 963 episode and 0 step\n",
            "Delta Q = 0.9035430532537756\n",
            "Q_table[0,1]_old = 0.03450309640944807\n",
            "Q_table[(0, 1)]_new = 0.034595840022278786\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 963 episode and 1 step\n",
            "Delta Q = 0.9035430532537756\n",
            "Q_table[5,0]_old = 0.031555266180014634\n",
            "Q_table[(5, 0)]_new = 0.0319427928157887\n",
            "We are on 5 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 963 episode and 2 step\n",
            "Delta Q = 0.9035430532537756\n",
            "Q_table[5,0]_old = 0.0319427928157887\n",
            "Q_table[(5, 0)]_new = 0.03229156678798535\n",
            "We are on 5 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 963 episode and 3 step\n",
            "Delta Q = 0.9038128945577406\n",
            "Q_table[5,3]_old = 0.03578841670480327\n",
            "Q_table[(5, 3)]_new = 0.036022469592063525\n",
            "We are on 5 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 963 episode and 4 step\n",
            "Delta Q = 0.9038128945577406\n",
            "Q_table[0,0]_old = 0.03723795748236052\n",
            "Q_table[(0, 0)]_new = 0.03732705629186505\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 963 episode and 5 step\n",
            "Delta Q = 0.9035662244896143\n",
            "Q_table[0,1]_old = 0.034595840022278786\n",
            "Q_table[(0, 1)]_new = 0.03470248050966519\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 963 episode and 6 step\n",
            "Delta Q = 0.9035662244896143\n",
            "Q_table[5,0]_old = 0.03229156678798535\n",
            "Q_table[(5, 0)]_new = 0.0326286345988011\n",
            "We are on 5 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 963 episode and 7 step\n",
            "Delta Q = 0.9038128945577406\n",
            "Q_table[5,3]_old = 0.036022469592063525\n",
            "Q_table[(5, 3)]_new = 0.036233117190597755\n",
            "We are on 5 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 963 episode and 8 step\n",
            "Delta Q = 0.9039810116197313\n",
            "Q_table[0,2]_old = 0.038514086441824046\n",
            "Q_table[(0, 2)]_new = 0.03864368941737299\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 963 episode and 9 step\n",
            "Delta Q = 0.90382572525232\n",
            "Q_table[1,0]_old = 0.035254463823781494\n",
            "Q_table[(1, 0)]_new = 0.03555474269372327\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 963 episode and 10 step\n",
            "Delta Q = 0.90382572525232\n",
            "Q_table[0,0]_old = 0.03732705629186505\n",
            "Q_table[(0, 0)]_new = 0.03742007591499847\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 963 episode and 11 step\n",
            "Delta Q = 0.90382572525232\n",
            "Q_table[0,3]_old = 0.03750756945165834\n",
            "Q_table[(0, 3)]_new = 0.03758253775881243\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 963 episode and 12 step\n",
            "Delta Q = 0.9039810116197313\n",
            "Q_table[0,2]_old = 0.03864368941737299\n",
            "Q_table[(0, 2)]_new = 0.03876033209536704\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 963 episode and 13 step\n",
            "Delta Q = 0.9039810116197313\n",
            "Q_table[1,3]_old = 0.03453688869143148\n",
            "Q_table[(1, 3)]_new = 0.03506421144201969\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 963 episode and 14 step\n",
            "Delta Q = 0.9038372728774413\n",
            "Q_table[1,0]_old = 0.03555474269372327\n",
            "Q_table[(1, 0)]_new = 0.03583654130179228\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 963 episode and 15 step\n",
            "Delta Q = 0.9038372728774413\n",
            "Q_table[0,0]_old = 0.03742007591499847\n",
            "Q_table[(0, 0)]_new = 0.03751534120093996\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 963 episode and 16 step\n",
            "Delta Q = 0.9039810116197313\n",
            "Q_table[0,2]_old = 0.03876033209536704\n",
            "Q_table[(0, 2)]_new = 0.03886531050556169\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 963 episode and 17 step\n",
            "Delta Q = 0.9043607349339285\n",
            "Q_table[1,2]_old = 0.04021223858314495\n",
            "Q_table[(1, 2)]_new = 0.04055174965875897\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 963 episode and 18 step\n",
            "Delta Q = 0.9049153436965169\n",
            "Q_table[2,1]_old = 0.04404782761543948\n",
            "Q_table[(2, 1)]_new = 0.04455838855041242\n",
            "We are on 2 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 963 episode and 19 step\n",
            "Delta Q = 0.9044112804664909\n",
            "Q_table[7,3]_old = 0.01997249379908216\n",
            "Q_table[(7, 3)]_new = 0.022386524885664772\n",
            "We are on 7 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 963 episode and 20 step\n",
            "Delta Q = 0.9049153436965169\n",
            "Q_table[2,1]_old = 0.04455838855041242\n",
            "Q_table[(2, 1)]_new = 0.04501789339188807\n",
            "We are on 2 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 963 episode and 21 step\n",
            "Delta Q = 0.9\n",
            "Q_table[7,0]_old = 0.0\n",
            "Q_table[(7, 0)]_new = 0.0\n",
            "We are on 7 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 964 episode and 0 step\n",
            "Delta Q = 0.9035870786018692\n",
            "Q_table[0,1]_old = 0.03470248050966519\n",
            "Q_table[(0, 1)]_new = 0.034819311060567855\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 964 episode and 1 step\n",
            "Delta Q = 0.9038476657400506\n",
            "Q_table[5,3]_old = 0.036233117190597755\n",
            "Q_table[(5, 3)]_new = 0.036457471211588585\n",
            "We are on 5 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 964 episode and 2 step\n",
            "Delta Q = 0.9038476657400506\n",
            "Q_table[0,3]_old = 0.03758253775881243\n",
            "Q_table[(0, 3)]_new = 0.03767194972298179\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 964 episode and 3 step\n",
            "Delta Q = 0.9038476657400506\n",
            "Q_table[0,0]_old = 0.03751534120093996\n",
            "Q_table[(0, 0)]_new = 0.037611472820896566\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 964 episode and 4 step\n",
            "Delta Q = 0.9038476657400506\n",
            "Q_table[0,3]_old = 0.03767194972298179\n",
            "Q_table[(0, 3)]_new = 0.03775242049073421\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 964 episode and 5 step\n",
            "Delta Q = 0.9038476657400506\n",
            "Q_table[0,3]_old = 0.03775242049073421\n",
            "Q_table[(0, 3)]_new = 0.0378248441817114\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 964 episode and 6 step\n",
            "Delta Q = 0.9040146232162172\n",
            "Q_table[0,2]_old = 0.03886531050556169\n",
            "Q_table[(0, 2)]_new = 0.03899340267122266\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 964 episode and 7 step\n",
            "Delta Q = 0.9040146232162172\n",
            "Q_table[1,3]_old = 0.03506421144201969\n",
            "Q_table[(1, 3)]_new = 0.03557241351403486\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 964 episode and 8 step\n",
            "Delta Q = 0.903860346864451\n",
            "Q_table[1,0]_old = 0.03583654130179228\n",
            "Q_table[(1, 0)]_new = 0.0361132340360641\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 964 episode and 9 step\n",
            "Delta Q = 0.9036092896499472\n",
            "Q_table[0,1]_old = 0.034819311060567855\n",
            "Q_table[(0, 1)]_new = 0.034946669604458344\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 964 episode and 10 step\n",
            "Delta Q = 0.9036414914066684\n",
            "Q_table[5,1]_old = 0.03192736797157522\n",
            "Q_table[(5, 1)]_new = 0.03237612258108602\n",
            "We are on 5 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 964 episode and 11 step\n",
            "Delta Q = 0.9036414914066684\n",
            "Q_table[10,0]_old = 0.024270900095580167\n",
            "Q_table[(10, 0)]_new = 0.02548530149269047\n",
            "We are on 10 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 964 episode and 12 step\n",
            "Delta Q = 0.9\n",
            "Q_table[10,1]_old = 0.0\n",
            "Q_table[(10, 1)]_new = 0.0\n",
            "We are on 10 state\n",
            "And now we are on 15 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 965 episode and 0 step\n",
            "Delta Q = 0.9040146232162172\n",
            "Q_table[0,2]_old = 0.03899340267122266\n",
            "Q_table[(0, 2)]_new = 0.03910868562031753\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 965 episode and 1 step\n",
            "Delta Q = 0.9040146232162172\n",
            "Q_table[1,3]_old = 0.03557241351403486\n",
            "Q_table[(1, 3)]_new = 0.03602979537884851\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 965 episode and 2 step\n",
            "Delta Q = 0.9038717598764114\n",
            "Q_table[1,0]_old = 0.0361132340360641\n",
            "Q_table[(1, 0)]_new = 0.036373670508869124\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 965 episode and 3 step\n",
            "Delta Q = 0.9040146232162172\n",
            "Q_table[0,2]_old = 0.03910868562031753\n",
            "Q_table[(0, 2)]_new = 0.039212440274502915\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 965 episode and 4 step\n",
            "Delta Q = 0.9\n",
            "Q_table[1,1]_old = 0.0\n",
            "Q_table[(1, 1)]_new = 0.0\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 966 episode and 0 step\n",
            "Delta Q = 0.9038820315871758\n",
            "Q_table[0,3]_old = 0.0378248441817114\n",
            "Q_table[(0, 3)]_new = 0.03792439135071605\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 966 episode and 1 step\n",
            "Delta Q = 0.9038820315871758\n",
            "Q_table[0,3]_old = 0.03792439135071605\n",
            "Q_table[(0, 3)]_new = 0.038013983802820235\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 966 episode and 2 step\n",
            "Delta Q = 0.9038820315871758\n",
            "Q_table[0,0]_old = 0.037611472820896566\n",
            "Q_table[(0, 0)]_new = 0.0377323571259827\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 966 episode and 3 step\n",
            "Delta Q = 0.9038820315871758\n",
            "Q_table[0,3]_old = 0.038013983802820235\n",
            "Q_table[(0, 3)]_new = 0.038094617009714\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 966 episode and 4 step\n",
            "Delta Q = 0.9038820315871758\n",
            "Q_table[0,0]_old = 0.0377323571259827\n",
            "Q_table[(0, 0)]_new = 0.037841153000560214\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 966 episode and 5 step\n",
            "Delta Q = 0.9036092896499472\n",
            "Q_table[0,1]_old = 0.034946669604458344\n",
            "Q_table[(0, 1)]_new = 0.03506129229395978\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 966 episode and 6 step\n",
            "Delta Q = 0.9036414914066684\n",
            "Q_table[5,1]_old = 0.03237612258108602\n",
            "Q_table[(5, 1)]_new = 0.03278000172964574\n",
            "We are on 5 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 966 episode and 7 step\n",
            "Delta Q = 0.9045867015970035\n",
            "Q_table[10,2]_old = 0.036782741481498196\n",
            "Q_table[(10, 2)]_new = 0.03769116893035189\n",
            "We are on 10 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 966 episode and 8 step\n",
            "Delta Q = 0.9037314257241048\n",
            "Q_table[11,0]_old = 0.015331306698881234\n",
            "Q_table[(11, 0)]_new = 0.017529601753097947\n",
            "We are on 11 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 966 episode and 9 step\n",
            "Delta Q = 0.9\n",
            "Q_table[10,1]_old = 0.0\n",
            "Q_table[(10, 1)]_new = 0.0\n",
            "We are on 10 state\n",
            "And now we are on 15 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 967 episode and 0 step\n",
            "Delta Q = 0.9038820315871758\n",
            "Q_table[0,3]_old = 0.038094617009714\n",
            "Q_table[(0, 3)]_new = 0.03816718689591839\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 967 episode and 1 step\n",
            "Delta Q = 0.9038820315871758\n",
            "Q_table[0,0]_old = 0.037841153000560214\n",
            "Q_table[(0, 0)]_new = 0.03793906928767998\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 967 episode and 2 step\n",
            "Delta Q = 0.9036092896499472\n",
            "Q_table[0,1]_old = 0.03506129229395978\n",
            "Q_table[(0, 1)]_new = 0.035164452714511074\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 967 episode and 3 step\n",
            "Delta Q = 0.9038820315871758\n",
            "Q_table[5,3]_old = 0.036457471211588585\n",
            "Q_table[(5, 3)]_new = 0.036693755677605515\n",
            "We are on 5 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 967 episode and 4 step\n",
            "Delta Q = 0.903632681812083\n",
            "Q_table[0,1]_old = 0.035164452714511074\n",
            "Q_table[(0, 1)]_new = 0.03528068925514292\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 967 episode and 5 step\n",
            "Delta Q = 0.9\n",
            "Q_table[5,2]_old = 0.0\n",
            "Q_table[(5, 2)]_new = 0.0\n",
            "We are on 5 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 968 episode and 0 step\n",
            "Delta Q = 0.903632681812083\n",
            "Q_table[0,1]_old = 0.03528068925514292\n",
            "Q_table[(0, 1)]_new = 0.03538530214171157\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 968 episode and 1 step\n",
            "Delta Q = 0.903632681812083\n",
            "Q_table[5,0]_old = 0.0326286345988011\n",
            "Q_table[(5, 0)]_new = 0.03299845295100394\n",
            "We are on 5 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 968 episode and 2 step\n",
            "Delta Q = 0.903632681812083\n",
            "Q_table[5,0]_old = 0.03299845295100394\n",
            "Q_table[(5, 0)]_new = 0.03333128946798649\n",
            "We are on 5 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 968 episode and 3 step\n",
            "Delta Q = 0.9\n",
            "Q_table[5,2]_old = 0.0\n",
            "Q_table[(5, 2)]_new = 0.0\n",
            "We are on 5 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 969 episode and 0 step\n",
            "Delta Q = 0.9040146232162172\n",
            "Q_table[0,2]_old = 0.039212440274502915\n",
            "Q_table[(0, 2)]_new = 0.03930581946326976\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 969 episode and 1 step\n",
            "Delta Q = 0.9040146232162172\n",
            "Q_table[1,3]_old = 0.03602979537884851\n",
            "Q_table[(1, 3)]_new = 0.0364414390571808\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 969 episode and 2 step\n",
            "Delta Q = 0.9038912761268637\n",
            "Q_table[1,0]_old = 0.036373670508869124\n",
            "Q_table[(1, 0)]_new = 0.03662757958484592\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 969 episode and 3 step\n",
            "Delta Q = 0.903632681812083\n",
            "Q_table[0,1]_old = 0.03538530214171157\n",
            "Q_table[(0, 1)]_new = 0.035479453739623364\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 969 episode and 4 step\n",
            "Delta Q = 0.9\n",
            "Q_table[5,2]_old = 0.0\n",
            "Q_table[(5, 2)]_new = 0.0\n",
            "We are on 5 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 970 episode and 0 step\n",
            "Delta Q = 0.903632681812083\n",
            "Q_table[0,1]_old = 0.035479453739623364\n",
            "Q_table[(0, 1)]_new = 0.035564190177743975\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 970 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[5,2]_old = 0.0\n",
            "Q_table[(5, 2)]_new = 0.0\n",
            "We are on 5 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 971 episode and 0 step\n",
            "Delta Q = 0.9038912761268637\n",
            "Q_table[0,0]_old = 0.03793906928767998\n",
            "Q_table[(0, 0)]_new = 0.03803643848577569\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 971 episode and 1 step\n",
            "Delta Q = 0.9038912761268637\n",
            "Q_table[0,3]_old = 0.03816718689591839\n",
            "Q_table[(0, 3)]_new = 0.038241744333190254\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 971 episode and 2 step\n",
            "Delta Q = 0.9040146232162172\n",
            "Q_table[0,2]_old = 0.03930581946326976\n",
            "Q_table[(0, 2)]_new = 0.03938986073315992\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 971 episode and 3 step\n",
            "Delta Q = 0.9040146232162172\n",
            "Q_table[1,3]_old = 0.0364414390571808\n",
            "Q_table[(1, 3)]_new = 0.03681191836767986\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 971 episode and 4 step\n",
            "Delta Q = 0.9038995962125829\n",
            "Q_table[1,0]_old = 0.03662757958484592\n",
            "Q_table[(1, 0)]_new = 0.03686441783894416\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 971 episode and 5 step\n",
            "Delta Q = 0.9040146232162172\n",
            "Q_table[0,2]_old = 0.03938986073315992\n",
            "Q_table[(0, 2)]_new = 0.039465497876061066\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 971 episode and 6 step\n",
            "Delta Q = 0.9039070842897301\n",
            "Q_table[1,0]_old = 0.03686441783894416\n",
            "Q_table[(1, 0)]_new = 0.03708506034477979\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 971 episode and 7 step\n",
            "Delta Q = 0.9040146232162172\n",
            "Q_table[0,2]_old = 0.039465497876061066\n",
            "Q_table[(0, 2)]_new = 0.0395335713046721\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 971 episode and 8 step\n",
            "Delta Q = 0.9039138235591626\n",
            "Q_table[1,0]_old = 0.03708506034477979\n",
            "Q_table[(1, 0)]_new = 0.037290377869464354\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 971 episode and 9 step\n",
            "Delta Q = 0.9040146232162172\n",
            "Q_table[0,2]_old = 0.0395335713046721\n",
            "Q_table[(0, 2)]_new = 0.03959483739042202\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 971 episode and 10 step\n",
            "Delta Q = 0.904456771445797\n",
            "Q_table[1,2]_old = 0.04055174965875897\n",
            "Q_table[(1, 2)]_new = 0.04095334613867999\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 971 episode and 11 step\n",
            "Delta Q = 0.9040543812677293\n",
            "Q_table[2,0]_old = 0.029569829279555114\n",
            "Q_table[(2, 0)]_new = 0.030667227619328923\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 971 episode and 12 step\n",
            "Delta Q = 0.9\n",
            "Q_table[1,1]_old = 0.0\n",
            "Q_table[(1, 1)]_new = 0.0\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 972 episode and 0 step\n",
            "Delta Q = 0.9040543812677293\n",
            "Q_table[0,2]_old = 0.03959483739042202\n",
            "Q_table[(0, 2)]_new = 0.03968973491910914\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 972 episode and 1 step\n",
            "Delta Q = 0.904456771445797\n",
            "Q_table[1,2]_old = 0.04095334613867999\n",
            "Q_table[(1, 2)]_new = 0.041314782970608914\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 972 episode and 2 step\n",
            "Delta Q = 0.9049153436965169\n",
            "Q_table[2,1]_old = 0.04501789339188807\n",
            "Q_table[(2, 1)]_new = 0.04543144774921615\n",
            "We are on 2 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 972 episode and 3 step\n",
            "Delta Q = 0.9\n",
            "Q_table[7,0]_old = 0.0\n",
            "Q_table[(7, 0)]_new = 0.0\n",
            "We are on 7 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 0 step\n",
            "Delta Q = 0.9039292837569918\n",
            "Q_table[0,0]_old = 0.03803643848577569\n",
            "Q_table[(0, 0)]_new = 0.03816207839418993\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 1 step\n",
            "Delta Q = 0.9039292837569918\n",
            "Q_table[0,0]_old = 0.03816207839418993\n",
            "Q_table[(0, 0)]_new = 0.038275154311762746\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 2 step\n",
            "Delta Q = 0.9039292837569918\n",
            "Q_table[0,0]_old = 0.038275154311762746\n",
            "Q_table[(0, 0)]_new = 0.038376922637578276\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 3 step\n",
            "Delta Q = 0.9039292837569918\n",
            "Q_table[0,0]_old = 0.038376922637578276\n",
            "Q_table[(0, 0)]_new = 0.03846851413081226\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 4 step\n",
            "Delta Q = 0.9039292837569918\n",
            "Q_table[0,0]_old = 0.03846851413081226\n",
            "Q_table[(0, 0)]_new = 0.03855094647472283\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 5 step\n",
            "Delta Q = 0.903632681812083\n",
            "Q_table[0,1]_old = 0.035564190177743975\n",
            "Q_table[(0, 1)]_new = 0.035640452972052525\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 6 step\n",
            "Delta Q = 0.903632681812083\n",
            "Q_table[5,0]_old = 0.03333128946798649\n",
            "Q_table[(5, 0)]_new = 0.03363084233327079\n",
            "We are on 5 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 7 step\n",
            "Delta Q = 0.9039292837569918\n",
            "Q_table[5,3]_old = 0.036693755677605515\n",
            "Q_table[(5, 3)]_new = 0.03695366386683677\n",
            "We are on 5 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 8 step\n",
            "Delta Q = 0.9040901635140903\n",
            "Q_table[0,2]_old = 0.03968973491910914\n",
            "Q_table[(0, 2)]_new = 0.03981092494128851\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 9 step\n",
            "Delta Q = 0.9039412815691876\n",
            "Q_table[1,0]_old = 0.037290377869464354\n",
            "Q_table[(1, 0)]_new = 0.03750262165170548\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 10 step\n",
            "Delta Q = 0.9039412815691876\n",
            "Q_table[0,0]_old = 0.03855094647472283\n",
            "Q_table[(0, 0)]_new = 0.038637133396438116\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 11 step\n",
            "Delta Q = 0.9040901635140903\n",
            "Q_table[0,2]_old = 0.03981092494128851\n",
            "Q_table[(0, 2)]_new = 0.03991999596124995\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 12 step\n",
            "Delta Q = 0.9039520796001638\n",
            "Q_table[1,0]_old = 0.03750262165170548\n",
            "Q_table[(1, 0)]_new = 0.037704439086698675\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 13 step\n",
            "Delta Q = 0.9039520796001638\n",
            "Q_table[0,3]_old = 0.038241744333190254\n",
            "Q_table[(0, 3)]_new = 0.03836964950003497\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 14 step\n",
            "Delta Q = 0.9039520796001638\n",
            "Q_table[0,3]_old = 0.03836964950003497\n",
            "Q_table[(0, 3)]_new = 0.038484764150195215\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 15 step\n",
            "Delta Q = 0.9036584127228169\n",
            "Q_table[0,1]_old = 0.035640452972052525\n",
            "Q_table[(0, 1)]_new = 0.03573482039766412\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 16 step\n",
            "Delta Q = 0.9039520796001638\n",
            "Q_table[5,3]_old = 0.03695366386683677\n",
            "Q_table[(5, 3)]_new = 0.03721037708031683\n",
            "We are on 5 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 17 step\n",
            "Delta Q = 0.9040901635140903\n",
            "Q_table[0,2]_old = 0.03991999596124995\n",
            "Q_table[(0, 2)]_new = 0.04001815987921524\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 18 step\n",
            "Delta Q = 0.9040901635140903\n",
            "Q_table[1,3]_old = 0.03681191836767986\n",
            "Q_table[(1, 3)]_new = 0.03722089004500216\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 19 step\n",
            "Delta Q = 0.9040901635140903\n",
            "Q_table[1,3]_old = 0.03722089004500216\n",
            "Q_table[(1, 3)]_new = 0.03758896455459223\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 20 step\n",
            "Delta Q = 0.9040901635140903\n",
            "Q_table[1,3]_old = 0.03758896455459223\n",
            "Q_table[(1, 3)]_new = 0.03792023161322329\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 973 episode and 21 step\n",
            "Delta Q = 0.9\n",
            "Q_table[1,1]_old = 0.0\n",
            "Q_table[(1, 1)]_new = 0.0\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 974 episode and 0 step\n",
            "Delta Q = 0.9036838273309514\n",
            "Q_table[0,1]_old = 0.03573482039766412\n",
            "Q_table[(0, 1)]_new = 0.03584516568884907\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 974 episode and 1 step\n",
            "Delta Q = 0.9036838273309514\n",
            "Q_table[5,0]_old = 0.03363084233327079\n",
            "Q_table[(5, 0)]_new = 0.033951585430895076\n",
            "We are on 5 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 974 episode and 2 step\n",
            "Delta Q = 0.9037314257241048\n",
            "Q_table[5,1]_old = 0.03278000172964574\n",
            "Q_table[(5, 1)]_new = 0.03323342728078601\n",
            "We are on 5 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 974 episode and 3 step\n",
            "Delta Q = 0.9036838273309514\n",
            "Q_table[10,3]_old = 0.021589350853568702\n",
            "Q_table[(10, 3)]_new = 0.0231142430991632\n",
            "We are on 10 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 974 episode and 4 step\n",
            "Delta Q = 0.9\n",
            "Q_table[5,2]_old = 0.0\n",
            "Q_table[(5, 2)]_new = 0.0\n",
            "We are on 5 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 975 episode and 0 step\n",
            "Delta Q = 0.9039617978280423\n",
            "Q_table[0,3]_old = 0.038484764150195215\n",
            "Q_table[(0, 3)]_new = 0.038598085563218004\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 975 episode and 1 step\n",
            "Delta Q = 0.9039617978280423\n",
            "Q_table[0,0]_old = 0.038637133396438116\n",
            "Q_table[(0, 0)]_new = 0.038735217884836616\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 975 episode and 2 step\n",
            "Delta Q = 0.9039617978280423\n",
            "Q_table[0,3]_old = 0.038598085563218004\n",
            "Q_table[(0, 3)]_new = 0.038700074834938515\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 975 episode and 3 step\n",
            "Delta Q = 0.9039617978280423\n",
            "Q_table[0,3]_old = 0.038700074834938515\n",
            "Q_table[(0, 3)]_new = 0.038791865179486976\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 975 episode and 4 step\n",
            "Delta Q = 0.9039617978280423\n",
            "Q_table[0,0]_old = 0.038735217884836616\n",
            "Q_table[(0, 0)]_new = 0.03882349392439527\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 975 episode and 5 step\n",
            "Delta Q = 0.9036838273309514\n",
            "Q_table[0,1]_old = 0.03584516568884907\n",
            "Q_table[(0, 1)]_new = 0.03594447645091553\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 975 episode and 6 step\n",
            "Delta Q = 0.9039617978280423\n",
            "Q_table[5,3]_old = 0.03721037708031683\n",
            "Q_table[(5, 3)]_new = 0.03745113720032746\n",
            "We are on 5 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 975 episode and 7 step\n",
            "Delta Q = 0.9040901635140903\n",
            "Q_table[0,2]_old = 0.04001815987921524\n",
            "Q_table[(0, 2)]_new = 0.040106507405384004\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 975 episode and 8 step\n",
            "Delta Q = 0.9044977133271724\n",
            "Q_table[1,2]_old = 0.041314782970608914\n",
            "Q_table[(1, 2)]_new = 0.041681018000720424\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 975 episode and 9 step\n",
            "Delta Q = 0.9049153436965169\n",
            "Q_table[2,1]_old = 0.04543144774921615\n",
            "Q_table[(2, 1)]_new = 0.045803646670811424\n",
            "We are on 2 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 975 episode and 10 step\n",
            "Delta Q = 0.9045345610204103\n",
            "Q_table[7,3]_old = 0.022386524885664772\n",
            "Q_table[(7, 3)]_new = 0.02468243341750863\n",
            "We are on 7 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 975 episode and 11 step\n",
            "Delta Q = 0.9045345610204103\n",
            "Q_table[2,3]_old = 0.034203392075359024\n",
            "Q_table[(2, 3)]_new = 0.03531761388823345\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 975 episode and 12 step\n",
            "Delta Q = 0.9026920234698452\n",
            "Q_table[2,2]_old = 0.01769506622037352\n",
            "Q_table[(2, 2)]_new = 0.018617583068181415\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 975 episode and 13 step\n",
            "Delta Q = 0.9045345610204103\n",
            "Q_table[3,0]_old = 0.02719215626106312\n",
            "Q_table[(3, 0)]_new = 0.02900750165536714\n",
            "We are on 3 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 975 episode and 14 step\n",
            "Delta Q = 0.9049153436965169\n",
            "Q_table[2,1]_old = 0.045803646670811424\n",
            "Q_table[(2, 1)]_new = 0.04613862570024717\n",
            "We are on 2 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 975 episode and 15 step\n",
            "Delta Q = 0.9\n",
            "Q_table[7,2]_old = 0.0\n",
            "Q_table[(7, 2)]_new = 0.0\n",
            "We are on 7 state\n",
            "And now we are on 8 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 976 episode and 0 step\n",
            "Delta Q = 0.9037076625828324\n",
            "Q_table[0,1]_old = 0.03594447645091553\n",
            "Q_table[(0, 1)]_new = 0.0360576913886564\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 976 episode and 1 step\n",
            "Delta Q = 0.9037314257241048\n",
            "Q_table[5,1]_old = 0.03323342728078601\n",
            "Q_table[(5, 1)]_new = 0.033641510276812246\n",
            "We are on 5 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 976 episode and 2 step\n",
            "Delta Q = 0.9037076625828324\n",
            "Q_table[10,3]_old = 0.0231142430991632\n",
            "Q_table[(10, 3)]_new = 0.0245104813720793\n",
            "We are on 10 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 976 episode and 3 step\n",
            "Delta Q = 0.9\n",
            "Q_table[5,2]_old = 0.0\n",
            "Q_table[(5, 2)]_new = 0.0\n",
            "We are on 5 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 977 episode and 0 step\n",
            "Delta Q = 0.9041264207820714\n",
            "Q_table[0,2]_old = 0.040106507405384004\n",
            "Q_table[(0, 2)]_new = 0.04022227744691693\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 977 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[1,1]_old = 0.0\n",
            "Q_table[(1, 1)]_new = 0.0\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 978 episode and 0 step\n",
            "Delta Q = 0.9041264207820714\n",
            "Q_table[0,2]_old = 0.04022227744691693\n",
            "Q_table[(0, 2)]_new = 0.04032647048429656\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 978 episode and 1 step\n",
            "Delta Q = 0.9041264207820714\n",
            "Q_table[1,3]_old = 0.03792023161322329\n",
            "Q_table[(1, 3)]_new = 0.038254629233972284\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 978 episode and 2 step\n",
            "Delta Q = 0.9\n",
            "Q_table[1,1]_old = 0.0\n",
            "Q_table[(1, 1)]_new = 0.0\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 979 episode and 0 step\n",
            "Delta Q = 0.9039923205779454\n",
            "Q_table[0,0]_old = 0.03882349392439527\n",
            "Q_table[(0, 0)]_new = 0.0389334651099011\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 979 episode and 1 step\n",
            "Delta Q = 0.9041264207820714\n",
            "Q_table[0,2]_old = 0.04032647048429656\n",
            "Q_table[(0, 2)]_new = 0.040420244217938224\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 979 episode and 2 step\n",
            "Delta Q = 0.9\n",
            "Q_table[1,1]_old = 0.0\n",
            "Q_table[(1, 1)]_new = 0.0\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 980 episode and 0 step\n",
            "Delta Q = 0.9041264207820714\n",
            "Q_table[0,2]_old = 0.040420244217938224\n",
            "Q_table[(0, 2)]_new = 0.04050464057821573\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 980 episode and 1 step\n",
            "Delta Q = 0.9041264207820714\n",
            "Q_table[1,3]_old = 0.038254629233972284\n",
            "Q_table[(1, 3)]_new = 0.03855558709264638\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 980 episode and 2 step\n",
            "Delta Q = 0.9045677239443245\n",
            "Q_table[1,2]_old = 0.041681018000720424\n",
            "Q_table[(1, 2)]_new = 0.04208064014497285\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 980 episode and 3 step\n",
            "Delta Q = 0.9045677239443245\n",
            "Q_table[2,3]_old = 0.03531761388823345\n",
            "Q_table[(2, 3)]_new = 0.036353576443734575\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 980 episode and 4 step\n",
            "Delta Q = 0.9041659833743524\n",
            "Q_table[2,0]_old = 0.030667227619328923\n",
            "Q_table[(2, 0)]_new = 0.031766488231748345\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 980 episode and 5 step\n",
            "Delta Q = 0.9041659833743524\n",
            "Q_table[1,3]_old = 0.03855558709264638\n",
            "Q_table[(1, 3)]_new = 0.038866011757734055\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 980 episode and 6 step\n",
            "Delta Q = 0.9\n",
            "Q_table[1,1]_old = 0.0\n",
            "Q_table[(1, 1)]_new = 0.0\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 981 episode and 0 step\n",
            "Delta Q = 0.9040099594172434\n",
            "Q_table[0,3]_old = 0.038791865179486976\n",
            "Q_table[(0, 3)]_new = 0.038922638078781636\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 981 episode and 1 step\n",
            "Delta Q = 0.9037076625828324\n",
            "Q_table[0,1]_old = 0.0360576913886564\n",
            "Q_table[(0, 1)]_new = 0.03615958483262319\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 981 episode and 2 step\n",
            "Delta Q = 0.9040099594172434\n",
            "Q_table[5,3]_old = 0.03745113720032746\n",
            "Q_table[(5, 3)]_new = 0.037715982897538074\n",
            "We are on 5 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 981 episode and 3 step\n",
            "Delta Q = 0.9037338823068563\n",
            "Q_table[0,1]_old = 0.03615958483262319\n",
            "Q_table[(0, 1)]_new = 0.03627750865621714\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 981 episode and 4 step\n",
            "Delta Q = 0.9037338823068563\n",
            "Q_table[5,0]_old = 0.033951585430895076\n",
            "Q_table[(5, 0)]_new = 0.03429030919466184\n",
            "We are on 5 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 981 episode and 5 step\n",
            "Delta Q = 0.9040099594172434\n",
            "Q_table[5,3]_old = 0.037715982897538074\n",
            "Q_table[(5, 3)]_new = 0.03795434402502763\n",
            "We are on 5 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 981 episode and 6 step\n",
            "Delta Q = 0.9037574800584778\n",
            "Q_table[0,1]_old = 0.03627750865621714\n",
            "Q_table[(0, 1)]_new = 0.03640723784907317\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 981 episode and 7 step\n",
            "Delta Q = 0.9\n",
            "Q_table[5,2]_old = 0.0\n",
            "Q_table[(5, 2)]_new = 0.0\n",
            "We are on 5 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 982 episode and 0 step\n",
            "Delta Q = 0.9040099594172434\n",
            "Q_table[0,0]_old = 0.0389334651099011\n",
            "Q_table[(0, 0)]_new = 0.03905007801615435\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 982 episode and 1 step\n",
            "Delta Q = 0.9037574800584778\n",
            "Q_table[0,1]_old = 0.03640723784907317\n",
            "Q_table[(0, 1)]_new = 0.03652399412264359\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 982 episode and 2 step\n",
            "Delta Q = 0.9040099594172434\n",
            "Q_table[5,3]_old = 0.03795434402502763\n",
            "Q_table[(5, 3)]_new = 0.038168869039768225\n",
            "We are on 5 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 982 episode and 3 step\n",
            "Delta Q = 0.9040099594172434\n",
            "Q_table[0,3]_old = 0.038922638078781636\n",
            "Q_table[(0, 3)]_new = 0.039040333688146835\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 982 episode and 4 step\n",
            "Delta Q = 0.9041659833743524\n",
            "Q_table[0,2]_old = 0.04050464057821573\n",
            "Q_table[(0, 2)]_new = 0.04062015989474647\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 982 episode and 5 step\n",
            "Delta Q = 0.9\n",
            "Q_table[1,1]_old = 0.0\n",
            "Q_table[(1, 1)]_new = 0.0\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 983 episode and 0 step\n",
            "Delta Q = 0.9041659833743524\n",
            "Q_table[0,2]_old = 0.04062015989474647\n",
            "Q_table[(0, 2)]_new = 0.040724127279624135\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 983 episode and 1 step\n",
            "Delta Q = 0.9041659833743524\n",
            "Q_table[1,3]_old = 0.038866011757734055\n",
            "Q_table[(1, 3)]_new = 0.03914539395631296\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 983 episode and 2 step\n",
            "Delta Q = 0.9045677239443245\n",
            "Q_table[1,2]_old = 0.04208064014497285\n",
            "Q_table[(1, 2)]_new = 0.042440300074800034\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 983 episode and 3 step\n",
            "Delta Q = 0.9049153436965169\n",
            "Q_table[2,1]_old = 0.04613862570024717\n",
            "Q_table[(2, 1)]_new = 0.04644010682673934\n",
            "We are on 2 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 983 episode and 4 step\n",
            "Delta Q = 0.9\n",
            "Q_table[7,0]_old = 0.0\n",
            "Q_table[(7, 0)]_new = 0.0\n",
            "We are on 7 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 984 episode and 0 step\n",
            "Delta Q = 0.9040316886006828\n",
            "Q_table[0,0]_old = 0.03905007801615435\n",
            "Q_table[(0, 0)]_new = 0.0391767588152217\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 984 episode and 1 step\n",
            "Delta Q = 0.9042015897074053\n",
            "Q_table[0,2]_old = 0.040724127279624135\n",
            "Q_table[(0, 2)]_new = 0.04085330425906693\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 984 episode and 2 step\n",
            "Delta Q = 0.9042015897074053\n",
            "Q_table[1,3]_old = 0.03914539395631296\n",
            "Q_table[(1, 3)]_new = 0.03943244426808687\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 984 episode and 3 step\n",
            "Delta Q = 0.9\n",
            "Q_table[1,1]_old = 0.0\n",
            "Q_table[(1, 1)]_new = 0.0\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 985 episode and 0 step\n",
            "Delta Q = 0.9040444771216476\n",
            "Q_table[0,3]_old = 0.039040333688146835\n",
            "Q_table[(0, 3)]_new = 0.03918077744097978\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 985 episode and 1 step\n",
            "Delta Q = 0.903778718034937\n",
            "Q_table[0,1]_old = 0.03652399412264359\n",
            "Q_table[(0, 1)]_new = 0.036650312745316285\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 985 episode and 2 step\n",
            "Delta Q = 0.903778718034937\n",
            "Q_table[5,0]_old = 0.03429030919466184\n",
            "Q_table[(5, 0)]_new = 0.03463999631013271\n",
            "We are on 5 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 985 episode and 3 step\n",
            "Delta Q = 0.9037314257241048\n",
            "Q_table[5,1]_old = 0.033641510276812246\n",
            "Q_table[(5, 1)]_new = 0.03400878497323586\n",
            "We are on 5 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 985 episode and 4 step\n",
            "Delta Q = 0.903778718034937\n",
            "Q_table[10,3]_old = 0.0245104813720793\n",
            "Q_table[(10, 3)]_new = 0.025838151269808422\n",
            "We are on 10 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 985 episode and 5 step\n",
            "Delta Q = 0.9\n",
            "Q_table[5,2]_old = 0.0\n",
            "Q_table[(5, 2)]_new = 0.0\n",
            "We are on 5 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 0 step\n",
            "Delta Q = 0.9040444771216476\n",
            "Q_table[0,3]_old = 0.03918077744097978\n",
            "Q_table[(0, 3)]_new = 0.03930717681852943\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 1 step\n",
            "Delta Q = 0.903778718034937\n",
            "Q_table[0,1]_old = 0.036650312745316285\n",
            "Q_table[(0, 1)]_new = 0.03676399950572171\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 2 step\n",
            "Delta Q = 0.903778718034937\n",
            "Q_table[5,0]_old = 0.03463999631013271\n",
            "Q_table[(5, 0)]_new = 0.03495471471405649\n",
            "We are on 5 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 3 step\n",
            "Delta Q = 0.9040444771216476\n",
            "Q_table[5,3]_old = 0.038168869039768225\n",
            "Q_table[(5, 3)]_new = 0.03839645925743903\n",
            "We are on 5 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 4 step\n",
            "Delta Q = 0.9038012494664864\n",
            "Q_table[0,1]_old = 0.03676399950572171\n",
            "Q_table[(0, 1)]_new = 0.036888849021636\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 5 step\n",
            "Delta Q = 0.9040444771216476\n",
            "Q_table[5,3]_old = 0.03839645925743903\n",
            "Q_table[(5, 3)]_new = 0.038601290453342756\n",
            "We are on 5 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 6 step\n",
            "Delta Q = 0.9040444771216476\n",
            "Q_table[0,3]_old = 0.03930717681852943\n",
            "Q_table[(0, 3)]_new = 0.039420936258324116\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 7 step\n",
            "Delta Q = 0.9042015897074053\n",
            "Q_table[0,2]_old = 0.04085330425906693\n",
            "Q_table[(0, 2)]_new = 0.04096956354056544\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 8 step\n",
            "Delta Q = 0.9042015897074053\n",
            "Q_table[1,3]_old = 0.03943244426808687\n",
            "Q_table[(1, 3)]_new = 0.03969078954868339\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 9 step\n",
            "Delta Q = 0.9042015897074053\n",
            "Q_table[1,3]_old = 0.03969078954868339\n",
            "Q_table[(1, 3)]_new = 0.03992330030122025\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 10 step\n",
            "Delta Q = 0.9042015897074053\n",
            "Q_table[1,3]_old = 0.03992330030122025\n",
            "Q_table[(1, 3)]_new = 0.04013255997850343\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 11 step\n",
            "Delta Q = 0.9042015897074053\n",
            "Q_table[1,3]_old = 0.04013255997850343\n",
            "Q_table[(1, 3)]_new = 0.04032089368805829\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 12 step\n",
            "Delta Q = 0.904055986790516\n",
            "Q_table[1,0]_old = 0.037704439086698675\n",
            "Q_table[(1, 0)]_new = 0.037989981968544785\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 13 step\n",
            "Delta Q = 0.904055986790516\n",
            "Q_table[0,3]_old = 0.039420936258324116\n",
            "Q_table[(0, 3)]_new = 0.039534829423007685\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 14 step\n",
            "Delta Q = 0.903821527754881\n",
            "Q_table[0,1]_old = 0.036888849021636\n",
            "Q_table[(0, 1)]_new = 0.037021491874353336\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 15 step\n",
            "Delta Q = 0.904055986790516\n",
            "Q_table[5,3]_old = 0.038601290453342756\n",
            "Q_table[(5, 3)]_new = 0.03879714819852446\n",
            "We are on 5 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 16 step\n",
            "Delta Q = 0.904055986790516\n",
            "Q_table[0,0]_old = 0.0391767588152217\n",
            "Q_table[(0, 0)]_new = 0.03931506972421551\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 17 step\n",
            "Delta Q = 0.903840917671654\n",
            "Q_table[0,1]_old = 0.037021491874353336\n",
            "Q_table[(0, 1)]_new = 0.03716026035857192\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 18 step\n",
            "Delta Q = 0.903840917671654\n",
            "Q_table[5,0]_old = 0.03495471471405649\n",
            "Q_table[(5, 0)]_new = 0.03530016091430476\n",
            "We are on 5 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 19 step\n",
            "Delta Q = 0.904055986790516\n",
            "Q_table[5,3]_old = 0.03879714819852446\n",
            "Q_table[(5, 3)]_new = 0.03897342016918799\n",
            "We are on 5 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 20 step\n",
            "Delta Q = 0.904055986790516\n",
            "Q_table[0,0]_old = 0.03931506972421551\n",
            "Q_table[(0, 0)]_new = 0.03943954954230994\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 21 step\n",
            "Delta Q = 0.9042015897074053\n",
            "Q_table[0,2]_old = 0.04096956354056544\n",
            "Q_table[(0, 2)]_new = 0.0410741968939141\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 22 step\n",
            "Delta Q = 0.9040663454924975\n",
            "Q_table[1,0]_old = 0.037989981968544785\n",
            "Q_table[(1, 0)]_new = 0.0382573292641878\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 23 step\n",
            "Delta Q = 0.9040663454924975\n",
            "Q_table[0,3]_old = 0.039534829423007685\n",
            "Q_table[(0, 3)]_new = 0.03964769197320441\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 24 step\n",
            "Delta Q = 0.9038583685967496\n",
            "Q_table[0,1]_old = 0.03716026035857192\n",
            "Q_table[(0, 1)]_new = 0.03730260291946434\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 25 step\n",
            "Delta Q = 0.9040663454924975\n",
            "Q_table[5,3]_old = 0.03897342016918799\n",
            "Q_table[(5, 3)]_new = 0.03914242364476669\n",
            "We are on 5 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 26 step\n",
            "Delta Q = 0.9040663454924975\n",
            "Q_table[0,0]_old = 0.03943954954230994\n",
            "Q_table[(0, 0)]_new = 0.03956194008057644\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 27 step\n",
            "Delta Q = 0.9038750999408319\n",
            "Q_table[0,1]_old = 0.03730260291946434\n",
            "Q_table[(0, 1)]_new = 0.03744744256834981\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 28 step\n",
            "Delta Q = 0.9037314257241048\n",
            "Q_table[5,1]_old = 0.03400878497323586\n",
            "Q_table[(5, 1)]_new = 0.034339332200017114\n",
            "We are on 5 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 29 step\n",
            "Delta Q = 0.9045867015970035\n",
            "Q_table[10,2]_old = 0.03769116893035189\n",
            "Q_table[(10, 2)]_new = 0.038508753634320214\n",
            "We are on 10 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 30 step\n",
            "Delta Q = 0.9038123666097977\n",
            "Q_table[11,0]_old = 0.017529601753097947\n",
            "Q_table[(11, 0)]_new = 0.019589008187585855\n",
            "We are on 11 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 31 step\n",
            "Delta Q = 0.9038750999408319\n",
            "Q_table[10,3]_old = 0.025838151269808422\n",
            "Q_table[(10, 3)]_new = 0.027129436083659482\n",
            "We are on 10 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 32 step\n",
            "Delta Q = 0.9038750999408319\n",
            "Q_table[5,0]_old = 0.03530016091430476\n",
            "Q_table[(5, 0)]_new = 0.03564524476370619\n",
            "We are on 5 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 33 step\n",
            "Delta Q = 0.9038750999408319\n",
            "Q_table[5,0]_old = 0.03564524476370619\n",
            "Q_table[(5, 0)]_new = 0.03595582022816747\n",
            "We are on 5 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 34 step\n",
            "Delta Q = 0.9038123666097977\n",
            "Q_table[5,1]_old = 0.034339332200017114\n",
            "Q_table[(5, 1)]_new = 0.034717765589813106\n",
            "We are on 5 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 35 step\n",
            "Delta Q = 0.9038750999408319\n",
            "Q_table[10,3]_old = 0.027129436083659482\n",
            "Q_table[(10, 3)]_new = 0.028291592416125437\n",
            "We are on 10 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 36 step\n",
            "Delta Q = 0.9040663454924975\n",
            "Q_table[5,3]_old = 0.03914242364476669\n",
            "Q_table[(5, 3)]_new = 0.03929452677278751\n",
            "We are on 5 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 37 step\n",
            "Delta Q = 0.903890158150506\n",
            "Q_table[0,1]_old = 0.03744744256834981\n",
            "Q_table[(0, 1)]_new = 0.0375928564620208\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 38 step\n",
            "Delta Q = 0.903890158150506\n",
            "Q_table[5,0]_old = 0.03595582022816747\n",
            "Q_table[(5, 0)]_new = 0.03625039635585669\n",
            "We are on 5 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 39 step\n",
            "Delta Q = 0.903890158150506\n",
            "Q_table[5,0]_old = 0.03625039635585669\n",
            "Q_table[(5, 0)]_new = 0.036515514870776984\n",
            "We are on 5 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 40 step\n",
            "Delta Q = 0.9040663454924975\n",
            "Q_table[5,3]_old = 0.03929452677278751\n",
            "Q_table[(5, 3)]_new = 0.03943141958800626\n",
            "We are on 5 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 41 step\n",
            "Delta Q = 0.9040663454924975\n",
            "Q_table[0,0]_old = 0.03956194008057644\n",
            "Q_table[(0, 0)]_new = 0.03967209156501629\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 42 step\n",
            "Delta Q = 0.9042015897074053\n",
            "Q_table[0,2]_old = 0.0410741968939141\n",
            "Q_table[(0, 2)]_new = 0.0411683669119279\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 43 step\n",
            "Delta Q = 0.9042015897074053\n",
            "Q_table[1,3]_old = 0.04032089368805829\n",
            "Q_table[(1, 3)]_new = 0.04049039402665766\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 44 step\n",
            "Delta Q = 0.9042015897074053\n",
            "Q_table[1,3]_old = 0.04049039402665766\n",
            "Q_table[(1, 3)]_new = 0.0406429443313971\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 45 step\n",
            "Delta Q = 0.9042015897074053\n",
            "Q_table[1,3]_old = 0.0406429443313971\n",
            "Q_table[(1, 3)]_new = 0.04078023960566259\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 46 step\n",
            "Delta Q = 0.9040756683242809\n",
            "Q_table[1,0]_old = 0.0382573292641878\n",
            "Q_table[(1, 0)]_new = 0.038507264662049887\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 47 step\n",
            "Delta Q = 0.9039037105392126\n",
            "Q_table[0,1]_old = 0.0375928564620208\n",
            "Q_table[(0, 1)]_new = 0.037737281355031335\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 48 step\n",
            "Delta Q = 0.9039037105392126\n",
            "Q_table[5,0]_old = 0.036515514870776984\n",
            "Q_table[(5, 0)]_new = 0.0367676739229119\n",
            "We are on 5 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 986 episode and 49 step\n",
            "Delta Q = 0.9\n",
            "Q_table[5,2]_old = 0.0\n",
            "Q_table[(5, 2)]_new = 0.0\n",
            "We are on 5 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 987 episode and 0 step\n",
            "Delta Q = 0.9040756683242809\n",
            "Q_table[0,3]_old = 0.03964769197320441\n",
            "Q_table[(0, 3)]_new = 0.03975859110016484\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 987 episode and 1 step\n",
            "Delta Q = 0.9042015897074053\n",
            "Q_table[0,2]_old = 0.0411683669119279\n",
            "Q_table[(0, 2)]_new = 0.04125311992814031\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 987 episode and 2 step\n",
            "Delta Q = 0.9\n",
            "Q_table[1,1]_old = 0.0\n",
            "Q_table[(1, 1)]_new = 0.0\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 988 episode and 0 step\n",
            "Delta Q = 0.9040840588728859\n",
            "Q_table[0,3]_old = 0.03975859110016484\n",
            "Q_table[(0, 3)]_new = 0.03986679086303425\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 988 episode and 1 step\n",
            "Delta Q = 0.9042015897074053\n",
            "Q_table[0,2]_old = 0.04125311992814031\n",
            "Q_table[(0, 2)]_new = 0.04132939764273148\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 988 episode and 2 step\n",
            "Delta Q = 0.9\n",
            "Q_table[1,1]_old = 0.0\n",
            "Q_table[(1, 1)]_new = 0.0\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 989 episode and 0 step\n",
            "Delta Q = 0.9039037105392126\n",
            "Q_table[0,1]_old = 0.037737281355031335\n",
            "Q_table[(0, 1)]_new = 0.03786726375874082\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 989 episode and 1 step\n",
            "Delta Q = 0.9040916103666304\n",
            "Q_table[5,3]_old = 0.03943141958800626\n",
            "Q_table[(5, 3)]_new = 0.03957988799583605\n",
            "We are on 5 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 989 episode and 2 step\n",
            "Delta Q = 0.9039184089115878\n",
            "Q_table[0,1]_old = 0.03786726375874082\n",
            "Q_table[(0, 1)]_new = 0.03799894629445451\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 989 episode and 3 step\n",
            "Delta Q = 0.9038123666097977\n",
            "Q_table[5,1]_old = 0.034717765589813106\n",
            "Q_table[(5, 1)]_new = 0.0350583556406295\n",
            "We are on 5 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 989 episode and 4 step\n",
            "Delta Q = 0.9\n",
            "Q_table[10,1]_old = 0.0\n",
            "Q_table[(10, 1)]_new = 0.0\n",
            "We are on 10 state\n",
            "And now we are on 15 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 990 episode and 0 step\n",
            "Delta Q = 0.9040916103666304\n",
            "Q_table[0,3]_old = 0.03986679086303425\n",
            "Q_table[(0, 3)]_new = 0.03997172214336124\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 990 episode and 1 step\n",
            "Delta Q = 0.9040916103666304\n",
            "Q_table[0,3]_old = 0.03997172214336124\n",
            "Q_table[(0, 3)]_new = 0.04006616029565553\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 990 episode and 2 step\n",
            "Delta Q = 0.9042015897074053\n",
            "Q_table[0,2]_old = 0.04132939764273148\n",
            "Q_table[(0, 2)]_new = 0.04139804758586354\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 990 episode and 3 step\n",
            "Delta Q = 0.9042015897074053\n",
            "Q_table[1,3]_old = 0.04078023960566259\n",
            "Q_table[(1, 3)]_new = 0.040903805352501536\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 990 episode and 4 step\n",
            "Delta Q = 0.9042015897074053\n",
            "Q_table[1,3]_old = 0.040903805352501536\n",
            "Q_table[(1, 3)]_new = 0.041015014524656584\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 990 episode and 5 step\n",
            "Delta Q = 0.9042015897074053\n",
            "Q_table[1,3]_old = 0.041015014524656584\n",
            "Q_table[(1, 3)]_new = 0.04111510277959613\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 990 episode and 6 step\n",
            "Delta Q = 0.9045975705758472\n",
            "Q_table[1,2]_old = 0.042440300074800034\n",
            "Q_table[(1, 2)]_new = 0.04279384064316722\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 990 episode and 7 step\n",
            "Delta Q = 0.9042365902236735\n",
            "Q_table[2,0]_old = 0.031766488231748345\n",
            "Q_table[(2, 0)]_new = 0.032826429632247064\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 990 episode and 8 step\n",
            "Delta Q = 0.9\n",
            "Q_table[1,1]_old = 0.0\n",
            "Q_table[(1, 1)]_new = 0.0\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 0 step\n",
            "Delta Q = 0.9040984067110005\n",
            "Q_table[0,0]_old = 0.03967209156501629\n",
            "Q_table[(0, 0)]_new = 0.03980328911951515\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 1 step\n",
            "Delta Q = 0.9042365902236735\n",
            "Q_table[0,2]_old = 0.04139804758586354\n",
            "Q_table[(0, 2)]_new = 0.041494833050950745\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 2 step\n",
            "Delta Q = 0.9042365902236735\n",
            "Q_table[1,3]_old = 0.04111510277959613\n",
            "Q_table[(1, 3)]_new = 0.041240182725310076\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 991 episode and 3 step\n",
            "Delta Q = 0.9\n",
            "Q_table[1,1]_old = 0.0\n",
            "Q_table[(1, 1)]_new = 0.0\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 992 episode and 0 step\n",
            "Delta Q = 0.9041079884720441\n",
            "Q_table[0,0]_old = 0.03980328911951515\n",
            "Q_table[(0, 0)]_new = 0.03993094867960777\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 992 episode and 1 step\n",
            "Delta Q = 0.9041079884720441\n",
            "Q_table[0,0]_old = 0.03993094867960777\n",
            "Q_table[(0, 0)]_new = 0.04004584228369112\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 992 episode and 2 step\n",
            "Delta Q = 0.9041079884720441\n",
            "Q_table[0,3]_old = 0.04006616029565553\n",
            "Q_table[(0, 3)]_new = 0.04016753273813411\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 992 episode and 3 step\n",
            "Delta Q = 0.9041079884720441\n",
            "Q_table[0,0]_old = 0.04004584228369112\n",
            "Q_table[(0, 0)]_new = 0.04014924652736613\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 992 episode and 4 step\n",
            "Delta Q = 0.9041079884720441\n",
            "Q_table[0,3]_old = 0.04016753273813411\n",
            "Q_table[(0, 3)]_new = 0.04025876793636483\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 992 episode and 5 step\n",
            "Delta Q = 0.9042365902236735\n",
            "Q_table[0,2]_old = 0.041494833050950745\n",
            "Q_table[(0, 2)]_new = 0.041581939969529226\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 992 episode and 6 step\n",
            "Delta Q = 0.9\n",
            "Q_table[1,1]_old = 0.0\n",
            "Q_table[(1, 1)]_new = 0.0\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 993 episode and 0 step\n",
            "Delta Q = 0.9041166120569835\n",
            "Q_table[0,0]_old = 0.04014924652736613\n",
            "Q_table[(0, 0)]_new = 0.040250933931612914\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 993 episode and 1 step\n",
            "Delta Q = 0.9041166120569835\n",
            "Q_table[0,3]_old = 0.04025876793636483\n",
            "Q_table[(0, 3)]_new = 0.04034950319971174\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 993 episode and 2 step\n",
            "Delta Q = 0.9041166120569835\n",
            "Q_table[0,0]_old = 0.040250933931612914\n",
            "Q_table[(0, 0)]_new = 0.04034245259543502\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 993 episode and 3 step\n",
            "Delta Q = 0.9042365902236735\n",
            "Q_table[0,2]_old = 0.041581939969529226\n",
            "Q_table[(0, 2)]_new = 0.04166033619624986\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 993 episode and 4 step\n",
            "Delta Q = 0.9042365902236735\n",
            "Q_table[1,3]_old = 0.041240182725310076\n",
            "Q_table[(1, 3)]_new = 0.04135275467645263\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 993 episode and 5 step\n",
            "Delta Q = 0.9042365902236735\n",
            "Q_table[1,3]_old = 0.04135275467645263\n",
            "Q_table[(1, 3)]_new = 0.04145406943248092\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 993 episode and 6 step\n",
            "Delta Q = 0.9041243732834288\n",
            "Q_table[1,0]_old = 0.038507264662049887\n",
            "Q_table[(1, 0)]_new = 0.038780911479273636\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 993 episode and 7 step\n",
            "Delta Q = 0.9042365902236735\n",
            "Q_table[0,2]_old = 0.04166033619624986\n",
            "Q_table[(0, 2)]_new = 0.04173089280029844\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 993 episode and 8 step\n",
            "Delta Q = 0.9042365902236735\n",
            "Q_table[1,3]_old = 0.04145406943248092\n",
            "Q_table[(1, 3)]_new = 0.04154525271290639\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 993 episode and 9 step\n",
            "Delta Q = 0.9045975705758472\n",
            "Q_table[1,2]_old = 0.04279384064316722\n",
            "Q_table[(1, 2)]_new = 0.04311202715469769\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 993 episode and 10 step\n",
            "Delta Q = 0.904268090688315\n",
            "Q_table[2,0]_old = 0.032826429632247064\n",
            "Q_table[(2, 0)]_new = 0.03381187735733743\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 993 episode and 11 step\n",
            "Delta Q = 0.9045975705758472\n",
            "Q_table[1,2]_old = 0.04311202715469769\n",
            "Q_table[(1, 2)]_new = 0.043398395015075114\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 993 episode and 12 step\n",
            "Delta Q = 0.9049153436965169\n",
            "Q_table[2,1]_old = 0.04644010682673934\n",
            "Q_table[(2, 1)]_new = 0.04671143984058229\n",
            "We are on 2 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 993 episode and 13 step\n",
            "Delta Q = 0.9\n",
            "Q_table[7,0]_old = 0.0\n",
            "Q_table[(7, 0)]_new = 0.0\n",
            "We are on 7 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 994 episode and 0 step\n",
            "Delta Q = 0.9042964411064924\n",
            "Q_table[0,2]_old = 0.04173089280029844\n",
            "Q_table[(0, 2)]_new = 0.04185424462676103\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 994 episode and 1 step\n",
            "Delta Q = 0.9046244325442176\n",
            "Q_table[1,2]_old = 0.043398395015075114\n",
            "Q_table[(1, 2)]_new = 0.043682988057785255\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 994 episode and 2 step\n",
            "Delta Q = 0.9043246158177207\n",
            "Q_table[2,0]_old = 0.03381187735733743\n",
            "Q_table[(2, 0)]_new = 0.034755305439324424\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 994 episode and 3 step\n",
            "Delta Q = 0.9043246158177207\n",
            "Q_table[1,3]_old = 0.04154525271290639\n",
            "Q_table[(1, 3)]_new = 0.0417153432593365\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 994 episode and 4 step\n",
            "Delta Q = 0.9041435702180494\n",
            "Q_table[1,0]_old = 0.038780911479273636\n",
            "Q_table[(1, 0)]_new = 0.03904639054939561\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 994 episode and 5 step\n",
            "Delta Q = 0.9041435702180494\n",
            "Q_table[0,0]_old = 0.04034245259543502\n",
            "Q_table[(0, 0)]_new = 0.04045177755394086\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 994 episode and 6 step\n",
            "Delta Q = 0.9043246158177207\n",
            "Q_table[0,2]_old = 0.04185424462676103\n",
            "Q_table[(0, 2)]_new = 0.041993435981805674\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 994 episode and 7 step\n",
            "Delta Q = 0.9043246158177207\n",
            "Q_table[1,3]_old = 0.0417153432593365\n",
            "Q_table[(1, 3)]_new = 0.041868424751123595\n",
            "We are on 1 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 994 episode and 8 step\n",
            "Delta Q = 0.9046244325442176\n",
            "Q_table[1,2]_old = 0.043682988057785255\n",
            "Q_table[(1, 2)]_new = 0.043939121796224376\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 994 episode and 9 step\n",
            "Delta Q = 0.9043499730578263\n",
            "Q_table[2,0]_old = 0.034755305439324424\n",
            "Q_table[(2, 0)]_new = 0.0356297479532182\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 994 episode and 10 step\n",
            "Delta Q = 0.9041573501621988\n",
            "Q_table[1,0]_old = 0.03904639054939561\n",
            "Q_table[(1, 0)]_new = 0.03929910165665482\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 994 episode and 11 step\n",
            "Delta Q = 0.9039184089115878\n",
            "Q_table[0,1]_old = 0.03799894629445451\n",
            "Q_table[(0, 1)]_new = 0.038117460576596825\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 994 episode and 12 step\n",
            "Delta Q = 0.9038123666097977\n",
            "Q_table[5,1]_old = 0.0350583556406295\n",
            "Q_table[(5, 1)]_new = 0.035364886686364255\n",
            "We are on 5 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 994 episode and 13 step\n",
            "Delta Q = 0.9038123666097977\n",
            "Q_table[10,0]_old = 0.02548530149269047\n",
            "Q_table[(10, 0)]_new = 0.026749137953219128\n",
            "We are on 10 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 994 episode and 14 step\n",
            "Delta Q = 0.9\n",
            "Q_table[10,1]_old = 0.0\n",
            "Q_table[(10, 1)]_new = 0.0\n",
            "We are on 10 state\n",
            "And now we are on 15 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 995 episode and 0 step\n",
            "Delta Q = 0.9041573501621988\n",
            "Q_table[0,0]_old = 0.04045177755394086\n",
            "Q_table[(0, 0)]_new = 0.04056394996074554\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 995 episode and 1 step\n",
            "Delta Q = 0.9043499730578263\n",
            "Q_table[0,2]_old = 0.041993435981805674\n",
            "Q_table[(0, 2)]_new = 0.04214406544145132\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 995 episode and 2 step\n",
            "Delta Q = 0.9041722624787037\n",
            "Q_table[1,0]_old = 0.03929910165665482\n",
            "Q_table[(1, 0)]_new = 0.03954145396969302\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 995 episode and 3 step\n",
            "Delta Q = 0.9043499730578263\n",
            "Q_table[0,2]_old = 0.04214406544145132\n",
            "Q_table[(0, 2)]_new = 0.04227963195513241\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 995 episode and 4 step\n",
            "Delta Q = 0.9041856835635581\n",
            "Q_table[1,0]_old = 0.03954145396969302\n",
            "Q_table[(1, 0)]_new = 0.03977299213628182\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 995 episode and 5 step\n",
            "Delta Q = 0.9043499730578263\n",
            "Q_table[0,2]_old = 0.04227963195513241\n",
            "Q_table[(0, 2)]_new = 0.042401641817445386\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 995 episode and 6 step\n",
            "Delta Q = 0.9046244325442176\n",
            "Q_table[1,2]_old = 0.043939121796224376\n",
            "Q_table[(1, 2)]_new = 0.04416964216081959\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 995 episode and 7 step\n",
            "Delta Q = 0.9028717426638814\n",
            "Q_table[2,2]_old = 0.018617583068181415\n",
            "Q_table[(2, 2)]_new = 0.01962756742524462\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 995 episode and 8 step\n",
            "Delta Q = 0.9046244325442176\n",
            "Q_table[3,0]_old = 0.02900750165536714\n",
            "Q_table[(3, 0)]_new = 0.030731184034048075\n",
            "We are on 3 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 995 episode and 9 step\n",
            "Delta Q = 0.9030423872193708\n",
            "Q_table[2,2]_old = 0.01962756742524462\n",
            "Q_table[(2, 2)]_new = 0.020707197902090916\n",
            "We are on 2 state\n",
            "And now we are on 3 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 995 episode and 10 step\n",
            "Delta Q = 0.9046244325442176\n",
            "Q_table[3,0]_old = 0.030731184034048075\n",
            "Q_table[(3, 0)]_new = 0.03228249817486092\n",
            "We are on 3 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 995 episode and 11 step\n",
            "Delta Q = 0.9043727945739212\n",
            "Q_table[2,0]_old = 0.0356297479532182\n",
            "Q_table[(2, 0)]_new = 0.03643956773181752\n",
            "We are on 2 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 995 episode and 12 step\n",
            "Delta Q = 0.9046244325442176\n",
            "Q_table[1,2]_old = 0.04416964216081959\n",
            "Q_table[(1, 2)]_new = 0.044377110488955276\n",
            "We are on 1 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 995 episode and 13 step\n",
            "Delta Q = 0.9046244325442176\n",
            "Q_table[2,3]_old = 0.036353576443734575\n",
            "Q_table[(2, 3)]_new = 0.03734265134357877\n",
            "We are on 2 state\n",
            "And now we are on 2 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 995 episode and 14 step\n",
            "Delta Q = 0.9049153436965169\n",
            "Q_table[2,1]_old = 0.04671143984058229\n",
            "Q_table[(2, 1)]_new = 0.046955639553040954\n",
            "We are on 2 state\n",
            "And now we are on 7 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 995 episode and 15 step\n",
            "Delta Q = 0.9\n",
            "Q_table[7,0]_old = 0.0\n",
            "Q_table[(7, 0)]_new = 0.0\n",
            "We are on 7 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 996 episode and 0 step\n",
            "Delta Q = 0.9041977625399271\n",
            "Q_table[0,0]_old = 0.04056394996074554\n",
            "Q_table[(0, 0)]_new = 0.040705317504598076\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 996 episode and 1 step\n",
            "Delta Q = 0.9041977625399271\n",
            "Q_table[0,0]_old = 0.040705317504598076\n",
            "Q_table[(0, 0)]_new = 0.040832548294065366\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 996 episode and 2 step\n",
            "Delta Q = 0.9039184089115878\n",
            "Q_table[0,1]_old = 0.038117460576596825\n",
            "Q_table[(0, 1)]_new = 0.03822412343052491\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 996 episode and 3 step\n",
            "Delta Q = 0.9041977625399271\n",
            "Q_table[5,3]_old = 0.03957988799583605\n",
            "Q_table[(5, 3)]_new = 0.03981966173617954\n",
            "We are on 5 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 996 episode and 4 step\n",
            "Delta Q = 0.9039421465118818\n",
            "Q_table[0,1]_old = 0.03822412343052491\n",
            "Q_table[(0, 1)]_new = 0.03834385759935419\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 996 episode and 5 step\n",
            "Delta Q = 0.9039421465118818\n",
            "Q_table[5,0]_old = 0.0367676739229119\n",
            "Q_table[(5, 0)]_new = 0.037033053042502484\n",
            "We are on 5 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 996 episode and 6 step\n",
            "Delta Q = 0.9038123666097977\n",
            "Q_table[5,1]_old = 0.035364886686364255\n",
            "Q_table[(5, 1)]_new = 0.03564076462752554\n",
            "We are on 5 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 996 episode and 7 step\n",
            "Delta Q = 0.9039421465118818\n",
            "Q_table[10,3]_old = 0.028291592416125437\n",
            "Q_table[(10, 3)]_new = 0.029404579686394667\n",
            "We are on 10 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 996 episode and 8 step\n",
            "Delta Q = 0.9038123666097977\n",
            "Q_table[5,1]_old = 0.03564076462752554\n",
            "Q_table[(5, 1)]_new = 0.03588905477457069\n",
            "We are on 5 state\n",
            "And now we are on 10 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 996 episode and 9 step\n",
            "Delta Q = 0.9045867015970035\n",
            "Q_table[10,2]_old = 0.038508753634320214\n",
            "Q_table[(10, 2)]_new = 0.03924457986789171\n",
            "We are on 10 state\n",
            "And now we are on 11 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 996 episode and 10 step\n",
            "Delta Q = 0.9\n",
            "Q_table[11,3]_old = 0.0\n",
            "Q_table[(11, 3)]_new = 0.0\n",
            "We are on 11 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 997 episode and 0 step\n",
            "Delta Q = 0.9041977625399271\n",
            "Q_table[0,0]_old = 0.040832548294065366\n",
            "Q_table[(0, 0)]_new = 0.040947056004585924\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 997 episode and 1 step\n",
            "Delta Q = 0.9041977625399271\n",
            "Q_table[0,0]_old = 0.040947056004585924\n",
            "Q_table[(0, 0)]_new = 0.04105011294405443\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 997 episode and 2 step\n",
            "Delta Q = 0.9041977625399271\n",
            "Q_table[0,0]_old = 0.04105011294405443\n",
            "Q_table[(0, 0)]_new = 0.04114286418957608\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 997 episode and 3 step\n",
            "Delta Q = 0.9043933339384066\n",
            "Q_table[0,2]_old = 0.042401641817445386\n",
            "Q_table[(0, 2)]_new = 0.04255481157410742\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 997 episode and 4 step\n",
            "Delta Q = 0.9042129263458366\n",
            "Q_table[1,0]_old = 0.03977299213628182\n",
            "Q_table[(1, 0)]_new = 0.040008619268490274\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 997 episode and 5 step\n",
            "Delta Q = 0.9042129263458366\n",
            "Q_table[0,3]_old = 0.04034950319971174\n",
            "Q_table[(0, 3)]_new = 0.04052747922557721\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 997 episode and 6 step\n",
            "Delta Q = 0.9042129263458366\n",
            "Q_table[0,0]_old = 0.04114286418957608\n",
            "Q_table[(0, 0)]_new = 0.04124150411645511\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 997 episode and 7 step\n",
            "Delta Q = 0.9042129263458366\n",
            "Q_table[0,0]_old = 0.04124150411645511\n",
            "Q_table[(0, 0)]_new = 0.041330280050646234\n",
            "We are on 0 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 997 episode and 8 step\n",
            "Delta Q = 0.9043933339384066\n",
            "Q_table[0,2]_old = 0.04255481157410742\n",
            "Q_table[(0, 2)]_new = 0.04269266435510325\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 997 episode and 9 step\n",
            "Delta Q = 0.9042265737711552\n",
            "Q_table[1,0]_old = 0.040008619268490274\n",
            "Q_table[(1, 0)]_new = 0.040234331112796465\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 997 episode and 10 step\n",
            "Delta Q = 0.9039421465118818\n",
            "Q_table[0,1]_old = 0.03834385759935419\n",
            "Q_table[(0, 1)]_new = 0.03845161835130055\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 997 episode and 11 step\n",
            "Delta Q = 0.9039421465118818\n",
            "Q_table[5,0]_old = 0.037033053042502484\n",
            "Q_table[(5, 0)]_new = 0.03727189425013401\n",
            "We are on 5 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 997 episode and 12 step\n",
            "Delta Q = 0.9\n",
            "Q_table[5,2]_old = 0.0\n",
            "Q_table[(5, 2)]_new = 0.0\n",
            "We are on 5 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 998 episode and 0 step\n",
            "Delta Q = 0.9039421465118818\n",
            "Q_table[0,1]_old = 0.03845161835130055\n",
            "Q_table[(0, 1)]_new = 0.03854860302805227\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 998 episode and 1 step\n",
            "Delta Q = 0.9\n",
            "Q_table[5,2]_old = 0.0\n",
            "Q_table[(5, 2)]_new = 0.0\n",
            "We are on 5 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 999 episode and 0 step\n",
            "Delta Q = 0.9043933339384066\n",
            "Q_table[0,2]_old = 0.04269266435510325\n",
            "Q_table[(0, 2)]_new = 0.0428167318579995\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 999 episode and 1 step\n",
            "Delta Q = 0.904238856453942\n",
            "Q_table[1,0]_old = 0.040234331112796465\n",
            "Q_table[(1, 0)]_new = 0.04044975445545877\n",
            "We are on 1 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 999 episode and 2 step\n",
            "Delta Q = 0.9039421465118818\n",
            "Q_table[0,1]_old = 0.03854860302805227\n",
            "Q_table[(0, 1)]_new = 0.038635889237128816\n",
            "We are on 0 state\n",
            "And now we are on 5 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 999 episode and 3 step\n",
            "Delta Q = 0.904238856453942\n",
            "Q_table[5,3]_old = 0.03981966173617954\n",
            "Q_table[(5, 3)]_new = 0.04007655201650354\n",
            "We are on 5 state\n",
            "And now we are on 0 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 999 episode and 4 step\n",
            "Delta Q = 0.9043933339384066\n",
            "Q_table[0,2]_old = 0.0428167318579995\n",
            "Q_table[(0, 2)]_new = 0.042928392610606124\n",
            "We are on 0 state\n",
            "And now we are on 1 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n",
            "We are on 999 episode and 5 step\n",
            "Delta Q = 0.9\n",
            "Q_table[1,1]_old = 0.0\n",
            "Q_table[(1, 1)]_new = 0.0\n",
            "We are on 1 state\n",
            "And now we are on 6 state\n",
            "We get 0.0 reward \n",
            "exploration_rate = 1\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imageio imageio_ffmpeg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j45ghrMbmYMW",
        "outputId": "e18d8077-8fbd-436f-ec64-bedba826c285"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (2.31.6)\n",
            "Requirement already satisfied: imageio_ffmpeg in /usr/local/lib/python3.10/dist-packages (0.4.9)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from imageio) (1.25.2)\n",
            "Requirement already satisfied: pillow<10.1.0,>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio) (9.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio_ffmpeg) (67.7.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import imageio"
      ],
      "metadata": {
        "id": "NKpgHiejml6h"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def record_video(env, q_table, out_directory, fps=1):\n",
        "  images = []\n",
        "  done = False\n",
        "  state = env.reset(seed=random.randint(0,500))\n",
        "  img = env.render(mode='rgb_array')\n",
        "  images.append(img)\n",
        "  while not done:\n",
        "    # Take the action (index) that have the maximum expected future reward given that state\n",
        "    action = np.argmax(q_table[state][:])\n",
        "    state, reward, done, info = env.step(action) # We directly put next_state = state for recording logic\n",
        "    img = env.render(mode='rgb_array')\n",
        "    images.append(img)\n",
        "  imageio.mimsave(out_directory, [np.array(img) for i, img in enumerate(images)], fps=fps)"
      ],
      "metadata": {
        "id": "Vi8Mq4tEl4Yb"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_path=\"/content/replay.gif\"\n",
        "video_fps=10\n",
        "record_video(env, q_table, video_path, video_fps)\n",
        "\n",
        "from IPython.display import Image\n",
        "Image('./replay.gif')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "turRjFNxmFal",
        "outputId": "dfcf17a4-cbee-4677-9971-d1f14c2d9a2f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/gif": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    }
  ]
}